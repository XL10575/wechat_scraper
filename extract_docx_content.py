#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æå–DOCXæ–‡æ¡£å†…å®¹å·¥å…·
æå–æ–‡å­—å’Œå›¾ç‰‡ï¼Œä¾¿äºå¤åˆ¶åˆ°é£ä¹¦çŸ¥è¯†åº“
"""

import os
import sys
from pathlib import Path
from loguru import logger
import zipfile
import xml.etree.ElementTree as ET
from io import BytesIO
import base64

try:
    from docx import Document
    from docx.document import Document as _Document
    from docx.oxml.table import CT_Tbl
    from docx.oxml.text.paragraph import CT_P
    from docx.table import _Cell, Table
    from docx.text.paragraph import Paragraph
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    logger.warning("python-docx åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€XMLè§£æ")

def extract_docx_content(docx_path: str):
    """æå–DOCXæ–‡æ¡£çš„å†…å®¹
    
    Args:
        docx_path: DOCXæ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict: åŒ…å«æ–‡æœ¬å†…å®¹å’Œå›¾ç‰‡ä¿¡æ¯çš„å­—å…¸
    """
    try:
        logger.info(f"ğŸ“– å¼€å§‹æå–DOCXå†…å®¹: {os.path.basename(docx_path)}")
        
        if not os.path.exists(docx_path):
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docx_path}")
            return None
        
        if DOCX_AVAILABLE:
            return extract_with_python_docx(docx_path)
        else:
            return extract_with_xml_parser(docx_path)
            
    except Exception as e:
        logger.error(f"æå–DOCXå†…å®¹å¤±è´¥: {e}")
        return None

def extract_with_python_docx(docx_path: str):
    """ä½¿ç”¨python-docxåº“æå–å†…å®¹"""
    try:
        doc = Document(docx_path)
        
        content = {
            'title': os.path.splitext(os.path.basename(docx_path))[0],
            'paragraphs': [],
            'images': [],
            'tables': [],
            'full_text': ''
        }
        
        logger.info("ğŸ“ æå–æ®µè½å†…å®¹...")
        
        # æå–æ®µè½å†…å®¹
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                content['paragraphs'].append({
                    'text': text,
                    'style': para.style.name if para.style else 'Normal'
                })
        
        # æå–è¡¨æ ¼å†…å®¹
        logger.info("ğŸ“Š æå–è¡¨æ ¼å†…å®¹...")
        for table_idx, table in enumerate(doc.tables):
            table_data = []
            for row in table.rows:
                row_data = []
                for cell in row.cells:
                    row_data.append(cell.text.strip())
                table_data.append(row_data)
            
            if table_data:
                content['tables'].append({
                    'index': table_idx,
                    'data': table_data
                })
        
        # æå–å›¾ç‰‡ï¼ˆéœ€è¦è§£æå…³ç³»æ–‡ä»¶ï¼‰
        logger.info("ğŸ–¼ï¸ æå–å›¾ç‰‡ä¿¡æ¯...")
        images = extract_images_from_docx(docx_path)
        content['images'] = images
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        all_text = []
        for para in content['paragraphs']:
            all_text.append(para['text'])
        
        for table in content['tables']:
            for row in table['data']:
                all_text.extend(row)
        
        content['full_text'] = '\n\n'.join(filter(None, all_text))
        
        logger.success(f"âœ… å†…å®¹æå–å®Œæˆ:")
        logger.info(f"ğŸ“„ æ®µè½æ•°: {len(content['paragraphs'])}")
        logger.info(f"ğŸ“Š è¡¨æ ¼æ•°: {len(content['tables'])}")
        logger.info(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°: {len(content['images'])}")
        logger.info(f"ğŸ“ æ€»å­—ç¬¦æ•°: {len(content['full_text'])}")
        
        return content
        
    except Exception as e:
        logger.error(f"python-docxæå–å¤±è´¥: {e}")
        return None

def extract_images_from_docx(docx_path: str):
    """ä»DOCXæ–‡ä»¶ä¸­æå–å›¾ç‰‡"""
    images = []
    
    try:
        with zipfile.ZipFile(docx_path, 'r') as zip_file:
            # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
            image_files = [f for f in zip_file.namelist() 
                          if f.startswith('word/media/') and 
                          any(f.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp'])]
            
            logger.info(f"ğŸ” å‘ç° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
            
            for img_file in image_files:
                try:
                    # è¯»å–å›¾ç‰‡æ•°æ®
                    img_data = zip_file.read(img_file)
                    
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    _, ext = os.path.splitext(img_file)
                    
                    # ä¿å­˜å›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½•
                    temp_dir = "temp_images"
                    os.makedirs(temp_dir, exist_ok=True)
                    
                    img_filename = f"image_{len(images)+1}{ext}"
                    img_path = os.path.join(temp_dir, img_filename)
                    
                    with open(img_path, 'wb') as f:
                        f.write(img_data)
                    
                    images.append({
                        'filename': img_filename,
                        'path': img_path,
                        'size': len(img_data),
                        'format': ext[1:].upper()
                    })
                    
                    logger.info(f"ğŸ’¾ ä¿å­˜å›¾ç‰‡: {img_filename} ({len(img_data)} bytes)")
                    
                except Exception as e:
                    logger.warning(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {img_file}: {e}")
                    continue
                    
    except Exception as e:
        logger.error(f"æå–å›¾ç‰‡å¤±è´¥: {e}")
        
    return images

def extract_with_xml_parser(docx_path: str):
    """ä½¿ç”¨åŸºç¡€XMLè§£æå™¨æå–å†…å®¹"""
    try:
        logger.info("ä½¿ç”¨åŸºç¡€XMLè§£æå™¨...")
        
        content = {
            'title': os.path.splitext(os.path.basename(docx_path))[0],
            'paragraphs': [],
            'images': [],
            'tables': [],
            'full_text': ''
        }
        
        with zipfile.ZipFile(docx_path, 'r') as zip_file:
            # è¯»å–ä¸»æ–‡æ¡£
            try:
                doc_xml = zip_file.read('word/document.xml')
                root = ET.fromstring(doc_xml)
                
                # å®šä¹‰å‘½åç©ºé—´
                namespaces = {
                    'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'
                }
                
                # æå–æ®µè½
                paragraphs = root.findall('.//w:p', namespaces)
                
                for para in paragraphs:
                    text_elements = para.findall('.//w:t', namespaces)
                    para_text = ''.join(elem.text or '' for elem in text_elements)
                    
                    if para_text.strip():
                        content['paragraphs'].append({
                            'text': para_text.strip(),
                            'style': 'Normal'
                        })
                
                # åˆå¹¶æ–‡æœ¬
                content['full_text'] = '\n\n'.join(para['text'] for para in content['paragraphs'])
                
                # æå–å›¾ç‰‡
                content['images'] = extract_images_from_docx(docx_path)
                
                logger.success(f"âœ… XMLè§£æå®Œæˆ:")
                logger.info(f"ğŸ“„ æ®µè½æ•°: {len(content['paragraphs'])}")
                logger.info(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°: {len(content['images'])}")
                logger.info(f"ğŸ“ æ€»å­—ç¬¦æ•°: {len(content['full_text'])}")
                
                return content
                
            except Exception as e:
                logger.error(f"XMLè§£æå¤±è´¥: {e}")
                return None
                
    except Exception as e:
        logger.error(f"åŸºç¡€XMLè§£æå¤±è´¥: {e}")
        return None

def save_content_for_copy(content, output_file="docx_content_for_copy.md"):
    """å°†æå–çš„å†…å®¹ä¿å­˜ä¸ºMarkdownæ ¼å¼ï¼Œä¾¿äºå¤åˆ¶"""
    try:
        logger.info(f"ğŸ’¾ ä¿å­˜å†…å®¹åˆ°: {output_file}")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"# {content['title']}\n\n")
            f.write("---\n\n")
            
            # å†™å…¥æ®µè½å†…å®¹
            if content['paragraphs']:
                f.write("## æ–‡æ¡£å†…å®¹\n\n")
                for para in content['paragraphs']:
                    f.write(f"{para['text']}\n\n")
            
            # å†™å…¥è¡¨æ ¼
            if content['tables']:
                f.write("## è¡¨æ ¼å†…å®¹\n\n")
                for table_idx, table in enumerate(content['tables']):
                    f.write(f"### è¡¨æ ¼ {table_idx + 1}\n\n")
                    
                    if table['data']:
                        # å†™å…¥è¡¨æ ¼å¤´
                        headers = table['data'][0]
                        f.write("| " + " | ".join(headers) + " |\n")
                        f.write("| " + " | ".join(["---"] * len(headers)) + " |\n")
                        
                        # å†™å…¥è¡¨æ ¼æ•°æ®
                        for row in table['data'][1:]:
                            f.write("| " + " | ".join(row) + " |\n")
                        f.write("\n")
            
            # å†™å…¥å›¾ç‰‡ä¿¡æ¯
            if content['images']:
                f.write("## å›¾ç‰‡ä¿¡æ¯\n\n")
                f.write("ä»¥ä¸‹å›¾ç‰‡å·²ä¿å­˜åˆ° temp_images æ–‡ä»¶å¤¹ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶åˆ°é£ä¹¦ä¸­ï¼š\n\n")
                
                for img in content['images']:
                    f.write(f"- **{img['filename']}** ({img['format']}, {img['size']} bytes)\n")
                    f.write(f"  - è·¯å¾„: `{img['path']}`\n\n")
        
        logger.success(f"âœ… å†…å®¹å·²ä¿å­˜åˆ°: {output_file}")
        logger.info("ğŸ“‹ æ‚¨å¯ä»¥æ‰“å¼€æ­¤æ–‡ä»¶å¤åˆ¶å†…å®¹åˆ°é£ä¹¦çŸ¥è¯†åº“ä¸­")
        
        return output_file
        
    except Exception as e:
        logger.error(f"ä¿å­˜å†…å®¹å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("DOCXå†…å®¹æå–å·¥å…·")
    logger.info("=" * 60)
    
    # æŸ¥æ‰¾DOCXæ–‡ä»¶
    docx_path = "output/auto_download/æ›´æ–°å…¬å‘Š.docx"
    
    if not os.path.exists(docx_path):
        logger.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {docx_path}")
        
        # åˆ—å‡ºå¯ç”¨æ–‡ä»¶
        auto_download_dir = "output/auto_download"
        if os.path.exists(auto_download_dir):
            files = [f for f in os.listdir(auto_download_dir) if f.endswith('.docx')]
            if files:
                logger.info("ğŸ“ å¯ç”¨çš„DOCXæ–‡ä»¶:")
                for f in files:
                    logger.info(f"  - {f}")
                
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„DOCXæ–‡ä»¶
                docx_path = os.path.join(auto_download_dir, files[0])
                logger.info(f"ğŸ“– ä½¿ç”¨æ–‡ä»¶: {docx_path}")
            else:
                logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•DOCXæ–‡ä»¶")
                return
        else:
            logger.error("âŒ auto_downloadç›®å½•ä¸å­˜åœ¨")
            return
    
    # æå–å†…å®¹
    content = extract_docx_content(docx_path)
    
    if content:
        # ä¿å­˜ä¸ºä¾¿äºå¤åˆ¶çš„æ ¼å¼
        output_file = save_content_for_copy(content)
        
        if output_file:
            logger.info("\n" + "=" * 60)
            logger.success("ğŸ‰ å†…å®¹æå–å®Œæˆï¼")
            logger.info("ğŸ“‹ å¤åˆ¶æ­¥éª¤:")
            logger.info("1. æ‰“å¼€ç”Ÿæˆçš„Markdownæ–‡ä»¶æŸ¥çœ‹å†…å®¹")
            logger.info(f"2. å¤åˆ¶æ–‡æœ¬å†…å®¹åˆ°é£ä¹¦çŸ¥è¯†åº“: https://thedream.feishu.cn/wiki/R8mSwJ48piDjMwkk0I0cfISNnqb")
            logger.info("3. æ‰‹åŠ¨ä¸Šä¼  temp_images æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡åˆ°é£ä¹¦")
            logger.info("=" * 60)
    else:
        logger.error("âŒ å†…å®¹æå–å¤±è´¥")

if __name__ == "__main__":
    main() 