#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…·GUIç•Œé¢
ç®€æ´ç‰ˆæœ¬ï¼šæ”¯æŒå•ç¯‡ä¸‹è½½å’Œå¤šURLæ‰¹é‡ä¸‹è½½
"""

import tkinter as tk
from tkinter import ttk, scrolledtext, filedialog, messagebox
import threading
import queue
import os
import webbrowser
import re
from datetime import datetime
from loguru import logger
import sys
import json

# å¯¼å…¥æˆ‘ä»¬çš„å·¥å…·ç±»
from simple_url_scraper import SimpleUrlScraper

# ğŸ†• å¯¼å…¥é“¾æ¥æ”¶é›†å™¨
from wechat_article_link_collector import WeChatLinkCollector

# ğŸ†• åˆ›å»ºç®€åŒ–çš„é“¾æ¥æ”¶é›†å™¨ç±»ï¼ˆæ— GUIç‰ˆæœ¬ï¼‰
class SimplifiedLinkCollector:
    """ç®€åŒ–ç‰ˆé“¾æ¥æ”¶é›†å™¨ï¼Œä¸“é—¨ç”¨äºé›†æˆåˆ°ä¸»GUIä¸­"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        import requests
        self.session = requests.Session()
        self.token = ""
        self.cookies = {}
        self.user_info = {}
        self.session_id = ""
        
        # é¢‘ç‡æ§åˆ¶
        self.request_interval = 2.0
        self.last_request_time = 0
        
        # æ•°æ®å­˜å‚¨
        self.collected_articles = []
        self.current_account = None
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://mp.weixin.qq.com/',
            'Origin': 'https://mp.weixin.qq.com'
        }
        self.session.headers.update(headers)
    
    def _wait_for_rate_limit(self):
        """ç­‰å¾…ä»¥é¿å…è§¦å‘é¢‘ç‡é™åˆ¶"""
        import time
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.request_interval:
            wait_time = self.request_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def start_login_flow(self):
        """å¯åŠ¨ç™»å½•æµç¨‹å¹¶æ˜¾ç¤ºäºŒç»´ç """
        try:
            import time
            import base64
            import tempfile
            import webbrowser
            
            # å¯åŠ¨ç™»å½•ä¼šè¯
            self.session_id = str(int(time.time() * 1000)) + str(int(time.time() * 100) % 100)
            
            start_url = "https://mp.weixin.qq.com/cgi-bin/bizlogin"
            start_data = {
                'action': 'startlogin',
                'userlang': 'zh_CN',
                'redirect_url': '',
                'login_type': '3',
                'sessionid': self.session_id,
                'token': '',
                'lang': 'zh_CN',
                'f': 'json',
                'ajax': '1'
            }
            
            response = self.session.post(start_url, data=start_data)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('base_resp', {}).get('ret') == 0:
                    # è·å–å¹¶æ˜¾ç¤ºäºŒç»´ç 
                    return self._show_qrcode_and_wait()
            
            return False
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ç™»å½•å¤±è´¥: {e}")
            return False
    
    def _show_qrcode_and_wait(self):
        """æ˜¾ç¤ºäºŒç»´ç å¹¶ç­‰å¾…æ‰«ç """
        try:
            import time
            import base64
            import tempfile
            import webbrowser
            
            # è·å–äºŒç»´ç 
            qr_url = f"https://mp.weixin.qq.com/cgi-bin/scanloginqrcode?action=getqrcode&random={int(time.time())}"
            response = self.session.get(qr_url)
            
            if response.status_code == 200 and response.content:
                # ç”ŸæˆäºŒç»´ç HTMLé¡µé¢
                qr_base64 = base64.b64encode(response.content).decode('utf-8')
                html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ROè‡ªåŠ¨æ›´æ–° - å¾®ä¿¡å…¬ä¼—å·ç™»å½•</title>
    <style>
        body {{ font-family: Arial, sans-serif; text-align: center; padding: 50px; background-color: #f5f5f5; }}
        .container {{ background: white; border-radius: 10px; padding: 30px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); display: inline-block; }}
        h1 {{ color: #333; margin-bottom: 20px; }}
        .qr-code {{ margin: 20px 0; padding: 20px; border: 2px solid #eee; border-radius: 10px; }}
        .qr-code img {{ width: 200px; height: 200px; }}
        .instructions {{ color: #666; font-size: 16px; margin-top: 20px; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤– ROè‡ªåŠ¨æ›´æ–° - å¾®ä¿¡ç™»å½•</h1>
        <div class="qr-code">
            <img src="data:image/png;base64,{qr_base64}" alt="å¾®ä¿¡ç™»å½•äºŒç»´ç " />
        </div>
        <div class="instructions">
            ğŸ“± è¯·ä½¿ç”¨å¾®ä¿¡æ‰«æä¸Šæ–¹äºŒç»´ç ç™»å½•<br>
            éœ€è¦æœ‰å…¬ä¼—å·ç®¡ç†æƒé™çš„å¾®ä¿¡è´¦å·<br><br>
            ğŸ¤– ç™»å½•æˆåŠŸåå°†è‡ªåŠ¨å¼€å§‹ROæ–‡ç« æ›´æ–°æµç¨‹
        </div>
    </div>
</body>
</html>
"""
                
                # ä¿å­˜å¹¶æ‰“å¼€HTMLæ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(html_content)
                    temp_html_path = f.name
                
                webbrowser.open(f'file://{os.path.abspath(temp_html_path)}')
                
                # å¼€å§‹æ£€æŸ¥ç™»å½•çŠ¶æ€
                return self._wait_for_login()
            
            return False
            
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºäºŒç»´ç å¤±è´¥: {e}")
            return False
    
    def _wait_for_login(self):
        """ç­‰å¾…ç™»å½•å®Œæˆ"""
        try:
            import time
            
            for i in range(120):  # ç­‰å¾…æœ€å¤š2åˆ†é’Ÿ
                try:
                    scan_url = "https://mp.weixin.qq.com/cgi-bin/scanloginqrcode"
                    params = {
                        'action': 'ask',
                        'token': '',
                        'lang': 'zh_CN',
                        'f': 'json',
                        'ajax': '1'
                    }
                    
                    response = self.session.get(scan_url, params=params)
                    
                    if response.status_code == 200:
                        result = response.json()
                        
                        if result.get('base_resp', {}).get('ret') == 0:
                            status = result.get('status', 0)
                            
                            if status == 1:
                                # ç™»å½•æˆåŠŸ
                                return self._complete_login()
                            elif status == 2:
                                # äºŒç»´ç è¿‡æœŸ
                                return False
                            elif status == 3:
                                # å–æ¶ˆç™»å½•
                                return False
                    
                    time.sleep(1)
                    
                except Exception as e:
                    logger.warning(f"æ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥: {e}")
                    time.sleep(1)
            
            return False  # è¶…æ—¶
            
        except Exception as e:
            logger.error(f"ç­‰å¾…ç™»å½•å¤±è´¥: {e}")
            return False
    
    def _complete_login(self):
        """å®Œæˆç™»å½•"""
        try:
            from urllib.parse import urlparse, parse_qs
            
            login_url = "https://mp.weixin.qq.com/cgi-bin/bizlogin"
            login_data = {
                'action': 'login',
                'userlang': 'zh_CN',
                'redirect_url': '',
                'cookie_forbidden': 0,
                'cookie_cleaned': 0,
                'plugin_used': 0,
                'login_type': 3,
                'token': '',
                'lang': 'zh_CN',
                'f': 'json',
                'ajax': 1
            }
            
            response = self.session.post(login_url, data=login_data)
            
            if response.status_code == 200:
                result = response.json()
                redirect_url = result.get('redirect_url', '')
                
                if redirect_url:
                    # æå–token
                    parsed_url = urlparse(f"http://localhost{redirect_url}")
                    self.token = parse_qs(parsed_url.query).get('token', [''])[0]
                    
                    if self.token:
                        self.cookies = dict(self.session.cookies)
                        return True
            
            return False
            
        except Exception as e:
            logger.error(f"å®Œæˆç™»å½•å¤±è´¥: {e}")
            return False
    
    def search_account(self, keyword):
        """æœç´¢å…¬ä¼—å·"""
        try:
            if not self.token:
                return []
            
            self._wait_for_rate_limit()
            
            search_url = "https://mp.weixin.qq.com/cgi-bin/searchbiz"
            params = {
                'action': 'search_biz',
                'begin': 0,
                'count': 10,
                'query': keyword,
                'token': self.token,
                'lang': 'zh_CN',
                'f': 'json',
                'ajax': 1
            }
            
            response = self.session.get(search_url, params=params)
            
            if response.status_code == 200:
                result = response.json()
                
                if result.get('base_resp', {}).get('ret') == 0:
                    accounts = result.get('list', [])
                    
                    # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªç»“æœ
                    if accounts:
                        self.current_account = accounts[0]
                    
                    return accounts
            
            return []
            
        except Exception as e:
            logger.error(f"æœç´¢è´¦å·å¤±è´¥: {e}")
            return []
    
    def collect_articles(self, limit, start_date, end_date):
        """æ”¶é›†æ–‡ç« """
        try:
            if not self.current_account:
                return []
            
            import json
            from datetime import datetime, timedelta
            
            fakeid = self.current_account.get('fakeid', '')
            if not fakeid:
                return []
            
            collected_count = 0
            begin = 0
            page_size = 20
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_timestamp = int(start_date.timestamp())
            end_timestamp = int((end_date + timedelta(days=1) - timedelta(seconds=1)).timestamp())
            
            # æ”¶é›†ç¬¦åˆæ—¶é—´èŒƒå›´çš„æ–‡ç« 
            filtered_articles = []
            
            while collected_count < limit:
                self._wait_for_rate_limit()
                
                articles_url = "https://mp.weixin.qq.com/cgi-bin/appmsgpublish"
                params = {
                    'sub': 'list',
                    'search_field': 'null',
                    'begin': begin,
                    'count': page_size,
                    'query': '',
                    'fakeid': fakeid,
                    'type': '101_1',
                    'free_publish_type': 1,
                    'sub_action': 'list_ex',
                    'token': self.token,
                    'lang': 'zh_CN',
                    'f': 'json',
                    'ajax': 1
                }
                
                response = self.session.get(articles_url, params=params)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if result.get('base_resp', {}).get('ret') == 0:
                        # è§£ææ–‡ç« åˆ—è¡¨
                        articles = self._parse_articles_from_response(result)
                        
                        if not articles:
                            break
                        
                        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ç« éƒ½æ—©äºèµ·å§‹æ—¶é—´
                        first_article_time = articles[0].get('update_time', 0) if articles else 0
                        if first_article_time < start_timestamp:
                            break
                        
                        # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ–‡ç« 
                        for article in articles:
                            article_time = article.get('update_time', 0)
                            
                            if article_time < start_timestamp:
                                continue
                            
                            if article_time > end_timestamp:
                                continue
                            
                            # æ„å»ºæ–‡ç« ä¿¡æ¯
                            article_info = {
                                'title': article.get('title', ''),
                                'link': article.get('link', '').replace('\\/', '/'),
                                'author': article.get('author_name', ''),
                                'publish_time': datetime.fromtimestamp(article.get('update_time', 0)).strftime('%Y-%m-%d %H:%M:%S'),
                                'account_name': self.current_account.get('nickname', ''),
                                'account_alias': self.current_account.get('alias', ''),
                                'digest': article.get('digest', '')
                            }
                            filtered_articles.append(article_info)
                            collected_count += 1
                            
                            if collected_count >= limit:
                                break
                        
                        begin += page_size
                    else:
                        break
                else:
                    break
            
            # æŒ‰æ—¶é—´å€’åºæ’åº
            filtered_articles.sort(key=lambda x: x.get('publish_time', ''), reverse=True)
            
            self.collected_articles = filtered_articles
            return filtered_articles
            
        except Exception as e:
            logger.error(f"æ”¶é›†æ–‡ç« å¤±è´¥: {e}")
            return []
    
    def _parse_articles_from_response(self, result):
        """ä»APIå“åº”ä¸­è§£ææ–‡ç« åˆ—è¡¨"""
        articles = []
        
        try:
            import json
            
            publish_page_str = result.get('publish_page', '')
            if not publish_page_str:
                return articles
            
            publish_page = json.loads(publish_page_str)
            publish_list = publish_page.get('publish_list', [])
            
            for publish_item in publish_list:
                publish_info_str = publish_item.get('publish_info', '')
                if not publish_info_str:
                    continue
                
                publish_info = json.loads(publish_info_str)
                appmsgex_list = publish_info.get('appmsgex', [])
                
                for appmsg in appmsgex_list:
                    article = {
                        'title': appmsg.get('title', ''),
                        'link': appmsg.get('link', ''),
                        'author_name': appmsg.get('author_name', ''),
                        'digest': appmsg.get('digest', ''),
                        'update_time': appmsg.get('update_time', 0),
                        'create_time': appmsg.get('create_time', 0)
                    }
                    articles.append(article)
            
        except Exception as e:
            logger.warning(f"è§£ææ–‡ç« åˆ—è¡¨å‡ºé”™: {e}")
        
        return articles


class WechatDownloaderGUI:
    """å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…·GUI"""
    
    def __init__(self, root):
        """åˆå§‹åŒ–GUI"""
        self.root = root
        self.root.title("å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…· v4.0 - å…¨è‡ªåŠ¨åŒ–ç‰ˆ")
        self.root.geometry("800x700")
        self.root.resizable(True, True)
        
        # ğŸ†• ä¼˜å…ˆåˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—ï¼Œé¿å…æ—¥å¿—è°ƒç”¨å‡ºé”™
        self.msg_queue = queue.Queue()
        
        # è®¾ç½®å›¾æ ‡å’Œæ ·å¼
        self.setup_styles()
        
        # åˆå§‹åŒ–å·¥å…·ç±»ï¼ˆæ‡’åŠ è½½ï¼‰
        self.url_scraper = None
        self.scraper_initializing = False  # é˜²æ­¢é‡å¤åˆå§‹åŒ–
        
        # é£ä¹¦APIé…ç½®
        self.feishu_app_id = "cli_a8c822312a75901c"
        self.feishu_app_secret = "NDbCyKEwEIA8CZo2KHyqueIOlcafErko"
        self.feishu_space_id = "7511922459407450115"  # æ•°å­—æ ¼å¼çš„space_id
        self.feishu_client = None
        self.enable_feishu_upload = True  # æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦
        
        # çŸ¥è¯†åº“åˆ†ç±»é…ç½®
        self.wiki_locations = []  # å­˜å‚¨å…³é”®è¯-é“¾æ¥æ˜ å°„
        self.default_wiki_location = ""  # é»˜è®¤è½¬ç§»ä½ç½®
        
        # ğŸ†• é“¾æ¥æ”¶é›†å™¨ç›¸å…³
        self.link_collector = None
        
        # ğŸ†• ROè‡ªåŠ¨æ›´æ–°ç›¸å…³
        self.auto_update_enabled = False
        self.last_update_date = "2025-06-10"  # çŸ¥è¯†åº“å·²æœ‰æ–‡ç« çš„æœ€åæ—¥æœŸ
        self.ro_account_info = None  # ROå…¬ä¼—å·ä¿¡æ¯
        self.auto_update_status = ""
        
        # å®šæ—¶å™¨ç›¸å…³
        self.timer_enabled = False
        self.timer_interval = 60  # é»˜è®¤60åˆ†é’Ÿ
        self.timer_job_id = None  # å®šæ—¶å™¨ä»»åŠ¡ID
        self.next_update_time = None
        
        # GUIçŠ¶æ€
        self.is_downloading = False
        self.output_dir = "output"
        
        # è‡ªåŠ¨æ”¶é›†å’Œä¸‹è½½ç›¸å…³çŠ¶æ€
        self.is_auto_collecting = False
        self.last_clipboard_content = ""
        self.collected_urls = set()  # ç”¨äºå»é‡
        
        # è‡ªåŠ¨ä¸‹è½½é˜Ÿåˆ—
        self.download_queue = queue.Queue()  # ä¸‹è½½é˜Ÿåˆ—
        self.is_queue_processing = False     # é˜Ÿåˆ—å¤„ç†çŠ¶æ€
        self.current_downloading_url = None  # å½“å‰ä¸‹è½½çš„URL
        self.queue_stats = {"completed": 0, "failed": 0, "total": 0}
        
        # è‡ªåŠ¨ä¸‹è½½æ ¼å¼è®¾ç½®
        self.auto_download_format = "pdf"  # é»˜è®¤PDFæ ¼å¼
        
        # ğŸ†• ç°åœ¨å¯ä»¥å®‰å…¨åœ°åˆå§‹åŒ–çŸ¥è¯†åº“é…ç½®ï¼ˆä¼šç”¨åˆ°æ—¥å¿—ï¼‰
        self.init_default_wiki_config()
        
        # åˆ›å»ºGUIç•Œé¢
        self.create_widgets()
        
        # åŠ è½½è‡ªåŠ¨æ›´æ–°è®¾ç½®
        self.load_auto_update_settings()
        
        # å¯åŠ¨æ¶ˆæ¯å¤„ç†
        self.process_queue()
        
        logger.info("å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…·GUIåˆå§‹åŒ–å®Œæˆ")
    
    def setup_styles(self):
        """è®¾ç½®GUIæ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
        
        # é…ç½®æ ·å¼
        style.configure('Title.TLabel', font=('Arial', 16, 'bold'))
        style.configure('Header.TLabel', font=('Arial', 12, 'bold'))
        style.configure('Success.TLabel', foreground='green')
        style.configure('Error.TLabel', foreground='red')
    
    def create_widgets(self):
        """åˆ›å»ºGUIç»„ä»¶"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®ç½‘æ ¼æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="ğŸš€ å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…·", style='Title.TLabel')
        title_label.grid(row=0, column=0, columnspan=3, pady=(0, 20))
        
        # åˆ›å»ºé€‰é¡¹å¡
        notebook = ttk.Notebook(main_frame)
        notebook.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        main_frame.rowconfigure(1, weight=1)
        
        # å•ç¯‡ä¸‹è½½é€‰é¡¹å¡
        self.create_single_download_tab(notebook)
        
        # æ‰¹é‡ä¸‹è½½é€‰é¡¹å¡
        self.create_batch_download_tab(notebook)
        
        # ğŸ†• é“¾æ¥æ”¶é›†å™¨é€‰é¡¹å¡
        self.create_link_collector_tab(notebook)
        
        # ğŸ†• ROæ–‡ç« è‡ªåŠ¨æ›´æ–°é€‰é¡¹å¡
        self.create_auto_update_tab(notebook)
        
        # è®¾ç½®é€‰é¡¹å¡
        self.create_settings_tab(notebook)
        
        # æ—¥å¿—è¾“å‡ºåŒºåŸŸ
        self.create_log_area(main_frame)
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_bar(main_frame)
    
    def create_link_collector_tab(self, parent):
        """åˆ›å»ºé“¾æ¥æ”¶é›†å™¨é€‰é¡¹å¡"""
        frame = ttk.Frame(parent, padding="10")
        parent.add(frame, text="ğŸ”— é“¾æ¥æ”¶é›†å™¨")
        
        # è¯´æ˜æ–‡å­—
        info_text = """
ğŸ”— å¾®ä¿¡å…¬ä¼—å·é“¾æ¥æ”¶é›†å™¨ï¼š
â€¢ æ‰«ç ç™»å½•å¾®ä¿¡å…¬ä¼—å·åå°
â€¢ æœç´¢å¹¶é€‰æ‹©ç›®æ ‡å…¬ä¼—å·
â€¢ è®¾ç½®æ—¶é—´èŒƒå›´ï¼Œæ‰¹é‡è·å–æ–‡ç« é“¾æ¥
â€¢ æ”¯æŒå¯¼å‡ºCSVã€JSONã€TXTæ ¼å¼
â€¢ å¯ç›´æ¥ä¸ä¸‹è½½åŠŸèƒ½é…åˆä½¿ç”¨
        """
        ttk.Label(frame, text=info_text.strip(), justify=tk.LEFT).grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 15))
        
        # ç™»å½•åŒºåŸŸ
        login_frame = ttk.LabelFrame(frame, text="ğŸ” å¾®ä¿¡å…¬ä¼—å·ç™»å½•", padding="10")
        login_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        login_frame.columnconfigure(1, weight=1)
        
        # ç™»å½•çŠ¶æ€
        self.collector_login_status_var = tk.StringVar(value="æœªç™»å½•")
        ttk.Label(login_frame, text="ç™»å½•çŠ¶æ€:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.collector_login_status_label = ttk.Label(login_frame, textvariable=self.collector_login_status_var, 
                                                     foreground="red")
        self.collector_login_status_label.grid(row=0, column=1, sticky=tk.W)
        
        # ç™»å½•æŒ‰é’®
        collector_login_buttons = ttk.Frame(login_frame)
        collector_login_buttons.grid(row=0, column=2)
        
        self.collector_login_btn = ttk.Button(collector_login_buttons, text="ğŸš€ å¼€å§‹ç™»å½•", 
                                            command=self.start_collector_login)
        self.collector_login_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        ttk.Button(collector_login_buttons, text="ğŸ”„ é‡æ–°ç™»å½•", 
                  command=self.retry_collector_login).pack(side=tk.LEFT)
        
        # æœç´¢åŒºåŸŸ
        search_frame = ttk.LabelFrame(frame, text="ğŸ” æœç´¢å…¬ä¼—å·", padding="10")
        search_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        search_frame.columnconfigure(1, weight=1)
        
        ttk.Label(search_frame, text="æœç´¢å…³é”®è¯:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.collector_search_var = tk.StringVar()
        self.collector_search_entry = ttk.Entry(search_frame, textvariable=self.collector_search_var, width=30)
        self.collector_search_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 10))
        
        self.collector_search_btn = ttk.Button(search_frame, text="ğŸ” æœç´¢", 
                                             command=self.search_collector_accounts)
        self.collector_search_btn.grid(row=0, column=2)
        
        # æœç´¢ç»“æœæ˜¾ç¤º
        result_frame = ttk.Frame(search_frame)
        result_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(10, 0))
        result_frame.columnconfigure(0, weight=1)
        result_frame.rowconfigure(0, weight=1)
        search_frame.rowconfigure(1, weight=1)
        
        # ç®€åŒ–çš„æœç´¢ç»“æœæ˜¾ç¤º
        self.collector_results_text = scrolledtext.ScrolledText(result_frame, height=5, width=80)
        self.collector_results_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ”¶é›†è®¾ç½®åŒºåŸŸ
        collect_frame = ttk.LabelFrame(frame, text="ğŸ“¥ æ–‡ç« æ”¶é›†è®¾ç½®", padding="10")
        collect_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        collect_frame.columnconfigure(1, weight=1)
        
        # é€‰ä¸­çš„å…¬ä¼—å·
        ttk.Label(collect_frame, text="é€‰ä¸­å…¬ä¼—å·:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.collector_selected_var = tk.StringVar(value="æœªé€‰æ‹©")
        ttk.Label(collect_frame, textvariable=self.collector_selected_var, 
                 foreground="blue").grid(row=0, column=1, sticky=tk.W)
        
        # æ”¶é›†å‚æ•°
        params_frame = ttk.Frame(collect_frame)
        params_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(10, 0))
        
        # æ•°é‡é™åˆ¶
        ttk.Label(params_frame, text="è·å–æ•°é‡:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.collector_limit_var = tk.StringVar(value="50")
        ttk.Entry(params_frame, textvariable=self.collector_limit_var, width=10).grid(row=0, column=1, padx=(0, 20))
        
        # æ—¥æœŸèŒƒå›´
        ttk.Label(params_frame, text="èµ·å§‹æ—¥æœŸ:").grid(row=0, column=2, sticky=tk.W, padx=(0, 10))
        self.collector_start_date_var = tk.StringVar(value="2025-06-01")
        ttk.Entry(params_frame, textvariable=self.collector_start_date_var, width=12).grid(row=0, column=3, padx=(0, 20))
        
        ttk.Label(params_frame, text="ç»“æŸæ—¥æœŸ:").grid(row=0, column=4, sticky=tk.W, padx=(0, 10))
        self.collector_end_date_var = tk.StringVar(value="2025-06-11")
        ttk.Entry(params_frame, textvariable=self.collector_end_date_var, width=12).grid(row=0, column=5, padx=(0, 20))
        
        # æ“ä½œæŒ‰é’®
        collect_buttons = ttk.Frame(collect_frame)
        collect_buttons.grid(row=2, column=0, columnspan=3, pady=(10, 0))
        
        self.collector_collect_btn = ttk.Button(collect_buttons, text="ğŸ“¥ æ”¶é›†é“¾æ¥", 
                                              command=self.start_collect_links)
        self.collector_collect_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(collect_buttons, text="ğŸ“‹ å¯¼å‡ºåˆ°æ‰¹é‡ä¸‹è½½", 
                  command=self.export_to_batch_download).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(collect_buttons, text="ğŸ“„ å¯¼å‡ºCSV", 
                  command=self.export_collector_csv).pack(side=tk.LEFT, padx=(0, 5))
        
        ttk.Button(collect_buttons, text="ğŸ—‘ï¸ æ¸…ç©º", 
                  command=self.clear_collector_data).pack(side=tk.LEFT)
        
        # æ”¶é›†è¿›åº¦å’ŒçŠ¶æ€
        self.collector_progress_var = tk.StringVar(value="")
        ttk.Label(collect_frame, textvariable=self.collector_progress_var).grid(row=3, column=0, columnspan=3, 
                                                                               sticky=tk.W, pady=(10, 0))
        
        self.collector_stats_var = tk.StringVar(value="å·²æ”¶é›†: 0 ç¯‡æ–‡ç« ")
        ttk.Label(collect_frame, textvariable=self.collector_stats_var, 
                 font=("Arial", 12, "bold")).grid(row=4, column=0, columnspan=3, sticky=tk.W, pady=(5, 0))
        
        # å­˜å‚¨æ”¶é›†çš„æ•°æ®
        self.collected_articles = []
    
    def create_auto_update_tab(self, parent):
        """åˆ›å»ºROæ–‡ç« è‡ªåŠ¨æ›´æ–°é€‰é¡¹å¡"""
        frame = ttk.Frame(parent, padding="10")
        parent.add(frame, text="ğŸ¤– ROè‡ªåŠ¨æ›´æ–°")
        
        # è¯´æ˜æ–‡å­—
        info_text = """
ğŸ¤– ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª - è‡ªåŠ¨æ–‡ç« æ›´æ–°ï¼š
â€¢ è‡ªåŠ¨ç™»å½•å¾®ä¿¡å…¬ä¼—å·åå°
â€¢ è‡ªåŠ¨æœç´¢"ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª"å…¬ä¼—å·
â€¢ æ ¹æ®æ—¥æœŸå¢é‡æ›´æ–°æœ€æ–°æ–‡ç« åˆ°çŸ¥è¯†åº“
â€¢ é˜²æ¼æ£€æŸ¥ï¼šæ£€æŸ¥å‰3ä¸ªèŠ‚ç‚¹ç¡®ä¿æ— é—æ¼
â€¢ è‡ªåŠ¨è®°å½•æ›´æ–°è¿›åº¦ï¼Œä¸‹æ¬¡ç»§ç»­
        """
        ttk.Label(frame, text=info_text.strip(), justify=tk.LEFT).grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 15))
        
        # è‡ªåŠ¨æ›´æ–°å¼€å…³
        auto_switch_frame = ttk.LabelFrame(frame, text="ğŸ”§ è‡ªåŠ¨æ›´æ–°è®¾ç½®", padding="10")
        auto_switch_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        auto_switch_frame.columnconfigure(1, weight=1)
        
        self.auto_update_enabled_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(auto_switch_frame, text="å¯ç”¨ROæ–‡ç« è‡ªåŠ¨æ›´æ–°", 
                       variable=self.auto_update_enabled_var, 
                       command=self.toggle_auto_update).grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # å®šæ—¶æ›´æ–°è®¾ç½®
        timer_frame = ttk.Frame(auto_switch_frame)
        timer_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E))
        timer_frame.columnconfigure(2, weight=1)
        
        self.timer_enabled_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(timer_frame, text="å¯ç”¨å®šæ—¶è‡ªåŠ¨æ›´æ–°", 
                       variable=self.timer_enabled_var, 
                       command=self.toggle_timer_update).grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        
        ttk.Label(timer_frame, text="é—´éš”:").grid(row=0, column=1, sticky=tk.W, padx=(10, 5))
        
        self.timer_interval_var = tk.StringVar(value="60")
        interval_entry = ttk.Entry(timer_frame, textvariable=self.timer_interval_var, width=8)
        interval_entry.grid(row=0, column=2, sticky=tk.W, padx=(0, 5))
        interval_entry.bind('<KeyRelease>', self.on_timer_interval_changed)
        
        ttk.Label(timer_frame, text="åˆ†é’Ÿ").grid(row=0, column=3, sticky=tk.W, padx=(0, 10))
        
        # ä¸‹æ¬¡æ›´æ–°æ—¶é—´æ˜¾ç¤º
        self.next_update_time_var = tk.StringVar(value="å®šæ—¶å™¨æœªå¯åŠ¨")
        ttk.Label(timer_frame, text="ä¸‹æ¬¡æ›´æ–°:").grid(row=0, column=4, sticky=tk.W, padx=(10, 5))
        ttk.Label(timer_frame, textvariable=self.next_update_time_var, 
                 foreground="blue").grid(row=0, column=5, sticky=tk.W)
        
        # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
        status_frame = ttk.LabelFrame(frame, text="ğŸ“Š æ›´æ–°çŠ¶æ€", padding="10")
        status_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        status_frame.columnconfigure(1, weight=1)
        
        # ä¸Šæ¬¡æ›´æ–°æ—¥æœŸ
        ttk.Label(status_frame, text="ä¸Šæ¬¡æ›´æ–°è‡³:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.last_update_date_var = tk.StringVar(value=self.last_update_date)
        ttk.Label(status_frame, textvariable=self.last_update_date_var, 
                 foreground="blue").grid(row=0, column=1, sticky=tk.W)
        
        # å½“å‰çŠ¶æ€
        ttk.Label(status_frame, text="å½“å‰çŠ¶æ€:").grid(row=1, column=0, sticky=tk.W, padx=(0, 10))
        self.auto_update_status_var = tk.StringVar(value="ç­‰å¾…å¯åŠ¨")
        ttk.Label(status_frame, textvariable=self.auto_update_status_var, 
                 foreground="green").grid(row=1, column=1, sticky=tk.W)
        
        # ROå…¬ä¼—å·ä¿¡æ¯
        ttk.Label(status_frame, text="ç›®æ ‡å…¬ä¼—å·:").grid(row=2, column=0, sticky=tk.W, padx=(0, 10))
        self.ro_account_status_var = tk.StringVar(value="ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª (æœªæœç´¢)")
        ttk.Label(status_frame, textvariable=self.ro_account_status_var, 
                 foreground="orange").grid(row=2, column=1, sticky=tk.W)
        
        # æ‰‹åŠ¨æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.LabelFrame(frame, text="ğŸ® æ‰‹åŠ¨æ§åˆ¶", padding="10")
        control_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        control_buttons = ttk.Frame(control_frame)
        control_buttons.grid(row=0, column=0)
        
        self.manual_update_btn = ttk.Button(control_buttons, text="ğŸš€ ç«‹å³æ‰§è¡Œæ›´æ–°", 
                                          command=self.start_manual_update)
        self.manual_update_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(control_buttons, text="ğŸ” æµ‹è¯•ROå…¬ä¼—å·æœç´¢", 
                  command=self.test_ro_account_search).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(control_buttons, text="ğŸ“… é‡ç½®æ›´æ–°æ—¥æœŸ", 
                  command=self.reset_update_date).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(control_buttons, text="ğŸ“‹ æŸ¥çœ‹æ›´æ–°æ—¥å¿—", 
                  command=self.view_update_log).pack(side=tk.LEFT)
        
        # æ›´æ–°è¿›åº¦
        progress_frame = ttk.LabelFrame(frame, text="ğŸ“ˆ æ›´æ–°è¿›åº¦", padding="10")
        progress_frame.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        progress_frame.columnconfigure(0, weight=1)
        progress_frame.rowconfigure(0, weight=1)
        frame.rowconfigure(4, weight=1)
        
        self.auto_update_log = scrolledtext.ScrolledText(progress_frame, height=8, wrap=tk.WORD)
        self.auto_update_log.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # åœ¨å¯åŠ¨æ—¶æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ›´æ–°
        self.root.after(1000, self.check_auto_update_on_startup)
    
    def create_single_download_tab(self, parent):
        """åˆ›å»ºå•ç¯‡ä¸‹è½½é€‰é¡¹å¡"""
        frame = ttk.Frame(parent, padding="10")
        parent.add(frame, text="ğŸ“„ å•ç¯‡ä¸‹è½½")
        
        # URLè¾“å…¥
        ttk.Label(frame, text="å¾®ä¿¡æ–‡ç« URL:", style='Header.TLabel').grid(row=0, column=0, sticky=tk.W, pady=(0, 5))
        self.single_url_var = tk.StringVar()
        url_entry = ttk.Entry(frame, textvariable=self.single_url_var, width=60)
        url_entry.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        frame.columnconfigure(0, weight=1)
        
        # æ ¼å¼é€‰æ‹©
        ttk.Label(frame, text="è¾“å‡ºæ ¼å¼:", style='Header.TLabel').grid(row=2, column=0, sticky=tk.W, pady=(5, 5))
        
        format_frame = ttk.Frame(frame)
        format_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.single_format_var = tk.StringVar(value="pdf")
        formats = [
            ("ğŸ“‘ PDF (æ¨èï¼Œä¿æŒå®Œæ•´æ ¼å¼)", "pdf"),
            ("ğŸ“ Wordæ–‡æ¡£ (æ”¯æŒé£ä¹¦ç›´æ¥ä¸Šä¼ )", "docx"),
            ("ğŸŒ å®Œæ•´HTML (åŒ…å«å›¾ç‰‡)", "complete_html"),
            ("ğŸ“„ Markdown (é£ä¹¦é€‚ç”¨)", "individual"),
            ("ğŸ“Š JSONæ•°æ®", "json")
        ]
        
        for i, (text, value) in enumerate(formats):
            ttk.Radiobutton(format_frame, text=text, variable=self.single_format_var, 
                           value=value).grid(row=i//2, column=i%2, sticky=tk.W, padx=(0, 20))
        
        # ä¸‹è½½æŒ‰é’®
        button_frame = ttk.Frame(frame)
        button_frame.grid(row=4, column=0, columnspan=2, pady=20)
        
        self.single_download_btn = ttk.Button(button_frame, text="ğŸš€ å¼€å§‹ä¸‹è½½", 
                                            command=self.start_single_download)
        self.single_download_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(button_frame, text="ğŸ“ æ‰“å¼€ä¸‹è½½ç›®å½•", 
                  command=self.open_pdf_download_dir).pack(side=tk.LEFT)
        
        # ä¸‹è½½è¿›åº¦
        self.single_progress_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(frame, textvariable=self.single_progress_var, style='Success.TLabel').grid(row=5, column=0, columnspan=2, pady=10)
    
    def create_batch_download_tab(self, parent):
        """åˆ›å»ºæ‰¹é‡ä¸‹è½½é€‰é¡¹å¡"""
        frame = ttk.Frame(parent, padding="10")
        parent.add(frame, text="ğŸ“š æ‰¹é‡ä¸‹è½½")
        
        # è¯´æ˜æ–‡å­—
        info_text = """
ğŸš€ è‡ªåŠ¨ä¸‹è½½æ¨¡å¼ï¼š
â€¢ ç‚¹å‡»"å¼€å¯è‡ªåŠ¨ä¸‹è½½æ¨¡å¼"ï¼Œç„¶åå¤åˆ¶å¾®ä¿¡æ–‡ç« é“¾æ¥å³å¯è‡ªåŠ¨ä¸‹è½½PDF
â€¢ å¤šä¸ªé“¾æ¥ä¼šè‡ªåŠ¨æ’é˜Ÿï¼Œä¾æ¬¡ä¸‹è½½ï¼Œæ— éœ€æ‰‹åŠ¨ç‚¹å‡»ä¸‹è½½æŒ‰é’®
â€¢ è‡ªåŠ¨å»é‡ï¼Œè·³è¿‡é‡å¤é“¾æ¥
â€¢ æ–‡ä»¶ä¿å­˜åœ¨ output/auto_download/ ç›®å½•ä¸‹
â€¢ ğŸ”¥ NEW: æ”¯æŒè‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“ï¼Œåœ¨è®¾ç½®é¡µé¢å¯å¼€å¯/å…³é—­
â€¢ ä¹Ÿå¯ä»¥æ‰‹åŠ¨ç²˜è´´å¤šä¸ªé“¾æ¥åˆ°ä¸‹æ–¹æ–‡æœ¬æ¡†ï¼Œä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡ä¸‹è½½
        """
        ttk.Label(frame, text=info_text.strip(), justify=tk.LEFT).grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 15))
        
        # URLè¾“å…¥åŒºåŸŸ
        ttk.Label(frame, text="å¾®ä¿¡æ–‡ç« URLåˆ—è¡¨ (æ¯è¡Œä¸€ä¸ª):", style='Header.TLabel').grid(row=1, column=0, sticky=tk.W, pady=(0, 5))
        
        # URLæ–‡æœ¬æ¡†
        url_frame = ttk.Frame(frame)
        url_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        frame.columnconfigure(0, weight=1)
        frame.rowconfigure(2, weight=1)
        url_frame.columnconfigure(0, weight=1)
        url_frame.rowconfigure(0, weight=1)
        
        self.batch_urls_text = scrolledtext.ScrolledText(url_frame, height=10, width=80)
        self.batch_urls_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # ç¤ºä¾‹URL
        example_urls = """https://mp.weixin.qq.com/s?__biz=xxx&mid=xxx&idx=1&sn=xxx
https://mp.weixin.qq.com/s/abc123def456
https://mp.weixin.qq.com/s?a=b&c=d"""
        self.batch_urls_text.insert(tk.END, example_urls)
        
        # è‡ªåŠ¨ä¸‹è½½æ ¼å¼é€‰æ‹©
        format_frame = ttk.LabelFrame(frame, text="ğŸ¯ è‡ªåŠ¨ä¸‹è½½æ ¼å¼è®¾ç½®", padding="10")
        format_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        
        self.auto_format_var = tk.StringVar(value="pdf")
        self.auto_download_format = "pdf"  # ç¡®ä¿åˆå§‹åŒ–
        
        format_options = [
            ("ğŸ“‘ PDFæ ¼å¼ (å®Œæ•´æ ·å¼ï¼Œæ¨è)", "pdf"),
            ("ğŸ“ Wordæ–‡æ¡£ (æ”¯æŒé£ä¹¦çŸ¥è¯†åº“)", "docx")
        ]
        
        for i, (text, value) in enumerate(format_options):
            ttk.Radiobutton(format_frame, text=text, variable=self.auto_format_var, 
                           value=value, command=self.update_auto_format).grid(row=0, column=i, sticky=tk.W, padx=(0, 30))
        
        # æ“ä½œæŒ‰é’®ï¼ˆç¬¬ä¸€è¡Œï¼‰
        batch_button_frame1 = ttk.Frame(frame)
        batch_button_frame1.grid(row=4, column=0, columnspan=2, pady=(15, 5))
        
        ttk.Button(batch_button_frame1, text="ğŸ§¹ æ¸…ç©º", 
                  command=self.clear_batch_urls).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(batch_button_frame1, text="ğŸ“‹ ä»å‰ªè´´æ¿ç²˜è´´", 
                  command=self.paste_from_clipboard).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(batch_button_frame1, text="ğŸ“ ä»æ–‡ä»¶åŠ è½½", 
                  command=self.load_urls_from_file).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(batch_button_frame1, text="ğŸ”„ å»é‡", 
                  command=self.clean_duplicate_urls).pack(side=tk.LEFT, padx=(0, 10))
        
        # è‡ªåŠ¨ä¸‹è½½æŒ‰é’®
        self.auto_download_btn = ttk.Button(batch_button_frame1, text="ğŸš€ å¼€å¯è‡ªåŠ¨ä¸‹è½½æ¨¡å¼", 
                                          command=self.toggle_auto_download)
        self.auto_download_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        # æ‰¹é‡ä¸‹è½½é€‰é¡¹
        batch_options_frame = ttk.Frame(frame)
        batch_options_frame.grid(row=5, column=0, columnspan=2, pady=(5, 10))
        
        # è‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“å‹¾é€‰æ¡†
        self.batch_feishu_upload_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(batch_options_frame, text="ğŸ“š æ‰¹é‡ä¸‹è½½åè‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“", 
                       variable=self.batch_feishu_upload_var).pack(side=tk.LEFT)
        
        # æ“ä½œæŒ‰é’®ï¼ˆç¬¬äºŒè¡Œï¼‰
        batch_button_frame2 = ttk.Frame(frame)
        batch_button_frame2.grid(row=6, column=0, columnspan=2, pady=(5, 15))
        
        self.batch_download_btn = ttk.Button(batch_button_frame2, text="ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½", 
                                           command=self.start_batch_download)
        self.batch_download_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(batch_button_frame2, text="ğŸ“ æ‰“å¼€ä¸‹è½½ç›®å½•", 
                  command=self.open_pdf_download_dir).pack(side=tk.LEFT, padx=(0, 10))
        
        # è‡ªåŠ¨ä¸‹è½½çŠ¶æ€æ˜¾ç¤º
        self.auto_download_status = tk.StringVar(value="")
        ttk.Label(batch_button_frame2, textvariable=self.auto_download_status, 
                 style='Success.TLabel').pack(side=tk.LEFT, padx=(20, 0))
        
        # æ‰¹é‡ä¸‹è½½è¿›åº¦
        self.batch_progress_var = tk.StringVar(value="å‡†å¤‡å°±ç»ª")
        ttk.Label(frame, textvariable=self.batch_progress_var, style='Success.TLabel').grid(row=7, column=0, columnspan=2, pady=10)
        
        # ä¸‹è½½ç»Ÿè®¡
        self.batch_stats_var = tk.StringVar(value="")
        ttk.Label(frame, textvariable=self.batch_stats_var, style='Header.TLabel').grid(row=8, column=0, columnspan=2, pady=5)
    
    def create_settings_tab(self, parent):
        """åˆ›å»ºè®¾ç½®é€‰é¡¹å¡"""
        frame = ttk.Frame(parent, padding="10")
        parent.add(frame, text="âš™ï¸ è®¾ç½®")
        
        # åˆ›å»ºæ»šåŠ¨æ¡†æ¶ä»¥å®¹çº³æ›´å¤šå†…å®¹
        canvas = tk.Canvas(frame, highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame, orient="vertical", command=canvas.yview)
        scrollable_frame = ttk.Frame(canvas)
        
        # é…ç½®æ»šåŠ¨åŒºåŸŸ
        scrollable_frame.bind(
            "<Configure>",
            lambda e: canvas.configure(scrollregion=canvas.bbox("all"))
        )
        
        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        # å¸ƒå±€Canvaså’Œæ»šåŠ¨æ¡ - ç¡®ä¿Canvaså æ»¡å®½åº¦
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # ç»‘å®šCanvaså®½åº¦åˆ°scrollable_frameï¼Œç¡®ä¿å†…å®¹å……æ»¡å®½åº¦
        def configure_scrollable_frame(event):
            canvas.itemconfig(canvas.find_all()[0], width=event.width)
        canvas.bind('<Configure>', configure_scrollable_frame)
        
        # è¾“å‡ºç›®å½•è®¾ç½®
        ttk.Label(scrollable_frame, text="è¾“å‡ºç›®å½•:", style='Header.TLabel').grid(row=0, column=0, sticky=tk.W, pady=(0, 5))
        
        dir_frame = ttk.Frame(scrollable_frame)
        dir_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 15))
        scrollable_frame.columnconfigure(0, weight=1)
        dir_frame.columnconfigure(0, weight=1)
        
        self.output_dir_var = tk.StringVar(value=self.output_dir)
        ttk.Entry(dir_frame, textvariable=self.output_dir_var, state='readonly').grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 10))
        ttk.Button(dir_frame, text="æµè§ˆ", command=self.browse_output_dir).grid(row=0, column=1)
        
        # æµè§ˆå™¨è®¾ç½®
        ttk.Label(scrollable_frame, text="æµè§ˆå™¨æ¨¡å¼:", style='Header.TLabel').grid(row=2, column=0, sticky=tk.W, pady=(15, 5))
        
        self.headless_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(scrollable_frame, text="æ— å¤´æ¨¡å¼ (åå°è¿è¡Œï¼Œä½†å¯èƒ½æ— æ³•å¤„ç†éªŒè¯ç )", 
                       variable=self.headless_var).grid(row=3, column=0, sticky=tk.W, pady=(0, 15))
        
        # é£ä¹¦é›†æˆè®¾ç½®
        ttk.Label(scrollable_frame, text="é£ä¹¦çŸ¥è¯†åº“é›†æˆ:", style='Header.TLabel').grid(row=4, column=0, sticky=tk.W, pady=(15, 5))
        
        self.feishu_upload_var = tk.BooleanVar(value=self.enable_feishu_upload)
        ttk.Checkbutton(scrollable_frame, text="è‡ªåŠ¨ä¸Šä¼ PDFåˆ°é£ä¹¦çŸ¥è¯†åº“", 
                       variable=self.feishu_upload_var, 
                       command=self.toggle_feishu_upload).grid(row=5, column=0, sticky=tk.W, pady=(0, 5))
        
        # é£ä¹¦çŠ¶æ€æ˜¾ç¤º
        self.feishu_status_var = tk.StringVar(value="âš ï¸ é£ä¹¦é›†æˆå·²å¯ç”¨ï¼ˆä»…æ£€æµ‹æ¨¡å¼ï¼‰")
        ttk.Label(scrollable_frame, textvariable=self.feishu_status_var, 
                 style='Warning.TLabel').grid(row=6, column=0, sticky=tk.W, pady=(0, 5))
        
        # ğŸ†• OAuthè®¤è¯çŠ¶æ€å’Œé‡æ–°è®¤è¯åŠŸèƒ½
        oauth_frame = ttk.LabelFrame(scrollable_frame, text="ğŸ” OAuthè®¤è¯ç®¡ç†", padding="5")
        oauth_frame.grid(row=7, column=0, sticky=(tk.W, tk.E), pady=(5, 15))
        oauth_frame.columnconfigure(0, weight=1)
        
        # è®¤è¯çŠ¶æ€æ˜¾ç¤º
        self.oauth_status_var = tk.StringVar()
        self.oauth_status_label = ttk.Label(oauth_frame, textvariable=self.oauth_status_var, 
                                           foreground='blue')
        self.oauth_status_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 5))
        
        # è®¤è¯æ“ä½œæŒ‰é’®
        oauth_buttons_frame = ttk.Frame(oauth_frame)
        oauth_buttons_frame.grid(row=1, column=0, sticky=tk.W)
        
        self.oauth_reauth_btn = ttk.Button(oauth_buttons_frame, text="ğŸ”„ é‡æ–°è®¤è¯", 
                                          command=self.start_oauth_reauth)
        self.oauth_reauth_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(oauth_buttons_frame, text="ğŸ” æ£€æŸ¥çŠ¶æ€", 
                  command=self.check_oauth_status).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(oauth_buttons_frame, text="âŒ æ’¤é”€è®¤è¯", 
                  command=self.revoke_oauth_tokens).pack(side=tk.LEFT)
        
        # åˆå§‹åŒ–OAuthçŠ¶æ€æ£€æŸ¥
        self.check_oauth_status()
        
        # ğŸ†• çŸ¥è¯†åº“æ™ºèƒ½åˆ†ç±»è®¾ç½®
        self.create_wiki_location_settings(scrollable_frame, 8)
        
        # æ‰¹é‡ä¸‹è½½è®¾ç½®
        ttk.Label(scrollable_frame, text="æ‰¹é‡ä¸‹è½½è®¾ç½®:", style='Header.TLabel').grid(row=20, column=0, sticky=tk.W, pady=(15, 5))
        
        # å»¶è¿Ÿè®¾ç½®
        delay_frame = ttk.Frame(scrollable_frame)
        delay_frame.grid(row=21, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(delay_frame, text="ä¸‹è½½å»¶è¿Ÿ(ç§’):").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.delay_var = tk.StringVar(value="3")
        delay_spin = ttk.Spinbox(delay_frame, from_=1, to=10, width=10, textvariable=self.delay_var)
        delay_spin.grid(row=0, column=1, sticky=tk.W)
        ttk.Label(delay_frame, text="(é˜²æ­¢è¢«é™åˆ¶)").grid(row=0, column=2, sticky=tk.W, padx=(10, 0))
        
        # é‡è¯•è®¾ç½®
        retry_frame = ttk.Frame(scrollable_frame)
        retry_frame.grid(row=22, column=0, sticky=(tk.W, tk.E), pady=(0, 15))
        
        ttk.Label(retry_frame, text="å¤±è´¥é‡è¯•æ¬¡æ•°:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.retry_var = tk.StringVar(value="2")
        retry_spin = ttk.Spinbox(retry_frame, from_=0, to=5, width=10, textvariable=self.retry_var)
        retry_spin.grid(row=0, column=1, sticky=tk.W)
        
        # å…³äºä¿¡æ¯
        about_frame = ttk.LabelFrame(scrollable_frame, text="ğŸ“– å…³äº", padding="10")
        about_frame.grid(row=23, column=0, sticky=(tk.W, tk.E), pady=15)
        
        about_text = """
å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…· v3.0 - ç®€æ´ç‰ˆ

âœ¨ ä¸»è¦åŠŸèƒ½:
â€¢ å•ç¯‡æ–‡ç« ä¸‹è½½ (PDF/HTML/Markdown/JSON)
â€¢ å¤šURLæ‰¹é‡ä¸‹è½½ (ç®€å•ç›´æ¥)
â€¢ å®Œç¾ä¿æŒåŸæ–‡æ ¼å¼å’Œå›¾ç‰‡
â€¢ æ™ºèƒ½é‡è¯•å’Œé”™è¯¯å¤„ç†
â€¢ ğŸ†• æ™ºèƒ½åˆ†ç±»è½¬ç§»åˆ°é£ä¹¦çŸ¥è¯†åº“
â€¢ ğŸ†• OAuthè®¤è¯ç®¡ç†

ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹:
â€¢ äººç±»å¼é˜…è¯»è¡Œä¸ºæ¨¡æ‹Ÿ
â€¢ æ™ºèƒ½å›¾ç‰‡åŠ è½½æ£€æµ‹
â€¢ é«˜æ•ˆPDFç”Ÿæˆ
â€¢ è‡ªåŠ¨æ–‡ä»¶å‘½å
â€¢ ğŸ†• å…³é”®è¯åŒ¹é…è‡ªåŠ¨åˆ†ç±»

ğŸ“§ æ”¯æŒ: é‡åˆ°é—®é¢˜è¯·æŸ¥çœ‹æ—¥å¿—è¾“å‡º
        """
        ttk.Label(about_frame, text=about_text.strip(), justify=tk.LEFT).pack(anchor=tk.W)
        
        # ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶åˆ°Canvas
        def _on_mousewheel(event):
            canvas.yview_scroll(int(-1*(event.delta/120)), "units")
        
        # ç»‘å®šæ»šè½®äº‹ä»¶åˆ°Canvaså’Œscrollable_frame
        canvas.bind("<MouseWheel>", _on_mousewheel)
        scrollable_frame.bind("<MouseWheel>", _on_mousewheel)
        
        # ç¡®ä¿ç„¦ç‚¹äº‹ä»¶ä¹Ÿèƒ½æ»šåŠ¨
        def bind_mousewheel_to_widget(widget):
            widget.bind("<MouseWheel>", _on_mousewheel)
            for child in widget.winfo_children():
                bind_mousewheel_to_widget(child)
        
        bind_mousewheel_to_widget(scrollable_frame)
    
    def create_wiki_location_settings(self, parent, start_row):
        """åˆ›å»ºçŸ¥è¯†åº“ä½ç½®é…ç½®ç•Œé¢"""
        # ä¸»æ ‡é¢˜
        wiki_frame = ttk.LabelFrame(parent, text="ğŸ¯ çŸ¥è¯†åº“æ™ºèƒ½åˆ†ç±»è®¾ç½®", padding="10")
        wiki_frame.grid(row=start_row, column=0, sticky=(tk.W, tk.E), pady=(15, 0))
        parent.columnconfigure(0, weight=1)
        wiki_frame.columnconfigure(0, weight=1)
        
        # è¯´æ˜æ–‡å­—
        info_text = """
ğŸ’¡ æ™ºèƒ½åˆ†ç±»åŠŸèƒ½ï¼šæ ¹æ®æ–‡ç« æ ‡é¢˜ä¸­çš„å…³é”®è¯è‡ªåŠ¨è½¬ç§»åˆ°å¯¹åº”çš„çŸ¥è¯†åº“ä½ç½®
â€¢ æ”¯æŒå¤šä¸ªå…³é”®è¯åŒ¹é…åŒä¸€ä¸ªä½ç½®
â€¢ å¯ä»¥è®¾ç½®è½¬ç§»åˆ°é¡µé¢æˆ–å­é¡µé¢
â€¢ æœªåŒ¹é…åˆ°å…³é”®è¯æ—¶è½¬ç§»åˆ°é»˜è®¤ä½ç½®
        """
        ttk.Label(wiki_frame, text=info_text.strip(), justify=tk.LEFT, 
                 foreground='gray').grid(row=0, column=0, sticky=tk.W, pady=(0, 10))
        
        # é»˜è®¤ä½ç½®è®¾ç½®
        default_frame = ttk.LabelFrame(wiki_frame, text="ğŸ  é»˜è®¤è½¬ç§»ä½ç½®", padding="5")
        default_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        default_frame.columnconfigure(1, weight=1)
        
        # é»˜è®¤ä½ç½®URLè¾“å…¥è¡Œ
        ttk.Label(default_frame, text="é»˜è®¤ä½ç½®:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.default_wiki_var = tk.StringVar(value=self.default_wiki_location)
        ttk.Entry(default_frame, textvariable=self.default_wiki_var, width=50).grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 10))
        ttk.Button(default_frame, text="æµ‹è¯•", command=lambda: self.test_wiki_url(self.default_wiki_var.get())).grid(row=0, column=2)
        
        # é»˜è®¤ä½ç½®å­é¡µé¢é€‰é¡¹è¡Œ
        default_options_frame = ttk.Frame(default_frame)
        default_options_frame.grid(row=1, column=0, columnspan=3, sticky=tk.W, pady=(5, 0))
        
        self.default_as_subpage_var = tk.BooleanVar(value=True)  # é»˜è®¤å‹¾é€‰
        ttk.Checkbutton(default_options_frame, text="è½¬ç§»åˆ°è¯¥ä½ç½®çš„å­é¡µé¢", 
                       variable=self.default_as_subpage_var).pack(side=tk.LEFT)
        
        # å…³é”®è¯-ä½ç½®æ˜ å°„è®¾ç½®
        mapping_frame = ttk.LabelFrame(wiki_frame, text="ğŸ” å…³é”®è¯ä½ç½®æ˜ å°„", padding="5")
        mapping_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(10, 0))
        mapping_frame.columnconfigure(0, weight=1)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸç”¨äºä½ç½®æ˜ å°„
        self.create_wiki_mappings_area(mapping_frame)
        
        # æ“ä½œæŒ‰é’®
        button_frame = ttk.Frame(mapping_frame)
        button_frame.grid(row=1, column=0, pady=(10, 0))
        
        ttk.Button(button_frame, text="â• æ·»åŠ ä½ç½®", command=self.add_wiki_location).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="ğŸ’¾ ä¿å­˜é…ç½®", command=self.save_wiki_config).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="ğŸ”„ é‡ç½®é…ç½®", command=self.reset_wiki_config).pack(side=tk.LEFT)
        
        # ğŸ†• æ™ºèƒ½åˆ†ç±»æµ‹è¯•åŒºåŸŸ
        test_frame = ttk.LabelFrame(wiki_frame, text="ğŸ§ª æ™ºèƒ½åˆ†ç±»æµ‹è¯•", padding="5")
        test_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(10, 0))
        test_frame.columnconfigure(1, weight=1)
        
        ttk.Label(test_frame, text="æµ‹è¯•æ ‡é¢˜:").grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.test_title_var = tk.StringVar(value="Pythonç¼–ç¨‹æŠ€æœ¯å…¥é—¨æ•™ç¨‹")
        ttk.Entry(test_frame, textvariable=self.test_title_var, width=40).grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 10))
        ttk.Button(test_frame, text="ğŸ§ª æµ‹è¯•åˆ†ç±»", command=self.run_classification_test).grid(row=0, column=2)
        
        # æµ‹è¯•ç»“æœæ˜¾ç¤º
        self.test_result_var = tk.StringVar(value="ç‚¹å‡»'æµ‹è¯•åˆ†ç±»'æŸ¥çœ‹ç»“æœ")
        ttk.Label(test_frame, textvariable=self.test_result_var, foreground='blue').grid(row=1, column=0, columnspan=3, sticky=tk.W, pady=(5, 0))

    def create_wiki_mappings_area(self, parent):
        """åˆ›å»ºçŸ¥è¯†åº“æ˜ å°„é…ç½®åŒºåŸŸ"""
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        mappings_canvas = tk.Canvas(parent, height=200)
        mappings_scrollbar = ttk.Scrollbar(parent, orient="vertical", command=mappings_canvas.yview)
        self.mappings_frame = ttk.Frame(mappings_canvas)
        
        self.mappings_frame.bind(
            "<Configure>",
            lambda e: mappings_canvas.configure(scrollregion=mappings_canvas.bbox("all"))
        )
        
        mappings_canvas.create_window((0, 0), window=self.mappings_frame, anchor="nw")
        mappings_canvas.configure(yscrollcommand=mappings_scrollbar.set)
        
        mappings_canvas.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        mappings_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        parent.rowconfigure(0, weight=1)
        parent.columnconfigure(0, weight=1)
        
        # ç»‘å®šé¼ æ ‡æ»šè½®
        def _on_mappings_mousewheel(event):
            mappings_canvas.yview_scroll(int(-1*(event.delta/120)), "units")
        mappings_canvas.bind("<MouseWheel>", _on_mappings_mousewheel)
        
        # åˆ›å»ºç°æœ‰çš„æ˜ å°„é¡¹
        self.refresh_wiki_mappings()

    def refresh_wiki_mappings(self):
        """åˆ·æ–°çŸ¥è¯†åº“æ˜ å°„æ˜¾ç¤º"""
        # æ¸…ç©ºç°æœ‰å†…å®¹
        for widget in self.mappings_frame.winfo_children():
            widget.destroy()
        
        # æ·»åŠ è¡¨å¤´
        header_frame = ttk.Frame(self.mappings_frame)
        header_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Label(header_frame, text="å…³é”®è¯ (ç”¨é€—å·åˆ†éš”)", font=('Arial', 9, 'bold')).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Label(header_frame, text="çŸ¥è¯†åº“é“¾æ¥", font=('Arial', 9, 'bold')).pack(side=tk.LEFT, padx=(120, 10))
        ttk.Label(header_frame, text="å­é¡µé¢", font=('Arial', 9, 'bold')).pack(side=tk.LEFT, padx=(200, 10))
        ttk.Label(header_frame, text="æ“ä½œ", font=('Arial', 9, 'bold')).pack(side=tk.LEFT, padx=(30, 0))
        
        # æ·»åŠ ç°æœ‰çš„æ˜ å°„é¡¹
        for i, location in enumerate(self.wiki_locations):
            self.create_wiki_mapping_row(i, location)
        
        # å¦‚æœæ²¡æœ‰æ˜ å°„é¡¹ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤çš„
        if not self.wiki_locations:
            self.add_wiki_location()

    def create_wiki_mapping_row(self, index, location_data):
        """åˆ›å»ºå•ä¸ªçŸ¥è¯†åº“æ˜ å°„è¡Œ"""
        row_frame = ttk.Frame(self.mappings_frame)
        row_frame.pack(fill=tk.X, pady=2)
        
        # å…³é”®è¯è¾“å…¥æ¡†
        keywords_str = ", ".join(location_data.get("keywords", []))
        keywords_var = tk.StringVar(value=keywords_str)
        keywords_entry = ttk.Entry(row_frame, textvariable=keywords_var, width=20)
        keywords_entry.pack(side=tk.LEFT, padx=(0, 10))
        
        # é“¾æ¥è¾“å…¥æ¡†
        url_var = tk.StringVar(value=location_data.get("wiki_url", ""))
        url_entry = ttk.Entry(row_frame, textvariable=url_var, width=40)
        url_entry.pack(side=tk.LEFT, padx=(0, 10))
        
        # å­é¡µé¢å‹¾é€‰æ¡†
        subpage_var = tk.BooleanVar(value=location_data.get("as_subpage", True))
        subpage_check = ttk.Checkbutton(row_frame, variable=subpage_var)
        subpage_check.pack(side=tk.LEFT, padx=(0, 10))
        
        # æµ‹è¯•æŒ‰é’®
        ttk.Button(row_frame, text="æµ‹è¯•", width=6,
                  command=lambda: self.test_wiki_url(url_var.get())).pack(side=tk.LEFT, padx=(0, 5))
        
        # åˆ é™¤æŒ‰é’®
        ttk.Button(row_frame, text="åˆ é™¤", width=6,
                  command=lambda i=index: self.remove_wiki_location(i)).pack(side=tk.LEFT)
        
        # ä¿å­˜å˜é‡å¼•ç”¨ä»¥ä¾¿åç»­è·å–å€¼
        setattr(row_frame, 'keywords_var', keywords_var)
        setattr(row_frame, 'url_var', url_var)
        setattr(row_frame, 'subpage_var', subpage_var)
        setattr(row_frame, 'index', index)

    def add_wiki_location(self):
        """æ·»åŠ æ–°çš„çŸ¥è¯†åº“ä½ç½®"""
        new_location = {
            "keywords": [],
            "wiki_url": "",
            "as_subpage": True
        }
        self.wiki_locations.append(new_location)
        self.refresh_wiki_mappings()
        self.log_message("å·²æ·»åŠ æ–°çš„çŸ¥è¯†åº“ä½ç½®é…ç½®", "INFO")

    def remove_wiki_location(self, index):
        """åˆ é™¤çŸ¥è¯†åº“ä½ç½®"""
        if 0 <= index < len(self.wiki_locations):
            self.wiki_locations.pop(index)
            self.refresh_wiki_mappings()
            self.log_message(f"å·²åˆ é™¤çŸ¥è¯†åº“ä½ç½®é…ç½® #{index + 1}", "INFO")

    def save_wiki_config(self):
        """ä¿å­˜çŸ¥è¯†åº“é…ç½®"""
        try:
            # æ›´æ–°é»˜è®¤ä½ç½®
            self.default_wiki_location = self.default_wiki_var.get()
            
            # æ›´æ–°æ˜ å°„é…ç½®
            self.wiki_locations.clear()
            
            for widget in self.mappings_frame.winfo_children():
                if hasattr(widget, 'keywords_var'):
                    keywords_str = widget.keywords_var.get().strip()
                    wiki_url = widget.url_var.get().strip()
                    as_subpage = widget.subpage_var.get()
                    
                    if keywords_str and wiki_url:
                        # è§£æå…³é”®è¯
                        keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
                        
                        location_config = {
                            "keywords": keywords,
                            "wiki_url": wiki_url,
                            "as_subpage": as_subpage
                        }
                        self.wiki_locations.append(location_config)
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            self.save_config_to_file()
            
            self.log_message(f"âœ… çŸ¥è¯†åº“é…ç½®å·²ä¿å­˜ ({len(self.wiki_locations)} ä¸ªä½ç½®)", "SUCCESS")
            
        except Exception as e:
            self.log_message(f"âŒ ä¿å­˜çŸ¥è¯†åº“é…ç½®å¤±è´¥: {e}", "ERROR")

    def reset_wiki_config(self):
        """é‡ç½®çŸ¥è¯†åº“é…ç½®"""
        if messagebox.askyesno("ç¡®è®¤é‡ç½®", "ç¡®å®šè¦é‡ç½®çŸ¥è¯†åº“é…ç½®å—ï¼Ÿè¿™å°†æ¢å¤åˆ°é»˜è®¤è®¾ç½®ã€‚"):
            self.init_default_wiki_config()
            self.default_wiki_var.set(self.default_wiki_location)
            self.refresh_wiki_mappings()
            self.log_message("å·²é‡ç½®çŸ¥è¯†åº“é…ç½®åˆ°é»˜è®¤è®¾ç½®", "INFO")

    def test_wiki_url(self, url):
        """æµ‹è¯•çŸ¥è¯†åº“URLæ˜¯å¦æœ‰æ•ˆ"""
        if not url:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥URL")
            return
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ URLéªŒè¯é€»è¾‘
        # æš‚æ—¶åªåšç®€å•çš„æ ¼å¼æ£€æŸ¥
        if "feishu.cn" in url:
            messagebox.showinfo("æµ‹è¯•ç»“æœ", "URLæ ¼å¼æ­£ç¡®ï¼\næ³¨æ„ï¼šå®é™…æœ‰æ•ˆæ€§éœ€è¦åœ¨ä½¿ç”¨æ—¶éªŒè¯ã€‚")
            self.log_message(f"æµ‹è¯•çŸ¥è¯†åº“URL: {url}", "INFO")
        else:
            messagebox.showwarning("æµ‹è¯•ç»“æœ", "URLæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºé£ä¹¦é“¾æ¥ã€‚")

    def save_config_to_file(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            import json
            config_data = {
                "default_wiki_location": self.default_wiki_location,
                "default_as_subpage": self.default_as_subpage_var.get() if hasattr(self, 'default_as_subpage_var') else True,
                "wiki_locations": self.wiki_locations
            }
            
            with open("wiki_location_config.json", "w", encoding="utf-8") as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
                
            self.log_message("é…ç½®å·²ä¿å­˜åˆ° wiki_location_config.json", "INFO")
            
        except Exception as e:
            self.log_message(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}", "WARNING")

    def load_config_from_file(self):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            import json
            if os.path.exists("wiki_location_config.json"):
                with open("wiki_location_config.json", "r", encoding="utf-8") as f:
                    config_data = json.load(f)
                
                self.default_wiki_location = config_data.get("default_wiki_location", self.default_wiki_location)
                self.wiki_locations = config_data.get("wiki_locations", self.wiki_locations)
                
                # åŠ è½½é»˜è®¤ä½ç½®çš„å­é¡µé¢è®¾ç½®
                default_as_subpage = config_data.get("default_as_subpage", True)
                if hasattr(self, 'default_as_subpage_var'):
                    self.default_as_subpage_var.set(default_as_subpage)
                
                self.log_message("ä»é…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®æˆåŠŸ", "INFO")
                
        except Exception as e:
            self.log_message(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}", "WARNING")

    def find_target_wiki_location(self, title):
        """æ ¹æ®æ–‡ç« æ ‡é¢˜æ‰¾åˆ°ç›®æ ‡çŸ¥è¯†åº“åˆ†ç±»å­èŠ‚ç‚¹ä½ç½®"""
        self.log_message(f"ğŸ” æ™ºèƒ½åˆ†ç±»åˆ†æå¼€å§‹", "INFO")
        self.log_message(f"   ğŸ“ åˆ†ææ ‡é¢˜: {title}", "INFO")
        self.log_message(f"   ğŸ—‚ï¸ é…ç½®çš„åˆ†ç±»ä½ç½®: {len(self.wiki_locations)} ä¸ª", "INFO")
        self.log_message(f"   ğŸ’¡ åŒ¹é…ç­–ç•¥: å…³é”®è¯åŒ¹é… â†’ åˆ†ç±»å®šä½ â†’ æ™ºèƒ½ä¸Šä¼ ", "INFO")
        
        title_lower = title.lower()
        
        # éå†æ‰€æœ‰é…ç½®çš„ä½ç½®
        for i, location in enumerate(self.wiki_locations):
            keywords = location.get("keywords", [])
            wiki_url = location.get("wiki_url", "")
            as_subpage = location.get("as_subpage", True)
            
            location_name = wiki_url.split('/')[-1] if '/' in wiki_url else wiki_url
            self.log_message(f"   ğŸ“‚ ä½ç½®{i+1}: {location_name} (å…³é”®è¯: {keywords})", "INFO")
            
            for keyword in keywords:
                if keyword.lower() in title_lower:
                    self.log_message(f"   ğŸ¯ âœ… åŒ¹é…æˆåŠŸ! å…³é”®è¯ '{keyword}' å‘½ä¸­", "SUCCESS")
                    self.log_message(f"      ğŸ“ ç›®æ ‡ä½ç½®: {location_name}", "SUCCESS")
                    self.log_message(f"      ğŸ“„ ä¸Šä¼ æ–¹å¼: {'å­é¡µé¢' if as_subpage else 'ç‹¬ç«‹é¡µé¢'}", "SUCCESS")
                    return location
        
        # æ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
        default_as_subpage = self.default_as_subpage_var.get() if hasattr(self, 'default_as_subpage_var') else True
        default_location_name = self.default_wiki_location.split('/')[-1] if '/' in self.default_wiki_location else self.default_wiki_location
        self.log_message(f"   ğŸ  æ— å…³é”®è¯åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®", "INFO")
        self.log_message(f"      ğŸ“ é»˜è®¤ä½ç½®: {default_location_name}", "INFO")
        self.log_message(f"      ğŸ“„ ä¸Šä¼ æ–¹å¼: {'å­é¡µé¢' if default_as_subpage else 'ç‹¬ç«‹é¡µé¢'}", "INFO")
        
        # ğŸ”¥ ç¡®ä¿è¿”å›å®Œæ•´çš„ä½ç½®ä¿¡æ¯ï¼ŒåŒ…å«keywordså­—æ®µï¼ˆç©ºåˆ—è¡¨ï¼‰
        return {
            "keywords": [],  # é»˜è®¤ä½ç½®æ²¡æœ‰å…³é”®è¯
            "wiki_url": self.default_wiki_location,
            "as_subpage": default_as_subpage
        }

    def init_default_wiki_config(self):
        """åˆå§‹åŒ–é»˜è®¤çš„çŸ¥è¯†åº“é…ç½®"""
        # è®¾ç½®é»˜è®¤è½¬ç§»ä½ç½®ï¼ˆROçŸ¥è¯†åº“çš„é»˜è®¤ä½ç½®ï¼‰
        self.default_wiki_location = "https://thedream.feishu.cn/wiki/MLOZwjYtBiCepHkpHFPcA2dgnvf"
        
        # æ·»åŠ å®Œæ•´çš„ROå…³é”®è¯-é“¾æ¥é…ç½®ï¼ˆä¸wiki_location_config.jsonä¿æŒä¸€è‡´ï¼‰
        self.wiki_locations = [
            {
                "keywords": ["å†’é™©è€…æŒ‡å—"],
                "wiki_url": "https://thedream.feishu.cn/wiki/XS8kwk7oJieSv6keDWGc8bGln5g",
                "as_subpage": True
            },
            {
                "keywords": ["çƒ­ç‚¹é—®é¢˜æ±‡æ€»"],
                "wiki_url": "https://thedream.feishu.cn/wiki/CBnawegHoi8rsrkqmINc2jIHnMb",
                "as_subpage": True
            },
            {
                "keywords": ["å†’é™©è€…æŠ•ç¨¿"],
                "wiki_url": "https://thedream.feishu.cn/wiki/FlXIwYAkbioxf1kURgXcIZhInl7",
                "as_subpage": True
            },
            {
                "keywords": ["å¾é›†"],
                "wiki_url": "https://thedream.feishu.cn/wiki/YIK6wvyxuiER1MkWDUjcv1WfnQb",
                "as_subpage": True
            },
            {
                "keywords": ["å—é—¨èŒ¶è¯ä¼š"],
                "wiki_url": "https://thedream.feishu.cn/wiki/B3sUwGL9oiD6oNkTzzkcMm4fnKd",
                "as_subpage": True
            },
            {
                "keywords": ["æ³¢åˆ©è§‚å…‰å›¢"],
                "wiki_url": "https://thedream.feishu.cn/wiki/AFsRw5o52i3NLdkGl0FcFBa3nIU",
                "as_subpage": True
            },
            {
                "keywords": ["æ›´æ–°å…¬å‘Š"],
                "wiki_url": "https://thedream.feishu.cn/wiki/K1iVwfcrois7UHkY32Icurxtnuf",
                "as_subpage": True
            },
            {
                "keywords": ["å£çº¸æ´¾é€"],
                "wiki_url": "https://thedream.feishu.cn/wiki/XIgpwJVGOiuCtFkHq2zcfipjn4q",
                "as_subpage": True
            },
            {
                "keywords": ["ç¦åˆ©"],
                "wiki_url": "https://thedream.feishu.cn/wiki/NwtlwO1SHiUyzgkMU5Rc57i6nYc",
                "as_subpage": True
            },
            {
                "keywords": ["å½©è™¹è·¯é€ç¤¾"],
                "wiki_url": "https://thedream.feishu.cn/wiki/B3sUwGL9oiD6oNkTzzkcMm4fnKd",
                "as_subpage": True
            },
            {
                "keywords": ["å¡æ™®æ‹‰ç‹¬å®¶"],
                "wiki_url": "https://thedream.feishu.cn/wiki/WVPnwjiZiiGhpYkUCSWc01NFnOd",
                "as_subpage": True
            },
            {
                "keywords": ["æœ‰ç¤¼"],
                "wiki_url": "https://thedream.feishu.cn/wiki/W2Qsw8R8aiZrMQkQlSZcr8gmnhe",
                "as_subpage": True
            },
            {
                "keywords": ["å†’é™©æ—¥å†"],
                "wiki_url": "https://thedream.feishu.cn/wiki/QvkMwNvZHiKX7xkWkD4cDxMdntc",
                "as_subpage": True
            }
        ]
        
        # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ï¼ˆä¼šè¦†ç›–ä¸Šé¢çš„é»˜è®¤è®¾ç½®ï¼‰
        self.load_config_from_file()
        
        self.log_message(f"ğŸ“‚ æ™ºèƒ½åˆ†ç±»é…ç½®åˆå§‹åŒ–å®Œæˆ", "INFO")
        self.log_message(f"ğŸ  é»˜è®¤ä½ç½®: {self.default_wiki_location}", "INFO")
        self.log_message(f"ğŸ—‚ï¸ å…³é”®è¯ä½ç½®æ•°é‡: {len(self.wiki_locations)}", "INFO")
        
        # æ˜¾ç¤ºæ‰€æœ‰é…ç½®çš„å…³é”®è¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        for i, location in enumerate(self.wiki_locations, 1):
            keywords = location.get("keywords", [])
            wiki_url = location.get("wiki_url", "")
            self.log_message(f"   ğŸ“‹ [{i}] å…³é”®è¯: {keywords} â†’ {wiki_url.split('/')[-1]}", "INFO")
    
    def log_message(self, message, level="INFO"):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯åˆ°é˜Ÿåˆ—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"[{timestamp}] {level}: {message}\n"
        self.msg_queue.put(('log', formatted_message))
    
    def process_queue(self):
        """å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—"""
        try:
            while True:
                msg_type, data = self.msg_queue.get_nowait()
                if msg_type == 'log':
                    self.log_text.config(state='normal')
                    self.log_text.insert(tk.END, data)
                    self.log_text.see(tk.END)
                    self.log_text.config(state='disabled')
                elif msg_type == 'status':
                    self.status_var.set(data)
                elif msg_type == 'progress_single':
                    self.single_progress_var.set(data)
                elif msg_type == 'progress_batch':
                    self.batch_progress_var.set(data)
                elif msg_type == 'stats_batch':
                    self.batch_stats_var.set(data)
                elif msg_type == 'enable_buttons':
                    self.enable_buttons()
                elif msg_type == 'disable_buttons':
                    self.disable_buttons()
                elif msg_type == 'oauth_success':
                    self.handle_oauth_result(True)
                elif msg_type == 'oauth_failed':
                    self.handle_oauth_result(False)
        except queue.Empty:
            pass
        
        # æ¯100msæ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—
        self.root.after(100, self.process_queue)
    
    def enable_buttons(self):
        """å¯ç”¨æŒ‰é’®"""
        self.single_download_btn.config(state='normal')
        self.batch_download_btn.config(state='normal')
        self.is_downloading = False
    
    def disable_buttons(self):
        """ç¦ç”¨æŒ‰é’®"""
        self.single_download_btn.config(state='disabled')
        self.batch_download_btn.config(state='disabled')
        self.is_downloading = True
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.config(state='normal')
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state='disabled')
    
    def browse_output_dir(self):
        """æµè§ˆè¾“å‡ºç›®å½•"""
        directory = filedialog.askdirectory(initialdir=self.output_dir)
        if directory:
            self.output_dir = directory
            self.output_dir_var.set(directory)
    
    def open_output_dir(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        if os.path.exists(self.output_dir):
            if sys.platform == "win32":
                os.startfile(self.output_dir)
            elif sys.platform == "darwin":
                os.system(f"open '{self.output_dir}'")
            else:
                os.system(f"xdg-open '{self.output_dir}'")
        else:
            messagebox.showwarning("è­¦å‘Š", f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {self.output_dir}")
    
    def open_pdf_download_dir(self):
        """æ‰“å¼€PDFä¸‹è½½ç›®å½•"""
        pdf_dir = os.path.join(self.output_dir, "pdf")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(pdf_dir, exist_ok=True)
        
        if sys.platform == "win32":
            os.startfile(pdf_dir)
        elif sys.platform == "darwin":
            os.system(f"open '{pdf_dir}'")
        else:
            os.system(f"xdg-open '{pdf_dir}'")
        
        self.log_message(f"å·²æ‰“å¼€PDFä¸‹è½½ç›®å½•: {pdf_dir}")
    
    def update_auto_format(self):
        """æ›´æ–°è‡ªåŠ¨ä¸‹è½½æ ¼å¼"""
        self.auto_download_format = self.auto_format_var.get()
        format_name = "PDF" if self.auto_download_format == "pdf" else "Wordæ–‡æ¡£"
        self.log_message(f"ğŸ¯ è‡ªåŠ¨ä¸‹è½½æ ¼å¼å·²åˆ‡æ¢ä¸º: {format_name}", "INFO")
    
    def clear_batch_urls(self):
        """æ¸…ç©ºæ‰¹é‡URLæ–‡æœ¬æ¡†"""
        self.batch_urls_text.delete(1.0, tk.END)
    
    def paste_from_clipboard(self):
        """ä»å‰ªè´´æ¿ç²˜è´´URL"""
        try:
            clipboard_content = self.root.clipboard_get()
            self.batch_urls_text.insert(tk.END, "\n" + clipboard_content)
            self.log_message("å·²ä»å‰ªè´´æ¿ç²˜è´´å†…å®¹")
        except tk.TclError:
            messagebox.showwarning("è­¦å‘Š", "å‰ªè´´æ¿ä¸ºç©ºæˆ–æ— æ³•è®¿é—®")
    
    def load_urls_from_file(self):
        """ä»æ–‡ä»¶åŠ è½½URL"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©URLæ–‡ä»¶",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                self.batch_urls_text.insert(tk.END, "\n" + content)
                self.log_message(f"å·²ä»æ–‡ä»¶åŠ è½½URL: {file_path}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
    
    def start_single_download(self):
        """å¼€å§‹å•ç¯‡ä¸‹è½½"""
        url = self.single_url_var.get().strip()
        if not url:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥å¾®ä¿¡æ–‡ç« URL")
            return
        
        if self.is_downloading:
            messagebox.showwarning("è­¦å‘Š", "æ­£åœ¨ä¸‹è½½ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ")
            return
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œä¸‹è½½
        thread = threading.Thread(target=self._single_download_worker, args=(url,))
        thread.daemon = True
        thread.start()
    
    def start_batch_download(self):
        """å¼€å§‹æ‰¹é‡ä¸‹è½½"""
        urls_text = self.batch_urls_text.get(1.0, tk.END).strip()
        if not urls_text:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥å¾®ä¿¡æ–‡ç« URLåˆ—è¡¨")
            return
        
        if self.is_downloading:
            messagebox.showwarning("è­¦å‘Š", "æ­£åœ¨ä¸‹è½½ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ")
            return
        
        # è§£æURLåˆ—è¡¨
        urls = [url.strip() for url in urls_text.split('\n') if url.strip()]
        if not urls:
            messagebox.showerror("é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„URL")
            return
        
        # ç¡®è®¤ä¸‹è½½
        result = messagebox.askyesno("ç¡®è®¤æ‰¹é‡ä¸‹è½½", 
                                   f"å°†è¦ä¸‹è½½ {len(urls)} ç¯‡æ–‡ç« \n\n"
                                   f"é¢„è®¡è€—æ—¶: {len(urls) * int(self.delay_var.get())} ç§’\n\n"
                                   f"ç¡®å®šè¦å¼€å§‹æ‰¹é‡ä¸‹è½½å—ï¼Ÿ")
        if not result:
            return
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œæ‰¹é‡ä¸‹è½½
        thread = threading.Thread(target=self._batch_download_worker, args=(urls,))
        thread.daemon = True
        thread.start()
    
    def _single_download_worker(self, url):
        """å•ç¯‡ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        try:
            self.msg_queue.put(('disable_buttons', None))
            self.msg_queue.put(('status', 'æ­£åœ¨ä¸‹è½½...'))
            self.msg_queue.put(('progress_single', 'åˆå§‹åŒ–ä¸­...'))
            
            # ğŸ†• ä¼˜åŒ–ï¼šå¼‚æ­¥åˆå§‹åŒ–scraperï¼Œåªåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–
            if not self.url_scraper and not self.scraper_initializing:
                self.scraper_initializing = True
                self.msg_queue.put(('progress_single', 'é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...'))
                self.log_message("ğŸ”§ é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...", "INFO")
                self.url_scraper = SimpleUrlScraper(headless=self.headless_var.get())
                self.scraper_initializing = False
                self.log_message("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ", "SUCCESS")
            
            format_type = self.single_format_var.get()
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            self.log_message(f"å¼€å§‹ä¸‹è½½æ–‡ç« : {url}")
            self.log_message(f"è¾“å‡ºæ ¼å¼: {format_type}")
            
            # é¦–å…ˆè·å–æ–‡ç« ä¿¡æ¯æå–æ ‡é¢˜
            self.msg_queue.put(('progress_single', 'è·å–æ–‡ç« ä¿¡æ¯...'))
            article_info = self.url_scraper.extract_article_info(url)
            
            # ç”Ÿæˆæ–‡ä»¶å
            if article_info and 'error' not in article_info and article_info.get('title'):
                title = article_info['title']
                safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:80]
                if not safe_title.strip():
                    safe_title = f"article_{timestamp}"
                self.log_message(f"æ–‡ç« æ ‡é¢˜: {title}")
            else:
                safe_title = f"article_{timestamp}"
                self.log_message("æœªèƒ½è·å–æ–‡ç« æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶å")
            
            # æ ¹æ®æ ¼å¼ä¸‹è½½
            success = False
            output_path = ""
            
            if format_type == "pdf":
                self.msg_queue.put(('progress_single', 'ç”ŸæˆPDFä¸­...'))
                pdf_filename = f"{safe_title}.pdf"
                output_path = os.path.join(self.output_dir, "pdf", pdf_filename)
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                success = self.url_scraper.save_as_pdf(url, output_path)
                
            elif format_type == "docx":
                self.msg_queue.put(('progress_single', 'ç”ŸæˆWordæ–‡æ¡£ä¸­...'))
                docx_filename = f"{safe_title}.docx"
                output_path = os.path.join(self.output_dir, "docx", docx_filename)
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                success = self.url_scraper.save_as_docx(url, output_path)

            elif format_type == "complete_html":
                self.msg_queue.put(('progress_single', 'ç”Ÿæˆå®Œæ•´HTMLä¸­...'))
                html_filename = f"{safe_title}.html"
                output_path = os.path.join(self.output_dir, "complete_html", html_filename)
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                success = self.url_scraper.save_complete_html(url, output_path)
                
            else:
                # å…¶ä»–æ ¼å¼æš‚æ—¶æ ‡è®°ä¸ºæˆåŠŸ
                self.msg_queue.put(('progress_single', f'ç”Ÿæˆ{format_type}æ ¼å¼ä¸­...'))
                success = True
                output_path = f"{self.output_dir}/{format_type}/{safe_title}"
            
            if success:
                self.log_message("âœ… ä¸‹è½½æˆåŠŸ!", "SUCCESS")
                self.msg_queue.put(('progress_single', f'âœ… ä¸‹è½½æˆåŠŸ: {os.path.basename(output_path)}'))
                self.msg_queue.put(('status', 'ä¸‹è½½å®Œæˆ'))
                
                # è‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“
                if self.enable_feishu_upload and format_type in ["pdf", "docx"]:
                    self.upload_to_feishu(output_path)
            else:
                self.log_message("âŒ ä¸‹è½½å¤±è´¥", "ERROR")
                self.msg_queue.put(('progress_single', 'âŒ ä¸‹è½½å¤±è´¥'))
                self.msg_queue.put(('status', 'ä¸‹è½½å¤±è´¥'))
                
        except Exception as e:
            self.log_message(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}", "ERROR")
            self.msg_queue.put(('progress_single', 'âŒ ä¸‹è½½å‡ºé”™'))
            self.msg_queue.put(('status', 'ä¸‹è½½å‡ºé”™'))
        finally:
            self.msg_queue.put(('enable_buttons', None))
    
    def _batch_download_worker(self, urls):
        """æ‰¹é‡ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        try:
            self.msg_queue.put(('disable_buttons', None))
            self.msg_queue.put(('status', 'æ‰¹é‡ä¸‹è½½ä¸­...'))
            self.msg_queue.put(('progress_batch', 'å‡†å¤‡æ‰¹é‡ä¸‹è½½...'))
            
            # ğŸ†• ä¼˜åŒ–ï¼šå¼‚æ­¥åˆå§‹åŒ–scraperï¼Œåªåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–
            if not self.url_scraper and not self.scraper_initializing:
                self.scraper_initializing = True
                self.msg_queue.put(('progress_batch', 'é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...'))
                self.log_message("ğŸ”§ é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...", "INFO")
                self.url_scraper = SimpleUrlScraper(headless=self.headless_var.get())
                self.scraper_initializing = False
                self.log_message("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ", "SUCCESS")
            
            # ç»Ÿè®¡å˜é‡
            total_urls = len(urls)
            success_count = 0
            failed_count = 0
            delay_seconds = int(self.delay_var.get())
            max_retries = int(self.retry_var.get())
            
            # ğŸ†• è·å–æ‰¹é‡ä¸‹è½½æ ¼å¼è®¾ç½®ï¼ˆä½¿ç”¨è‡ªåŠ¨ä¸‹è½½æ ¼å¼è®¾ç½®ï¼‰
            format_type = self.auto_format_var.get()
            
            self.log_message(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {total_urls} ç¯‡æ–‡ç« ")
            self.log_message(f"ä¸‹è½½æ ¼å¼: {format_type.upper()}")
            self.log_message(f"ä¸‹è½½å»¶è¿Ÿ: {delay_seconds} ç§’ï¼Œé‡è¯•æ¬¡æ•°: {max_retries}")
            
            # æ£€æŸ¥é£ä¹¦ä¸Šä¼ è®¾ç½®
            if self.batch_feishu_upload_var.get():
                self.log_message("ğŸ“š å·²å¯ç”¨æ‰¹é‡ä¸‹è½½åè‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“", "INFO")
            else:
                self.log_message("ğŸ“ ä»…ä¸‹è½½æ–‡ä»¶ï¼Œä¸ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“", "INFO")
            
            # è¿‡æ»¤å’ŒéªŒè¯URL
            valid_urls = []
            for i, url in enumerate(urls):
                if self._is_valid_wechat_url(url):
                    valid_urls.append(url)
                else:
                    self.log_message(f"è·³è¿‡æ— æ•ˆURL: {url}", "WARNING")
                    failed_count += 1
            
            self.log_message(f"æœ‰æ•ˆURL: {len(valid_urls)} ä¸ªï¼Œæ— æ•ˆURL: {failed_count} ä¸ª")
            
            # å¼€å§‹ä¸‹è½½æœ‰æ•ˆURL
            for i, url in enumerate(valid_urls):
                try:
                    current_progress = f"ä¸‹è½½è¿›åº¦: {i+1}/{len(valid_urls)}"
                    self.msg_queue.put(('progress_batch', current_progress))
                    
                    stats = f"æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count} | å‰©ä½™: {len(valid_urls) - i - 1}"
                    self.msg_queue.put(('stats_batch', stats))
                    
                    self.log_message(f"[{i+1}/{len(valid_urls)}] å¼€å§‹ä¸‹è½½: {url}")
                    
                    # å°è¯•ä¸‹è½½
                    download_success = False
                    for attempt in range(max_retries + 1):
                        try:
                            if attempt > 0:
                                self.log_message(f"é‡è¯•ç¬¬ {attempt} æ¬¡...")
                            
                            # è·å–æ–‡ç« ä¿¡æ¯
                            article_info = self.url_scraper.extract_article_info(url)
                            if not article_info or 'error' in article_info:
                                raise Exception("æ— æ³•è·å–æ–‡ç« ä¿¡æ¯")
                            
                            # ç”Ÿæˆæ–‡ä»¶å
                            title = article_info.get('title', f'article_{i+1}')
                            safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:80]
                            if not safe_title.strip():
                                safe_title = f"article_{i+1}_{datetime.now().strftime('%H%M%S')}"
                            
                            # ğŸ†• æ ¹æ®æ ¼å¼ç±»å‹ä¸‹è½½æ–‡ä»¶
                            if format_type == "pdf":
                                file_extension = ".pdf"
                                filename = f"{safe_title}{file_extension}"
                                output_path = os.path.join(self.output_dir, "batch_download", filename)
                                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                                
                                # å¤„ç†æ–‡ä»¶åå†²çª
                                counter = 1
                                while os.path.exists(output_path):
                                    filename = f"{safe_title}_{counter}{file_extension}"
                                    output_path = os.path.join(self.output_dir, "batch_download", filename)
                                    counter += 1
                                
                                download_success = self.url_scraper.save_as_pdf(url, output_path)
                                
                            elif format_type == "docx":
                                file_extension = ".docx"
                                filename = f"{safe_title}{file_extension}"
                                output_path = os.path.join(self.output_dir, "batch_download", filename)
                                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                                
                                # å¤„ç†æ–‡ä»¶åå†²çª
                                counter = 1
                                while os.path.exists(output_path):
                                    filename = f"{safe_title}_{counter}{file_extension}"
                                    output_path = os.path.join(self.output_dir, "batch_download", filename)
                                    counter += 1
                                
                                download_success = self.url_scraper.save_as_docx(url, output_path)
                                
                            else:
                                raise Exception(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
                            
                            if download_success:
                                self.log_message(f"âœ… ä¸‹è½½æˆåŠŸ: {title}", "SUCCESS")
                                
                                # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“
                                if self.batch_feishu_upload_var.get():
                                    self.log_message(f"ğŸ“š å¼€å§‹æ‰¹é‡ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“: {os.path.basename(output_path)}", "INFO")
                                    upload_success = self._upload_to_feishu_batch(output_path)
                                    if upload_success:
                                        self.log_message(f"âœ… æ‰¹é‡é£ä¹¦ä¸Šä¼ æˆåŠŸ: {title}", "SUCCESS")
                                    else:
                                        self.log_message(f"âŒ æ‰¹é‡é£ä¹¦ä¸Šä¼ å¤±è´¥: {title}", "WARNING")
                                
                                break
                            else:
                                raise Exception(f"{format_type.upper()}ç”Ÿæˆå¤±è´¥")
                                
                        except Exception as e:
                            self.log_message(f"ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}): {e}", "WARNING")
                            if attempt < max_retries:
                                import time
                                time.sleep(2)  # é‡è¯•å‰ç­‰å¾…2ç§’
                    
                    if download_success:
                        success_count += 1
                    else:
                        failed_count += 1
                        self.log_message(f"âŒ å½»åº•å¤±è´¥: {url}", "ERROR")
                    
                    # å»¶è¿Ÿå¤„ç†ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
                    if i < len(valid_urls) - 1:
                        self.log_message(f"ç­‰å¾… {delay_seconds} ç§’åä¸‹è½½ä¸‹ä¸€ç¯‡...")
                        import time
                        time.sleep(delay_seconds)
                        
                except Exception as e:
                    failed_count += 1
                    self.log_message(f"å¤„ç†URLæ—¶å‡ºé”™: {e}", "ERROR")
                    continue
            
            # å®Œæˆç»Ÿè®¡
            final_stats = f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count} | æ€»è®¡: {total_urls}"
            self.msg_queue.put(('stats_batch', final_stats))
            
            if self.batch_feishu_upload_var.get():
                self.msg_queue.put(('progress_batch', 'âœ… æ‰¹é‡ä¸‹è½½å’Œä¸Šä¼ å®Œæˆ'))
                self.msg_queue.put(('status', 'æ‰¹é‡ä¸‹è½½å’Œä¸Šä¼ å®Œæˆ'))
                self.log_message("ğŸ‰ æ‰¹é‡ä¸‹è½½å’Œé£ä¹¦ä¸Šä¼ ä»»åŠ¡å®Œæˆï¼", "SUCCESS")
            else:
                self.msg_queue.put(('progress_batch', 'âœ… æ‰¹é‡ä¸‹è½½å®Œæˆ'))
                self.msg_queue.put(('status', 'æ‰¹é‡ä¸‹è½½å®Œæˆ'))
                self.log_message("ğŸ‰ æ‰¹é‡ä¸‹è½½ä»»åŠ¡å®Œæˆï¼", "SUCCESS")
            
            self.log_message(final_stats, "INFO")
                
        except Exception as e:
            self.log_message(f"æ‰¹é‡ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}", "ERROR")
            self.msg_queue.put(('progress_batch', 'âŒ æ‰¹é‡ä¸‹è½½å‡ºé”™'))
            self.msg_queue.put(('status', 'æ‰¹é‡ä¸‹è½½å‡ºé”™'))
        finally:
            self.msg_queue.put(('enable_buttons', None))
    
    def _is_valid_wechat_url(self, url):
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å¾®ä¿¡æ–‡ç« URL"""
        if not url or not url.startswith('http'):
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¾®ä¿¡å…¬ä¼—å·åŸŸå
        return 'mp.weixin.qq.com/s' in url
    
    def toggle_auto_download(self):
        """åˆ‡æ¢è‡ªåŠ¨ä¸‹è½½æ¨¡å¼çŠ¶æ€"""
        if self.is_auto_collecting:
            self.stop_auto_download()
        else:
            self.start_auto_download()
    
    def start_auto_download(self):
        """å¼€å§‹è‡ªåŠ¨ä¸‹è½½æ¨¡å¼"""
        self.log_message("ğŸš€ æ­£åœ¨å¯åŠ¨è‡ªåŠ¨ä¸‹è½½æ¨¡å¼...", "INFO")
        
        self.is_auto_collecting = True
        self.auto_download_btn.config(text="â¹ï¸ åœæ­¢è‡ªåŠ¨ä¸‹è½½")
        self.auto_download_status.set("ğŸš€ ç›‘æ§ä¸­...")
        self.log_message("ğŸš€ è‡ªåŠ¨ä¸‹è½½æ¨¡å¼å·²å¯åŠ¨ï¼å¤åˆ¶å¾®ä¿¡æ–‡ç« é“¾æ¥å³å¯è‡ªåŠ¨ä¸‹è½½PDF", "SUCCESS")
        
        # æ¸…ç©ºç»Ÿè®¡å’ŒçŠ¶æ€
        self.collected_urls.clear()
        self.queue_stats = {"completed": 0, "failed": 0, "total": 0}
        self.log_message("ğŸ§¹ å·²æ¸…ç©ºç»Ÿè®¡æ•°æ®", "INFO")
        
        # ğŸ†• å¯åŠ¨æ—¶ä¸åˆå§‹åŒ–æµè§ˆå™¨ï¼Œå¤§å¤§åŠ å¿«å¯åŠ¨é€Ÿåº¦
        # æµè§ˆå™¨å°†åœ¨é¦–æ¬¡ä¸‹è½½æ—¶æ‰åˆå§‹åŒ–ï¼Œé¿å…å¯åŠ¨å¡é¡¿
        self.log_message("âš¡ å¿«é€Ÿå¯åŠ¨æ¨¡å¼ï¼šæµè§ˆå™¨å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–", "INFO")
        self.log_message("ğŸ”§ æ³¨æ„ï¼šæ•´åˆç‰ˆä¸Šä¼ å™¨æœ‰ç‹¬ç«‹çš„ä¸‹è½½å™¨ï¼Œä¸ä¼šå½±å“æµè§ˆå™¨å¯åŠ¨é€Ÿåº¦", "INFO")
        
        # åˆå§‹åŒ–é£ä¹¦é›†æˆ
        if self.enable_feishu_upload:
            self.log_message("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–é£ä¹¦é›†æˆ...", "INFO")
            self.log_message("âœ… é£ä¹¦é›†æˆå·²å¯ç”¨ (ä½¿ç”¨æ•´åˆç‰ˆä¸Šä¼ å™¨)", "SUCCESS")
        
        # è·å–å½“å‰æ–‡æœ¬æ¡†ä¸­çš„URLç”¨äºåˆå§‹åŒ–å»é‡é›†åˆ
        current_content = self.batch_urls_text.get("1.0", tk.END).strip()
        if current_content and not "https://mp.weixin.qq.com/s?__biz=xxx" in current_content:
            self.log_message("ğŸ“„ å¤„ç†ç°æœ‰æ–‡æœ¬æ¡†ä¸­çš„URL...", "INFO")
            count = 0
            for line in current_content.split('\n'):
                line = line.strip()
                if line and self._is_valid_wechat_url(line):
                    self.collected_urls.add(line)
                    count += 1
            self.log_message(f"ğŸ“ ä»æ–‡æœ¬æ¡†åŠ è½½äº† {count} ä¸ªå·²æœ‰URL", "INFO")
        
        # å¼€å§‹é˜Ÿåˆ—å¤„ç†
        if not self.is_queue_processing:
            self.log_message("ğŸ“¥ å¯åŠ¨ä¸‹è½½é˜Ÿåˆ—å¤„ç†å™¨...", "INFO")
            self.start_queue_processor()
        
        # è·å–åˆå§‹å‰ªè´´æ¿å†…å®¹
        try:
            self.last_clipboard_content = self.root.clipboard_get()
            self.log_message(f"ğŸ“‹ è·å–åˆå§‹å‰ªè´´æ¿å†…å®¹: {self.last_clipboard_content[:30]}...", "INFO")
        except:
            self.last_clipboard_content = ""
            self.log_message("ğŸ“‹ åˆå§‹å‰ªè´´æ¿ä¸ºç©º", "INFO")
        
        # å¼€å§‹ç›‘æ§å‰ªè´´æ¿
        self.log_message("ğŸ‘€ å¼€å§‹ç›‘æ§å‰ªè´´æ¿å˜åŒ– (æ¯500msæ£€æŸ¥ä¸€æ¬¡)", "INFO")
        self.check_clipboard()
    
    def stop_auto_download(self):
        """åœæ­¢è‡ªåŠ¨ä¸‹è½½æ¨¡å¼"""
        self.is_auto_collecting = False
        self.is_queue_processing = False
        self.auto_download_btn.config(text="ğŸš€ å¼€å¯è‡ªåŠ¨ä¸‹è½½æ¨¡å¼")
        self.auto_download_status.set("")
        self.log_message("è‡ªåŠ¨ä¸‹è½½æ¨¡å¼å·²åœæ­¢", "INFO")
    
    def check_clipboard(self):
        """æ£€æŸ¥å‰ªè´´æ¿å†…å®¹ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        if not self.is_auto_collecting:
            return
        
        try:
            # è·å–å‰ªè´´æ¿å†…å®¹
            clipboard_content = self.root.clipboard_get()
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦å˜åŒ–ä¸”ä¸ä¸ºç©º
            if (clipboard_content != self.last_clipboard_content and 
                clipboard_content.strip() and 
                len(clipboard_content.strip()) > 10):  # é¿å…å¤„ç†å¾ˆçŸ­çš„å†…å®¹
                
                self.last_clipboard_content = clipboard_content
                
                # å»é™¤å‰åç©ºç™½å­—ç¬¦
                cleaned_url = clipboard_content.strip()
                
                # è®°å½•æ£€æµ‹åˆ°çš„å˜åŒ–
                self.log_message(f"ğŸ“‹ æ£€æµ‹åˆ°å‰ªè´´æ¿å˜åŒ–: {cleaned_url[:50]}...", "INFO")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¾®ä¿¡æ–‡ç« é“¾æ¥
                if self._is_valid_wechat_url(cleaned_url):
                    self.log_message(f"âœ… æ£€æµ‹åˆ°å¾®ä¿¡æ–‡ç« é“¾æ¥!", "SUCCESS")
                    # ä½¿ç”¨æ•´åˆç‰ˆå¤„ç†
                    self._process_url_with_integrated_uploader(cleaned_url)
                else:
                    self.log_message(f"âŒ ä¸æ˜¯å¾®ä¿¡æ–‡ç« é“¾æ¥: {cleaned_url[:30]}...", "WARNING")
                    
        except tk.TclError:
            # å‰ªè´´æ¿ä¸ºç©ºæˆ–æ— æ³•è®¿é—®ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            pass
        except Exception as e:
            self.log_message(f"æ£€æŸ¥å‰ªè´´æ¿æ—¶å‡ºé”™: {e}", "ERROR")
        
        # ç»§ç»­ç›‘æ§ï¼ˆæ¯500æ¯«ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
        if self.is_auto_collecting:
            self.root.after(500, self.check_clipboard)
    
    def add_url_and_download(self, url):
        """å°†URLæ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—å¹¶å¼€å§‹ä¸‹è½½"""
        url = url.strip()
        
        self.log_message(f"ğŸ”„ å¤„ç†URL: {url[:50]}...", "INFO")
        
        # æ£€æŸ¥æ˜¯å¦é‡å¤
        if url in self.collected_urls:
            self.log_message(f"é“¾æ¥é‡å¤ï¼Œè·³è¿‡: {url[:50]}...", "WARNING")
            return
        
        # æ·»åŠ åˆ°å»é‡é›†åˆ
        self.collected_urls.add(url)
        self.log_message(f"ğŸ“ å·²æ·»åŠ åˆ°å»é‡é›†åˆ (å½“å‰ {len(self.collected_urls)} ä¸ª)", "INFO")
        
        # æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—
        self.download_queue.put(url)
        self.queue_stats["total"] += 1
        self.log_message(f"ğŸ“¥ å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ— (é˜Ÿåˆ—å¤§å°: {self.download_queue.qsize()})", "INFO")
        
        # æ·»åŠ åˆ°æ–‡æœ¬æ¡†æ˜¾ç¤º
        current_content = self.batch_urls_text.get("1.0", tk.END).strip()
        
        # å¦‚æœæ–‡æœ¬æ¡†ä¸ºç©ºæˆ–åªæœ‰ç¤ºä¾‹å†…å®¹ï¼Œåˆ™æ¸…ç©ºåæ·»åŠ 
        if not current_content or "https://mp.weixin.qq.com/s?__biz=xxx" in current_content:
            self.log_message("ğŸ“„ æ¸…ç©ºæ–‡æœ¬æ¡†å¹¶æ·»åŠ æ–°URL", "INFO")
            self.batch_urls_text.delete("1.0", tk.END)
            self.batch_urls_text.insert(tk.END, url)
        else:
            # åœ¨æœ«å°¾æ·»åŠ æ–°è¡Œå’ŒURL
            self.log_message("ğŸ“„ åœ¨æ–‡æœ¬æ¡†æœ«å°¾æ·»åŠ æ–°URL", "INFO")
            self.batch_urls_text.insert(tk.END, f"\n{url}")
        
        # æ»šåŠ¨åˆ°åº•éƒ¨
        self.batch_urls_text.see(tk.END)
        
        # è®°å½•æ—¥å¿—
        self.log_message(f"ğŸ¯ å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—: {url[:50]}...", "SUCCESS")
        
        # æ›´æ–°çŠ¶æ€
        queue_size = self.download_queue.qsize()
        status_msg = f"é˜Ÿåˆ—ä¸­: {queue_size} ä¸ª"
        self.update_download_status(status_msg)
        self.log_message(f"ğŸ“Š æ›´æ–°çŠ¶æ€: {status_msg}", "INFO")
    
    def clean_duplicate_urls(self):
        """æ¸…ç†æ–‡æœ¬æ¡†ä¸­çš„é‡å¤URL"""
        current_content = self.batch_urls_text.get("1.0", tk.END).strip()
        if not current_content:
            return
        
        # åˆ†å‰²æˆè¡Œå¹¶å»é‡
        lines = current_content.split('\n')
        unique_urls = []
        seen_urls = set()
        
        for line in lines:
            line = line.strip()
            if line and self._is_valid_wechat_url(line):
                if line not in seen_urls:
                    unique_urls.append(line)
                    seen_urls.add(line)
        
        # æ›´æ–°æ–‡æœ¬æ¡†
        self.batch_urls_text.delete("1.0", tk.END)
        self.batch_urls_text.insert(tk.END, '\n'.join(unique_urls))
        
        # æ›´æ–°å»é‡é›†åˆ
        self.collected_urls = seen_urls.copy()
        
        removed_count = len(lines) - len(unique_urls)
        if removed_count > 0:
            self.log_message(f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {removed_count} ä¸ªé‡å¤é“¾æ¥", "INFO")
    
    def start_queue_processor(self):
        """å¯åŠ¨é˜Ÿåˆ—å¤„ç†å™¨"""
        self.is_queue_processing = True
        threading.Thread(target=self._queue_processor_worker, daemon=True).start()
        self.log_message("ğŸ“¥ ä¸‹è½½é˜Ÿåˆ—å¤„ç†å™¨å·²å¯åŠ¨", "INFO")
    
    def _queue_processor_worker(self):
        """é˜Ÿåˆ—å¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.is_queue_processing:
            try:
                # ä»é˜Ÿåˆ—è·å–URLï¼ˆè¶…æ—¶1ç§’ï¼‰
                url = self.download_queue.get(timeout=1)
                
                if not self.is_queue_processing:
                    break
                
                # å¼€å§‹ä¸‹è½½
                self.current_downloading_url = url
                self._download_single_url(url)
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.download_queue.task_done()
                self.current_downloading_url = None
                
            except queue.Empty:
                continue
            except Exception as e:
                self.log_message(f"é˜Ÿåˆ—å¤„ç†å‡ºé”™: {e}", "ERROR")
        
        self.log_message("ğŸ“¥ ä¸‹è½½é˜Ÿåˆ—å¤„ç†å™¨å·²åœæ­¢", "INFO")
    
    def _download_single_url(self, url):
        """ä¸‹è½½å•ä¸ªURL - æ”¯æŒPDFå’ŒWordæ ¼å¼"""
        try:
            format_name = "PDF" if self.auto_download_format == "pdf" else "Wordæ–‡æ¡£"
            self.log_message(f"ğŸš€ å¼€å§‹ä¸‹è½½{format_name}: {url[:50]}...", "INFO")
            self.update_download_status(f"â¬‡ï¸ ä¸‹è½½{format_name}ä¸­...")
            
            # ğŸ†• ä¼˜åŒ–ï¼šæ‡’åŠ è½½åˆå§‹åŒ–scraperï¼Œåªåœ¨çœŸæ­£éœ€è¦æ—¶åˆå§‹åŒ–
            if not self.url_scraper and not self.scraper_initializing:
                self.scraper_initializing = True
                self.log_message("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–URL scraperï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰...", "INFO")
                self.url_scraper = SimpleUrlScraper(headless=self.headless_var.get())
                self.scraper_initializing = False
                self.log_message("âœ… URL scraperåˆå§‹åŒ–å®Œæˆ", "SUCCESS")
            
            # è·å–æ–‡ç« ä¿¡æ¯
            article_info = self.url_scraper.extract_article_info(url)
            if not article_info or 'error' in article_info:
                raise Exception("æ— æ³•è·å–æ–‡ç« ä¿¡æ¯")
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºæ–‡ç« æ ‡é¢˜ï¼‰
            title = article_info.get('title', 'unknown_article')
            safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:80]
            if not safe_title.strip():
                safe_title = f"article_{datetime.now().strftime('%H%M%S')}"
            
            # æ ¹æ®æ ¼å¼ç”Ÿæˆæ–‡ä»¶æ‰©å±•å
            file_ext = ".pdf" if self.auto_download_format == "pdf" else ".docx"
            filename = f"{safe_title}{file_ext}"
            output_path = os.path.join(self.output_dir, "auto_download", filename)
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            original_path = output_path
            while os.path.exists(output_path):
                name_without_ext = safe_title
                filename = f"{name_without_ext}_{counter}{file_ext}"
                output_path = os.path.join(self.output_dir, "auto_download", filename)
                counter += 1
            
            # æ ¹æ®æ ¼å¼ä¸‹è½½æ–‡ä»¶
            success = False
            if self.auto_download_format == "pdf":
                success = self.url_scraper.save_as_pdf(url, output_path)
            elif self.auto_download_format == "docx":
                success = self.url_scraper.save_as_docx(url, output_path)
            
            if success:
                self.queue_stats["completed"] += 1
                self.log_message(f"âœ… {format_name}ä¸‹è½½æˆåŠŸ: {title}", "SUCCESS")
                self.log_message(f"ğŸ“ æ–‡ä»¶ä¿å­˜: {filename}", "INFO")
                
                # è‡ªåŠ¨ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“
                if self.enable_feishu_upload:
                    self.upload_to_feishu(output_path)
            else:
                raise Exception(f"{format_name}ç”Ÿæˆå¤±è´¥")
                
        except Exception as e:
            self.queue_stats["failed"] += 1
            self.log_message(f"âŒ {format_name}ä¸‹è½½å¤±è´¥: {e}", "ERROR")
        
        finally:
            # æ›´æ–°çŠ¶æ€
            self._update_queue_stats()
    
    def _update_queue_stats(self):
        """æ›´æ–°é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        completed = self.queue_stats["completed"]
        failed = self.queue_stats["failed"]
        total = self.queue_stats["total"]
        queue_size = self.download_queue.qsize()
        
        if queue_size > 0:
            status = f"â¬‡ï¸ é˜Ÿåˆ—: {queue_size} | å®Œæˆ: {completed} | å¤±è´¥: {failed}"
        elif total > 0:
            status = f"âœ… å…¨éƒ¨å®Œæˆ | æˆåŠŸ: {completed} | å¤±è´¥: {failed} | æ€»è®¡: {total}"
        else:
            status = "ğŸš€ å°±ç»ª"
        
        self.update_download_status(status)
    
    def update_download_status(self, status):
        """æ›´æ–°ä¸‹è½½çŠ¶æ€æ˜¾ç¤º"""
        if hasattr(self, 'auto_download_status'):
            self.auto_download_status.set(status)
    
    def toggle_feishu_upload(self):
        """åˆ‡æ¢é£ä¹¦ä¸Šä¼ åŠŸèƒ½"""
        self.enable_feishu_upload = self.feishu_upload_var.get()
        
        if self.enable_feishu_upload:
            # ä½¿ç”¨æ•´åˆç‰ˆé…ç½®
            self.feishu_status_var.set("âœ… æ•´åˆç‰ˆä¸Šä¼ å™¨å·²å¯ç”¨")
            self.log_message("âœ… é£ä¹¦å®Œæ•´åŠŸèƒ½å·²å¯ç”¨ï¼ˆæ•´åˆç‰ˆä¸Šä¼ å™¨ï¼‰", "SUCCESS")
        else:
            self.feishu_status_var.set("âŒ é£ä¹¦é›†æˆå·²ç¦ç”¨")
            self.log_message("é£ä¹¦çŸ¥è¯†åº“é›†æˆå·²ç¦ç”¨", "INFO")

    def check_oauth_status(self):
        """æ£€æŸ¥OAuthè®¤è¯çŠ¶æ€"""
        try:
            from feishu_oauth_client import FeishuOAuth2Client
            
            oauth_client = FeishuOAuth2Client(self.feishu_app_id, self.feishu_app_secret)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„token
            if oauth_client.load_tokens():
                access_token = oauth_client.get_valid_access_token()
                if access_token:
                    self.oauth_status_var.set("âœ… OAuthè®¤è¯æ­£å¸¸ï¼Œtokenæœ‰æ•ˆ")
                    self.oauth_status_label.config(foreground='green')
                    self.log_message("OAuthè®¤è¯çŠ¶æ€ï¼šæ­£å¸¸", "SUCCESS")
                else:
                    self.oauth_status_var.set("âš ï¸  OAuth tokenå·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°è®¤è¯")
                    self.oauth_status_label.config(foreground='orange')
                    self.log_message("OAuthè®¤è¯çŠ¶æ€ï¼štokenå·²è¿‡æœŸ", "WARNING")
            else:
                self.oauth_status_var.set("âŒ æœªæ‰¾åˆ°OAuthè®¤è¯ä¿¡æ¯ï¼Œéœ€è¦è¿›è¡Œé¦–æ¬¡è®¤è¯")
                self.oauth_status_label.config(foreground='red')
                self.log_message("OAuthè®¤è¯çŠ¶æ€ï¼šæœªè®¤è¯", "WARNING")
                
        except Exception as e:
            self.oauth_status_var.set(f"âŒ OAuthçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            self.oauth_status_label.config(foreground='red')
            self.log_message(f"OAuthçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}", "ERROR")

    def start_oauth_reauth(self):
        """å¯åŠ¨OAuthé‡æ–°è®¤è¯æµç¨‹"""
        try:
            self.log_message("ğŸ”„ å¼€å§‹OAuthé‡æ–°è®¤è¯æµç¨‹...", "INFO")
            self.oauth_reauth_btn.config(state='disabled', text="è®¤è¯ä¸­...")
            
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œè®¤è¯ï¼Œé¿å…é˜»å¡UI
            def oauth_thread():
                try:
                    from feishu_oauth_client import FeishuOAuth2Client
                    
                    oauth_client = FeishuOAuth2Client(self.feishu_app_id, self.feishu_app_secret)
                    
                    # å¯åŠ¨OAuthæµç¨‹
                    success = oauth_client.start_oauth_flow()
                    
                    if success:
                        self.msg_queue.put(('log', "[SUCCESS] ğŸ‰ OAuthé‡æ–°è®¤è¯æˆåŠŸï¼\n"))
                        self.msg_queue.put(('oauth_success', None))
                    else:
                        self.msg_queue.put(('log', "[ERROR] âŒ OAuthé‡æ–°è®¤è¯å¤±è´¥\n"))
                        self.msg_queue.put(('oauth_failed', None))
                        
                except Exception as e:
                    self.msg_queue.put(('log', f"[ERROR] OAuthè®¤è¯å¼‚å¸¸: {e}\n"))
                    self.msg_queue.put(('oauth_failed', None))
            
            import threading
            thread = threading.Thread(target=oauth_thread, daemon=True)
            thread.start()
            
            # æç¤ºç”¨æˆ·
            messagebox.showinfo("OAuthè®¤è¯", 
                              "å°†æ‰“å¼€æµè§ˆå™¨è¿›è¡ŒOAuthè®¤è¯\n\n"
                              "è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆæˆæƒæµç¨‹\n"
                              "è®¤è¯å®Œæˆåä¼šè‡ªåŠ¨è¿”å›ç¨‹åº")
            
        except Exception as e:
            self.log_message(f"å¯åŠ¨OAuthè®¤è¯å¤±è´¥: {e}", "ERROR")
            self.oauth_reauth_btn.config(state='normal', text="ğŸ”„ é‡æ–°è®¤è¯")

    def revoke_oauth_tokens(self):
        """æ’¤é”€OAuthè®¤è¯"""
        try:
            if messagebox.askyesno("ç¡®è®¤æ’¤é”€", "ç¡®å®šè¦æ’¤é”€OAuthè®¤è¯å—ï¼Ÿ\nè¿™å°†åˆ é™¤æ‰€æœ‰è®¤è¯ä¿¡æ¯ã€‚"):
                from feishu_oauth_client import FeishuOAuth2Client
                
                oauth_client = FeishuOAuth2Client(self.feishu_app_id, self.feishu_app_secret)
                oauth_client.revoke_tokens()
                
                self.log_message("ğŸ—‘ï¸  OAuthè®¤è¯å·²æ’¤é”€", "INFO")
                self.check_oauth_status()  # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
                
        except Exception as e:
            self.log_message(f"æ’¤é”€OAuthè®¤è¯å¤±è´¥: {e}", "ERROR")

    def handle_oauth_result(self, success: bool):
        """å¤„ç†OAuthè®¤è¯ç»“æœ"""
        if success:
            self.oauth_status_var.set("âœ… OAuthé‡æ–°è®¤è¯æˆåŠŸï¼")
            self.oauth_status_label.config(foreground='green')
        else:
            self.oauth_status_var.set("âŒ OAuthé‡æ–°è®¤è¯å¤±è´¥")
            self.oauth_status_label.config(foreground='red')
        
        self.oauth_reauth_btn.config(state='normal', text="ğŸ”„ é‡æ–°è®¤è¯")
        
        # é‡æ–°æ£€æŸ¥çŠ¶æ€
        self.root.after(2000, self.check_oauth_status)
    
    
    
    def _process_url_with_integrated_uploader(self, url: str):
        """ä½¿ç”¨æ•´åˆç‰ˆä¸Šä¼ å™¨å¤„ç†URL - æ”¯æŒæ™ºèƒ½åˆ†ç±»å’Œæ™ºèƒ½é‡å¤æ£€æµ‹"""
        try:
            from pathlib import Path
            from integrated_auto_download_uploader import IntegratedAutoUploader
            
            self.log_message(f"ğŸš€ ä½¿ç”¨æ•´åˆç‰ˆå¤„ç†å™¨å¤„ç†URL: {url[:50]}...", "INFO")
            
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if url in self.collected_urls:
                self.log_message(f"ğŸ“‹ é“¾æ¥é‡å¤ï¼Œè·³è¿‡: {url[:50]}...", "WARNING")
                return
            
            # æ·»åŠ åˆ°å»é‡é›†åˆå’Œç•Œé¢
            self.collected_urls.add(url)
            self.add_url_and_download(url)
            
            # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†ï¼Œé¿å…é˜»å¡UI
            def background_process():
                try:
                    # ğŸ”¥ ä½¿ç”¨GUIçš„æ™ºèƒ½åˆ†ç±»å¤„ç†æµç¨‹
                    self.log_message(f"ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†ç±»å¤„ç†æµç¨‹", "INFO")
                    
                    # æ­¥éª¤1: ä½¿ç”¨æ•´åˆç‰ˆä¸‹è½½æ–‡ä»¶
                    uploader = IntegratedAutoUploader(self.feishu_app_id, self.feishu_app_secret)
                    temp_file_path = uploader.download_article(url, self.auto_download_format)
                    
                    if not temp_file_path:
                        self.log_message(f"âŒ æ–‡ä»¶ä¸‹è½½å¤±è´¥: {url[:50]}...", "ERROR")
                        self.queue_stats["failed"] += 1
                        return
                    
                    filename = temp_file_path.name
                    title = temp_file_path.stem
                    
                    self.log_message(f"âœ… æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename}", "SUCCESS")
                    self.log_message(f"ğŸ“ æå–çš„æ–‡ä»¶æ ‡é¢˜: {title}", "INFO")
                    
                    # æ­¥éª¤2: ä½¿ç”¨GUIçš„æ™ºèƒ½åˆ†ç±»åŠŸèƒ½
                    self.log_message(f"ğŸ§  æ‰§è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æ...", "INFO")
                    target_location = self.find_target_wiki_location(title)
                    target_url = target_location.get("wiki_url", self.default_wiki_location)
                    as_subpage = target_location.get("as_subpage", True)
                    
                    self.log_message(f"ğŸ¯ æ™ºèƒ½åˆ†ç±»ç»“æœ: {target_url[:50]}...", "INFO")
                    self.log_message(f"ğŸ“„ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}", "INFO")
                    
                    # æ­¥éª¤3: æ™ºèƒ½é‡å¤æ£€æµ‹ - åœ¨ç›®æ ‡ä½ç½®æ£€æŸ¥é‡å¤
                    self.log_message(f"ğŸ” åœ¨ç›®æ ‡åˆ†ç±»ä½ç½®æ£€æŸ¥é‡å¤...", "INFO")
                    
                    # æå–ç›®æ ‡ä½ç½®çš„wiki_token
                    target_wiki_token = None
                    if "wiki/" in target_url:
                        if "?" in target_url:
                            clean_url = target_url.split("?")[0]
                        else:
                            clean_url = target_url
                        
                        if "/wiki/space/" in clean_url:
                            target_wiki_token = clean_url.split("/wiki/space/")[-1]
                        elif "/wiki/" in clean_url:
                            target_wiki_token = clean_url.split("/wiki/")[-1]
                    
                    self.log_message(f"ğŸ“‹ ç›®æ ‡wiki_token: {target_wiki_token}", "INFO")
                    
                    # åœ¨ç›®æ ‡åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æŸ¥é‡å¤æ–‡ç« 
                    if target_wiki_token:
                        self.log_message(f"ğŸ“‚ åœ¨åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æŸ¥é‡å¤: {target_wiki_token}", "INFO")
                        wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                            uploader.space_id, 
                            title, 
                            target_wiki_token  # åœ¨åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æŸ¥æ˜¯å¦æœ‰åŒåæ–‡ç« 
                        )
                    else:
                        # å¦‚æœæ— æ³•è§£æç›®æ ‡tokenï¼Œä½¿ç”¨é»˜è®¤ä½ç½®æ£€æŸ¥
                        self.log_message(f"âš ï¸ æ— æ³•è§£æç›®æ ‡tokenï¼Œä½¿ç”¨é»˜è®¤ä½ç½®æ£€æŸ¥...", "WARNING")
                        default_wiki_token = self.default_wiki_location.split("/wiki/")[-1] if "/wiki/" in self.default_wiki_location else None
                        if default_wiki_token:
                            self.log_message(f"ğŸ“‚ ä½¿ç”¨é»˜è®¤ä½ç½®: {default_wiki_token}", "INFO")
                            wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                                uploader.space_id, 
                                title, 
                                default_wiki_token
                            )
                        else:
                            # æœ€åå›é€€åˆ°çˆ¶èŠ‚ç‚¹æ£€æŸ¥
                            self.log_message(f"âš ï¸ é»˜è®¤ä½ç½®ä¹Ÿæ— æ³•è§£æï¼Œå›é€€åˆ°çˆ¶èŠ‚ç‚¹æ£€æŸ¥...", "WARNING")
                            wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                                uploader.space_id, 
                                title, 
                                uploader.parent_wiki_token
                            )
                    
                    if wiki_exists:
                        self.log_message(f"ğŸ“‹ ç›®æ ‡åˆ†ç±»å­èŠ‚ç‚¹ä¸‹å·²å­˜åœ¨åŒåæ–‡æ¡£ï¼Œè·³è¿‡: {title}", "WARNING")
                        self.queue_stats["completed"] += 1
                        return
                    
                    # æ­¥éª¤4: ä¸Šä¼ åˆ°äº‘æ–‡æ¡£
                    self.log_message(f"â˜ï¸ ä¸Šä¼ åˆ°äº‘æ–‡æ¡£...", "INFO")
                    file_token = uploader.upload_to_drive(temp_file_path)
                    
                    if file_token == "DUPLICATE":
                        self.log_message(f"ğŸ“‹ äº‘æ–‡æ¡£é‡å¤è·³è¿‡: {filename}", "WARNING")
                        self.queue_stats["completed"] += 1
                        return
                    
                    if not file_token:
                        self.log_message(f"âŒ äº‘æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {filename}", "ERROR")
                        self.queue_stats["failed"] += 1
                        return
                    
                    # æ­¥éª¤5: æ™ºèƒ½è½¬ç§»åˆ°ç›®æ ‡çŸ¥è¯†åº“ä½ç½®
                    self.log_message(f"ğŸ“š æ™ºèƒ½è½¬ç§»åˆ°ç›®æ ‡ä½ç½®...", "INFO")
                    wiki_result = self._smart_move_to_wiki(uploader, file_token, filename, target_location)
                    
                    if wiki_result:
                        if wiki_result.startswith("75"):  # task_idæ ¼å¼
                            self.log_message(f"â³ æ™ºèƒ½è½¬ç§»ä»»åŠ¡å·²æäº¤: {wiki_result}", "SUCCESS")
                        else:  # wiki_tokenæ ¼å¼
                            wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_result}"
                            self.log_message(f"âœ… æ™ºèƒ½åˆ†ç±»å¤„ç†æˆåŠŸ: {filename}", "SUCCESS")
                            self.log_message(f"ğŸ“– æ–‡æ¡£é“¾æ¥: {wiki_url}", "INFO")
                        
                        self.log_message(f"ğŸ¯ å·²è½¬ç§»åˆ°: {target_url[:50]}...", "SUCCESS")
                        self.queue_stats["completed"] += 1
                    else:
                        self.log_message(f"âŒ æ™ºèƒ½è½¬ç§»å¤±è´¥: {filename}", "ERROR")
                        self.queue_stats["failed"] += 1
                        
                except Exception as e:
                    self.log_message(f"âŒ æ™ºèƒ½åˆ†ç±»å¤„ç†å¼‚å¸¸: {e}", "ERROR")
                    self.queue_stats["failed"] += 1
                
                finally:
                    if 'uploader' in locals():
                        uploader.cleanup()
                    self._update_queue_stats()
            
            # åœ¨çº¿ç¨‹ä¸­è¿è¡Œ
            import threading
            thread = threading.Thread(target=background_process, daemon=True)
            thread.start()
            
        except Exception as e:
            self.log_message(f"âŒ æ™ºèƒ½åˆ†ç±»å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}", "ERROR")

    def _process_with_smart_classification(self, uploader, url: str, format_type: str, target_location: dict) -> bool:
        """ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å¤„ç†å•ä¸ªURLçš„å®Œæ•´æµç¨‹"""
        try:
            from pathlib import Path
            
            format_name = "PDF" if format_type == "pdf" else "Wordæ–‡æ¡£"
            self.log_message(f"ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†ç±»{format_name}å¤„ç†: {url[:50]}...", "INFO")
            
            # æ­¥éª¤1: ä¸‹è½½æ–‡ä»¶ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•åï¼‰
            temp_file_path = uploader.download_article(url, format_type)
            if not temp_file_path:
                self.log_message(f"âŒ {format_name}ä¸‹è½½å¤±è´¥", "ERROR")
                return False
            
            filename = temp_file_path.name  # Pathå¯¹è±¡ä½¿ç”¨.nameå±æ€§
            title = temp_file_path.stem  # Pathå¯¹è±¡ä½¿ç”¨.stemå±æ€§è·å–ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
            
            self.log_message(f"âœ… {format_name}ä¸‹è½½æˆåŠŸ: {filename}", "SUCCESS")
            self.log_message(f"ğŸ“ æå–çš„æ–‡ä»¶æ ‡é¢˜: {title}", "INFO")
            
            # ğŸ†• é‡æ–°æ‰§è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æï¼ˆåŸºäºå®é™…æ–‡ä»¶æ ‡é¢˜ï¼‰
            self.log_message(f"ğŸ”„ åŸºäºæ–‡ä»¶æ ‡é¢˜é‡æ–°æ‰§è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æ", "INFO")
            updated_target_location = self.find_target_wiki_location(title)
            
            # æ¯”è¾ƒåŸå§‹åˆ†ç±»å’ŒåŸºäºæ–‡ä»¶åçš„åˆ†ç±»
            original_url = target_location.get("wiki_url", "")
            updated_url = updated_target_location.get("wiki_url", "")
            
            if original_url != updated_url:
                self.log_message(f"ğŸ“Š æ™ºèƒ½åˆ†ç±»ç»“æœæ›´æ–°:", "INFO")
                self.log_message(f"   åŸå§‹åˆ†ç±»: {original_url[:50]}...", "INFO")
                self.log_message(f"   æ›´æ–°åˆ†ç±»: {updated_url[:50]}...", "INFO")
                target_location = updated_target_location
            else:
                self.log_message(f"ğŸ“Š æ™ºèƒ½åˆ†ç±»ç»“æœä¸€è‡´ï¼Œä½¿ç”¨åŸåˆ†ç±»", "INFO")
            
            # æ­¥éª¤2: æ£€æŸ¥é‡å¤
            if uploader.check_file_duplicate_by_title(title):
                self.log_message(f"ğŸ“‹ é£ä¹¦ä¸­å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œè·³è¿‡ä¸Šä¼ : {filename}", "WARNING")
                return True
            
            # æ­¥éª¤3: ä¸Šä¼ åˆ°äº‘æ–‡æ¡£
            self.log_message(f"â˜ï¸ ä¸Šä¼ {format_name}åˆ°äº‘æ–‡æ¡£...", "INFO")
            file_token = uploader.upload_to_drive(temp_file_path)  # temp_file_pathå·²ç»æ˜¯Pathå¯¹è±¡
            
            if not file_token:
                self.log_message(f"âŒ äº‘æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {filename}", "ERROR")
                return False
            
            # æ­¥éª¤4: æ™ºèƒ½è½¬ç§»åˆ°çŸ¥è¯†åº“
            target_url = target_location.get("wiki_url", self.default_wiki_location)
            self.log_message(f"ğŸ“š æ™ºèƒ½è½¬ç§»{format_name}åˆ°çŸ¥è¯†åº“: {target_url[:50]}...", "INFO")
            
            wiki_result = self._smart_move_to_wiki(uploader, file_token, filename, target_location)
            
            if wiki_result:
                if wiki_result.startswith("75"):  # task_idæ ¼å¼
                    self.log_message(f"â³ {format_name}æ™ºèƒ½è½¬ç§»ä»»åŠ¡å·²æäº¤: {wiki_result}", "SUCCESS")
                else:  # wiki_tokenæ ¼å¼
                    wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_result}"
                    self.log_message(f"âœ… {format_name}æ™ºèƒ½ä¸Šä¼ æˆåŠŸ: {filename}", "SUCCESS")
                    self.log_message(f"ğŸ“– æ–‡æ¡£é“¾æ¥: {wiki_url}", "INFO")
                
                self.log_message(f"ğŸ¯ å·²æ™ºèƒ½è½¬ç§»åˆ°: {target_url[:50]}...", "SUCCESS")
                return True
            else:
                self.log_message(f"âŒ {format_name}æ™ºèƒ½è½¬ç§»å¤±è´¥: {filename}", "ERROR")
                return False
                
        except Exception as e:
            self.log_message(f"æ™ºèƒ½åˆ†ç±»å¤„ç†å¼‚å¸¸: {e}", "ERROR")
            return False

    def test_smart_classification(self, test_title: str = None):
        """æµ‹è¯•æ™ºèƒ½åˆ†ç±»åŠŸèƒ½"""
        if not test_title:
            test_title = "Pythonç¼–ç¨‹æŠ€æœ¯å…¥é—¨æ•™ç¨‹"
        
        self.log_message(f"ğŸ§ª æµ‹è¯•æ™ºèƒ½åˆ†ç±»åŠŸèƒ½", "INFO")
        self.log_message(f"ğŸ“ æµ‹è¯•æ ‡é¢˜: {test_title}", "INFO")
        
        target_location = self.find_target_wiki_location(test_title)
        target_url = target_location.get("wiki_url", "æœªçŸ¥")
        as_subpage = target_location.get("as_subpage", True)
        
        self.log_message(f"ğŸ¯ åˆ†ç±»ç»“æœ - ç›®æ ‡ä½ç½®: {target_url}", "SUCCESS")
        self.log_message(f"ğŸ“‹ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}", "SUCCESS")
        
        return target_location

    def run_classification_test(self):
        """è¿è¡Œæ™ºèƒ½åˆ†ç±»æµ‹è¯•"""
        try:
            test_title = self.test_title_var.get().strip()
            if not test_title:
                messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥æµ‹è¯•æ ‡é¢˜")
                return
            
            # å…ˆä¿å­˜å½“å‰é…ç½®
            self.save_wiki_config()
            
            # æ‰§è¡Œæµ‹è¯•
            target_location = self.test_smart_classification(test_title)
            
            # æ˜¾ç¤ºç»“æœ
            target_url = target_location.get("wiki_url", "æœªåŒ¹é…")
            as_subpage = target_location.get("as_subpage", True)
            matched_keywords = []
            
            # æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯
            title_lower = test_title.lower()
            for location in self.wiki_locations:
                keywords = location.get("keywords", [])
                for keyword in keywords:
                    if keyword.lower() in title_lower:
                        matched_keywords.append(keyword)
                        break
            
            if matched_keywords:
                result_text = f"âœ… åŒ¹é…å…³é”®è¯: {', '.join(matched_keywords)} | ç›®æ ‡: {target_url[:30]}... | å­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}"
            else:
                # ä½¿ç”¨é»˜è®¤ä½ç½®è®¾ç½®
                default_as_subpage = self.default_as_subpage_var.get() if hasattr(self, 'default_as_subpage_var') else True
                result_text = f"ğŸ  ä½¿ç”¨é»˜è®¤ä½ç½®: {target_url[:30]}... | å­é¡µé¢: {'æ˜¯' if default_as_subpage else 'å¦'}"
            
            self.test_result_var.set(result_text)
            
        except Exception as e:
            self.test_result_var.set(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            self.log_message(f"æ™ºèƒ½åˆ†ç±»æµ‹è¯•å¤±è´¥: {e}", "ERROR")

    def upload_to_feishu(self, file_path: str) -> bool:
        """ä¸Šä¼ æ–‡ä»¶åˆ°é£ä¹¦çŸ¥è¯†åº“ï¼ˆæ”¯æŒPDFå’ŒWordæ–‡æ¡£ï¼‰- æ”¯æŒæ™ºèƒ½åˆ†ç±»
        ğŸ†• DOCXæ–‡ä»¶ä½¿ç”¨ä¸‰æ­¥å¯¼å…¥æµç¨‹ï¼Œè½¬æ¢ä¸ºé£ä¹¦äº‘æ–‡æ¡£æ ¼å¼
        """
        if not self.enable_feishu_upload:
            return True
        
        try:
            filename = os.path.basename(file_path)
            file_ext = os.path.splitext(filename)[1].lower()
            file_type = "PDF" if file_ext == ".pdf" else "Wordæ–‡æ¡£" if file_ext == ".docx" else "æ–‡ä»¶"
            
            # ä»æ–‡ä»¶åæå–æ ‡é¢˜ï¼ˆå»æ‰æ‰©å±•åï¼‰
            title = os.path.splitext(filename)[0]
            
            self.log_message(f"ğŸš€ å¼€å§‹é£ä¹¦{file_type}æ™ºèƒ½ä¸Šä¼ : {filename}", "INFO")
            self.log_message(f"ğŸ“ åˆ†ææ ‡é¢˜: {title}", "INFO")
            
            # ğŸ†• ä½¿ç”¨æ™ºèƒ½åˆ†ç±»åŠŸèƒ½æ‰¾åˆ°ç›®æ ‡ä½ç½®
            target_location = self.find_target_wiki_location(title)
            target_url = target_location.get("wiki_url", self.default_wiki_location)
            as_subpage = target_location.get("as_subpage", True)
            
            self.log_message(f"ğŸ¯ æ™ºèƒ½åˆ†ç±»ç»“æœ - ç›®æ ‡ä½ç½®: {target_url[:50]}...", "INFO")
            self.log_message(f"ğŸ“‹ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}", "INFO")
            
            # ğŸ”„ å¯¹äºPDFå’ŒDOCXæ–‡ä»¶ï¼Œéƒ½ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ æµç¨‹
            from pathlib import Path
            from integrated_auto_download_uploader import IntegratedAutoUploader
            
            # ä½¿ç”¨æ•´åˆä¸Šä¼ å™¨
            uploader = IntegratedAutoUploader(self.feishu_app_id, self.feishu_app_secret)
            
            # æ­¥éª¤1: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒæ—¶æ£€æŸ¥äº‘æ–‡æ¡£å’ŒçŸ¥è¯†åº“ï¼‰
            if uploader.check_file_duplicate_by_title(title, filename):
                self.log_message(f"ğŸ“‹ äº‘æ–‡æ¡£æˆ–çŸ¥è¯†åº“ä¸­å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œè·³è¿‡ä¸Šä¼ : {filename}", "WARNING")
                self.log_message(f"ğŸ’¡ æç¤º: '{title}' å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ ", "INFO")
                uploader.cleanup()
                return True  # è¿”å›Trueå› ä¸ºè¿™ä¸æ˜¯é”™è¯¯ï¼Œåªæ˜¯é‡å¤
            
            # æ­¥éª¤2: ä¸Šä¼ åˆ°äº‘æ–‡æ¡£
            self.log_message(f"â˜ï¸ ä¸Šä¼ {file_type}åˆ°äº‘æ–‡æ¡£...", "INFO")
            file_token = uploader.upload_to_drive(Path(file_path))
            
            # å¤„ç†é‡å¤æ–‡ä»¶çš„æƒ…å†µ
            if file_token == "DUPLICATE":
                self.log_message(f"ğŸ“‹ äº‘æ–‡æ¡£ä¸Šä¼ æ—¶å‘ç°é‡åï¼Œè·³è¿‡åç»­å¤„ç†: {filename}", "WARNING")
                uploader.cleanup()
                return True  # è¿”å›Trueå› ä¸ºè¿™ä¸æ˜¯é”™è¯¯
            
            if not file_token:
                self.log_message(f"âŒ äº‘æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {filename}", "ERROR")
                uploader.cleanup()
                return False
            
            # æ­¥éª¤3: æ™ºèƒ½è½¬ç§»åˆ°ç›®æ ‡çŸ¥è¯†åº“ä½ç½®
            self.log_message(f"ğŸ“š æ™ºèƒ½è½¬ç§»{file_type}åˆ°çŸ¥è¯†åº“ä½ç½®...", "INFO")
            self.log_message(f"ğŸ¯ ç›®æ ‡ä½ç½®: {target_url[:50]}...", "INFO")
            
            # ğŸ†• ä½¿ç”¨æ™ºèƒ½åˆ†ç±»è½¬ç§»
            wiki_result = self._smart_move_to_wiki(uploader, file_token, filename, target_location)
            
            if wiki_result:
                if wiki_result.startswith("75"):  # task_idæ ¼å¼
                    self.log_message(f"â³ é£ä¹¦{file_type}æ™ºèƒ½è½¬ç§»ä»»åŠ¡å·²æäº¤: {wiki_result}", "SUCCESS")
                else:  # wiki_tokenæ ¼å¼
                    wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_result}"
                    self.log_message(f"âœ… é£ä¹¦{file_type}æ™ºèƒ½ä¸Šä¼ æˆåŠŸ: {filename}", "SUCCESS")
                    self.log_message(f"ğŸ“– æ–‡æ¡£é“¾æ¥: {wiki_url}", "INFO")
                    self.log_message(f"ğŸ¯ å·²è½¬ç§»åˆ°: {target_url[:50]}...", "SUCCESS")
                
                uploader.cleanup()
                return True
            else:
                self.log_message(f"âŒ æ™ºèƒ½è½¬ç§»å¤±è´¥: {filename}", "ERROR")
                uploader.cleanup()
                return False
                
        except Exception as e:
            self.log_message(f"é£ä¹¦æ™ºèƒ½ä¸Šä¼ å¼‚å¸¸: {e}", "ERROR")
            return False

    def _upload_to_feishu_batch(self, file_path: str) -> bool:
        """æ‰¹é‡ä¸‹è½½ä¸“ç”¨çš„é£ä¹¦ä¸Šä¼ æ–¹æ³•ï¼Œä½¿ç”¨æ™ºèƒ½åˆ†ç±»åŠŸèƒ½"""
        if not self.batch_feishu_upload_var.get():
            return True
        
        try:
            filename = os.path.basename(file_path)
            file_ext = os.path.splitext(filename)[1].lower()
            file_type = "PDF" if file_ext == ".pdf" else "Wordæ–‡æ¡£" if file_ext == ".docx" else "æ–‡ä»¶"
            
            # ä»æ–‡ä»¶åæå–æ ‡é¢˜ï¼ˆå»æ‰æ‰©å±•åï¼‰
            title = os.path.splitext(filename)[0]
            
            self.log_message(f"ğŸš€ å¼€å§‹æ‰¹é‡é£ä¹¦{file_type}æ™ºèƒ½ä¸Šä¼ : {filename}", "INFO")
            self.log_message(f"ğŸ“ åˆ†ææ ‡é¢˜: {title}", "INFO")
            
            # ğŸ†• ä½¿ç”¨æ™ºèƒ½åˆ†ç±»åŠŸèƒ½æ‰¾åˆ°ç›®æ ‡ä½ç½®
            target_location = self.find_target_wiki_location(title)
            target_url = target_location.get("wiki_url", self.default_wiki_location)
            as_subpage = target_location.get("as_subpage", True)
            
            self.log_message(f"ğŸ¯ æ‰¹é‡ä¸Šä¼ ç›®æ ‡ä½ç½®: {target_url}", "INFO")
            self.log_message(f"ğŸ“‹ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}", "INFO")
            
            # ğŸ†• å¯¹äºDOCXæ–‡ä»¶ï¼Œä¹Ÿä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ æµç¨‹ï¼ˆä¸å†ä½¿ç”¨ä¸‰æ­¥å¯¼å…¥ï¼‰
            from pathlib import Path
            from integrated_auto_download_uploader import IntegratedAutoUploader
            
            # ä½¿ç”¨æ•´åˆä¸Šä¼ å™¨
            uploader = IntegratedAutoUploader(self.feishu_app_id, self.feishu_app_secret)
            
            # æ­¥éª¤1: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒæ—¶æ£€æŸ¥äº‘æ–‡æ¡£å’ŒçŸ¥è¯†åº“ï¼‰
            if uploader.check_file_duplicate_by_title(title, filename):
                self.log_message(f"ğŸ“‹ äº‘æ–‡æ¡£æˆ–çŸ¥è¯†åº“ä¸­å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œè·³è¿‡æ‰¹é‡ä¸Šä¼ : {filename}", "WARNING")
                self.log_message(f"ğŸ’¡ æç¤º: '{title}' å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ ", "INFO")
                uploader.cleanup()
                return True  # è¿”å›Trueå› ä¸ºè¿™ä¸æ˜¯é”™è¯¯ï¼Œåªæ˜¯é‡å¤
            
            # æ­¥éª¤2: ä¸Šä¼ åˆ°äº‘æ–‡æ¡£
            self.log_message(f"â˜ï¸ æ‰¹é‡ä¸Šä¼ {file_type}åˆ°äº‘æ–‡æ¡£...", "INFO")
            file_token = uploader.upload_to_drive(Path(file_path))
            
            # å¤„ç†é‡å¤æ–‡ä»¶çš„æƒ…å†µ
            if file_token == "DUPLICATE":
                self.log_message(f"ğŸ“‹ äº‘æ–‡æ¡£ä¸Šä¼ æ—¶å‘ç°é‡åï¼Œè·³è¿‡åç»­å¤„ç†: {filename}", "WARNING")
                uploader.cleanup()
                return True  # è¿”å›Trueå› ä¸ºè¿™ä¸æ˜¯é”™è¯¯ï¼Œåªæ˜¯é‡å¤
            
            if not file_token:
                self.log_message(f"âŒ äº‘æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {filename}", "ERROR")
                uploader.cleanup()
                return False
            
            # æ­¥éª¤3: æ™ºèƒ½è½¬ç§»åˆ°ç›®æ ‡çŸ¥è¯†åº“ä½ç½®
            self.log_message(f"ğŸ“š æ‰¹é‡æ™ºèƒ½è½¬ç§»{file_type}åˆ°çŸ¥è¯†åº“ä½ç½®...", "INFO")
            self.log_message(f"ğŸ¯ ç›®æ ‡ä½ç½®: {target_url}", "INFO")
            
            # ğŸ†• ä½¿ç”¨æ™ºèƒ½åˆ†ç±»è½¬ç§»
            wiki_result = self._smart_move_to_wiki(uploader, file_token, filename, target_location)
            
            if wiki_result:
                if wiki_result.startswith("75"):  # task_idæ ¼å¼
                    self.log_message(f"â³ æ‰¹é‡é£ä¹¦{file_type}æ™ºèƒ½è½¬ç§»ä»»åŠ¡å·²æäº¤: {wiki_result}", "SUCCESS")
                else:  # wiki_tokenæ ¼å¼
                    wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_result}"
                    self.log_message(f"âœ… æ‰¹é‡é£ä¹¦{file_type}æ™ºèƒ½ä¸Šä¼ æˆåŠŸ: {filename}", "SUCCESS")
                    self.log_message(f"ğŸ“– æ–‡æ¡£é“¾æ¥: {wiki_url}", "INFO")
                    self.log_message(f"ğŸ¯ å·²è½¬ç§»åˆ°: {target_url}", "SUCCESS")
                
                uploader.cleanup()
                return True
            else:
                self.log_message(f"âŒ æ‰¹é‡æ™ºèƒ½è½¬ç§»å¤±è´¥: {filename}", "ERROR")
                uploader.cleanup()
                return False
                
        except Exception as e:
            self.log_message(f"æ‰¹é‡é£ä¹¦æ™ºèƒ½ä¸Šä¼ å¼‚å¸¸: {e}", "ERROR")
            return False

    def _smart_move_to_wiki(self, uploader, file_token: str, filename: str, target_location: dict) -> str:
        """æ™ºèƒ½è½¬ç§»æ–‡ä»¶åˆ°çŸ¥è¯†åº“æŒ‡å®šä½ç½®"""
        try:
            target_url = target_location.get("wiki_url", self.default_wiki_location)
            as_subpage = target_location.get("as_subpage", True)
            
            self.log_message(f"ğŸ“‹ æ™ºèƒ½è½¬ç§»è¯¦æƒ…:", "INFO")
            self.log_message(f"   ğŸ“ æ–‡ä»¶: {filename}", "INFO")
            self.log_message(f"   ğŸ¯ ç›®æ ‡URL: {target_url}", "INFO")
            self.log_message(f"   ğŸ“„ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}", "INFO")
            
            # è§£æç›®æ ‡URLç±»å‹å¹¶æå–wiki_token
            wiki_token = None
            
            if "drive/folder/" in target_url:
                # äº‘æ–‡æ¡£æ–‡ä»¶å¤¹ç±»å‹ - éœ€è¦ç§»åŠ¨åˆ°çŸ¥è¯†åº“
                self.log_message(f"ğŸ“ æ£€æµ‹åˆ°äº‘æ–‡æ¡£æ–‡ä»¶å¤¹é“¾æ¥ï¼Œæ‰§è¡Œæ ‡å‡†è½¬ç§»æµç¨‹", "INFO")
                return uploader.move_to_wiki(file_token, filename)
                
            elif "wiki/" in target_url:
                # çŸ¥è¯†åº“ç±»å‹ - æå–wiki_token
                # å¤„ç†åŒ…å«æŸ¥è¯¢å‚æ•°çš„URL
                if "?" in target_url:
                    clean_url = target_url.split("?")[0]  # å»é™¤æŸ¥è¯¢å‚æ•°
                else:
                    clean_url = target_url
                
                if "/wiki/space/" in clean_url:
                    # çŸ¥è¯†åº“ç©ºé—´ç±»å‹
                    wiki_token = clean_url.split("/wiki/space/")[-1]
                    self.log_message(f"ğŸ“š æ£€æµ‹åˆ°çŸ¥è¯†åº“ç©ºé—´é“¾æ¥: {wiki_token}", "INFO")
                elif "/wiki/" in clean_url:
                    # çŸ¥è¯†åº“é¡µé¢ç±»å‹
                    wiki_token = clean_url.split("/wiki/")[-1]
                    self.log_message(f"ğŸ“„ æ£€æµ‹åˆ°çŸ¥è¯†åº“é¡µé¢é“¾æ¥: {wiki_token}", "INFO")
                
                if wiki_token:
                    self.log_message(f"ğŸ¯ æå–çš„wiki_token: {wiki_token}", "INFO")
                    if as_subpage:
                        self.log_message(f"ğŸ“‹ è½¬ç§»ä¸ºæŒ‡å®šé¡µé¢çš„å­é¡µé¢", "INFO")
                    else:
                        self.log_message(f"ğŸ“‘ è½¬ç§»ä¸ºåŒçº§é¡µé¢", "INFO")
                    
                    # ğŸ”¥ ä½¿ç”¨æå–çš„wiki_tokenè¿›è¡Œæ™ºèƒ½è½¬ç§»
                    return self._move_to_specific_wiki_location(uploader, file_token, filename, wiki_token)
                else:
                    self.log_message(f"âš ï¸ æ— æ³•ä»URLæå–wiki_token: {target_url}", "WARNING")
                    self.log_message(f"ğŸ”„ å›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
                    return uploader.move_to_wiki(file_token, filename)
                    
            else:
                # æœªçŸ¥é“¾æ¥ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤è½¬ç§»
                self.log_message(f"âš ï¸ æœªè¯†åˆ«çš„é“¾æ¥ç±»å‹: {target_url}", "WARNING")
                self.log_message(f"ğŸ”„ å›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
                return uploader.move_to_wiki(file_token, filename)
            
            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœä¸Šé¢çš„æ¡ä»¶éƒ½æ²¡æœ‰è¿”å›ï¼Œç¡®ä¿æœ‰è¿”å›å€¼
            self.log_message(f"âš ï¸ æ™ºèƒ½è½¬ç§»é€»è¾‘æ‰§è¡Œå®Œæ¯•ä½†æ— æ˜ç¡®ç»“æœï¼Œä½¿ç”¨æ ‡å‡†è½¬ç§»", "WARNING")
            return uploader.move_to_wiki(file_token, filename)
                
        except Exception as e:
            self.log_message(f"âŒ æ™ºèƒ½è½¬ç§»è¿‡ç¨‹å‡ºé”™: {e}", "ERROR")
            self.log_message(f"ğŸ”„ å‡ºé”™åå›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
            try:
                return uploader.move_to_wiki(file_token, filename)
            except Exception as e2:
                self.log_message(f"âŒ æ ‡å‡†è½¬ç§»æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}", "ERROR")
                return None

    def _move_to_specific_wiki_location(self, uploader, file_token: str, filename: str, parent_wiki_token: str) -> str:
        """è½¬ç§»æ–‡ä»¶åˆ°æŒ‡å®šçš„çŸ¥è¯†åº“ä½ç½® - æ”¯æŒæ™ºèƒ½åˆ†ç±»"""
        try:
            self.log_message(f"ğŸš€ æ‰§è¡Œæ™ºèƒ½åˆ†ç±»è½¬ç§»:", "INFO")
            self.log_message(f"   ğŸ“ æ–‡ä»¶: {filename}", "INFO")
            self.log_message(f"   ğŸ¯ ç›®æ ‡wiki_token: {parent_wiki_token}", "INFO")
            
            # ä½¿ç”¨uploaderçš„APIï¼Œä½†æŒ‡å®šç‰¹å®šçš„parent_wiki_token
            feishu_client = uploader.feishu_client if hasattr(uploader, 'feishu_client') else None
            
            if not feishu_client:
                self.log_message(f"âŒ æ— æ³•è·å–feishu_clientï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•", "ERROR")
                return uploader.move_to_wiki(file_token, filename)
            
            # æ‰‹åŠ¨æ„å»ºAPIè¯·æ±‚ - æ”¯æŒæ™ºèƒ½åˆ†ç±»æŒ‡å®šä½ç½®
            api_url = f"https://open.feishu.cn/open-apis/wiki/v2/spaces/{uploader.space_id}/nodes/move_docs_to_wiki"
            
            # ğŸ”¥ æ„å»ºæ™ºèƒ½åˆ†ç±»APIæ•°æ®
            data = {
                "obj_token": file_token,
                "obj_type": "file",
                "parent_wiki_token": parent_wiki_token
            }
            
            self.log_message(f"ğŸ”„ æ™ºèƒ½åˆ†ç±»APIè°ƒç”¨: {api_url}", "INFO")
            self.log_message(f"ğŸ“‹ æ™ºèƒ½åˆ†ç±»è¯·æ±‚æ•°æ®: {data}", "INFO")
            
            # è°ƒç”¨API
            response_obj = feishu_client._make_authenticated_request('POST', api_url, json=data)
            
            if response_obj and response_obj.status_code == 200:
                response = response_obj.json()
                self.log_message(f"ğŸ“¡ æ™ºèƒ½åˆ†ç±»APIå“åº”: {response}", "INFO")
                
                if response.get("code") == 0:
                    data_result = response.get("data", {})
                    task_id = data_result.get("task_id")
                    wiki_token = data_result.get("wiki_token")
                    
                    if wiki_token:
                        wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_token}"
                        self.log_message(f"âœ… æ™ºèƒ½åˆ†ç±»è½¬ç§»æˆåŠŸ!", "SUCCESS")
                        self.log_message(f"ğŸ“– æ–°æ–‡æ¡£é“¾æ¥: {wiki_url}", "SUCCESS")
                        self.log_message(f"ğŸ¯ åˆ†ç±»ä½ç½®: {parent_wiki_token}", "SUCCESS")
                        return wiki_token
                    elif task_id:
                        self.log_message(f"â³ æ™ºèƒ½åˆ†ç±»è½¬ç§»ä»»åŠ¡å·²æäº¤: {task_id}", "SUCCESS")
                        self.log_message(f"ğŸ¯ åˆ†ç±»ä½ç½®: {parent_wiki_token}", "SUCCESS")
                        return task_id
                    else:
                        self.log_message(f"âš ï¸ æ™ºèƒ½åˆ†ç±»å“åº”æ— ç»“æœæ•°æ®: {response}", "WARNING")
                        return None
                else:
                    error_msg = response.get("msg", "æœªçŸ¥é”™è¯¯")
                    self.log_message(f"âŒ æ™ºèƒ½åˆ†ç±»APIè°ƒç”¨å¤±è´¥: code={response.get('code')}, msg={error_msg}", "ERROR")
                    
                    # å¦‚æœæ˜¯æƒé™æˆ–å…¶ä»–APIé”™è¯¯ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•
                    self.log_message(f"ğŸ”„ å›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
                    return uploader.move_to_wiki(file_token, filename)
            else:
                status_code = response_obj.status_code if response_obj else 'None'
                self.log_message(f"âŒ æ™ºèƒ½åˆ†ç±»HTTPè¯·æ±‚å¤±è´¥: status_code={status_code}", "ERROR")
                
                # HTTPé”™è¯¯ä¹Ÿå›é€€åˆ°æ ‡å‡†æ–¹æ³•
                self.log_message(f"ğŸ”„ å›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
                return uploader.move_to_wiki(file_token, filename)
                
        except Exception as e:
            self.log_message(f"âŒ æ™ºèƒ½åˆ†ç±»è½¬ç§»å¼‚å¸¸: {e}", "ERROR")
            self.log_message(f"ğŸ”„ å¼‚å¸¸åå›é€€åˆ°æ ‡å‡†è½¬ç§»æ–¹æ³•", "INFO")
            try:
                return uploader.move_to_wiki(file_token, filename)
            except Exception as e2:
                self.log_message(f"âŒ æ ‡å‡†è½¬ç§»æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}", "ERROR")
                return None

    def on_closing(self):
        """çª—å£å…³é—­äº‹ä»¶"""
        if self.is_downloading:
            result = messagebox.askyesno("ç¡®è®¤é€€å‡º", "æ­£åœ¨ä¸‹è½½ä¸­ï¼Œç¡®å®šè¦é€€å‡ºå—ï¼Ÿ")
            if not result:
                return
        
        # åœæ­¢è‡ªåŠ¨ä¸‹è½½
        if self.is_auto_collecting:
            self.stop_auto_download()
        
        # åœæ­¢å®šæ—¶å™¨
        if self.timer_job_id:
            self.stop_timer_update()
        
        # ä¿å­˜è®¾ç½®
        self.save_auto_update_settings()
        
        # æ¸…ç†èµ„æº
        try:
            if self.url_scraper:
                self.url_scraper.cleanup()
        except:
            pass
        
        self.root.destroy()

    def create_log_area(self, parent):
        """åˆ›å»ºæ—¥å¿—è¾“å‡ºåŒºåŸŸ"""
        log_frame = ttk.LabelFrame(parent, text="ğŸ“ è¿è¡Œæ—¥å¿—", padding="5")
        log_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(10, 0))
        parent.rowconfigure(2, weight=1)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        
        # åˆ›å»ºæ–‡æœ¬åŒºåŸŸ
        self.log_text = scrolledtext.ScrolledText(log_frame, height=12, state='disabled')
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ¸…ç©ºæ—¥å¿—æŒ‰é’®
        ttk.Button(log_frame, text="æ¸…ç©ºæ—¥å¿—", command=self.clear_log).grid(row=1, column=0, pady=(5, 0))
    
    def create_status_bar(self, parent):
        """åˆ›å»ºçŠ¶æ€æ """
        status_frame = ttk.Frame(parent)
        status_frame.grid(row=3, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(10, 0))
        
        self.status_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(status_frame, textvariable=self.status_var).pack(side=tk.LEFT)
        
        # ç‰ˆæœ¬ä¿¡æ¯
        ttk.Label(status_frame, text="v4.0 å…¨åŠŸèƒ½ç‰ˆ - å®Œå…¨è‡ªåŠ¨åŒ–").pack(side=tk.RIGHT)
    
    # ===== ğŸ†• é“¾æ¥æ”¶é›†å™¨åŠŸèƒ½æ–¹æ³• =====
    
    def start_collector_login(self):
        """å¯åŠ¨é“¾æ¥æ”¶é›†å™¨ç™»å½•"""
        try:
            self.log_message("ğŸš€ å¯åŠ¨é“¾æ¥æ”¶é›†å™¨ç™»å½•...", "INFO")
            
            # åˆ›å»ºé“¾æ¥æ”¶é›†å™¨å®ä¾‹
            if not self.link_collector:
                # ä½¿ç”¨ç®€åŒ–ç‰ˆé“¾æ¥æ”¶é›†å™¨
                self.link_collector = SimplifiedLinkCollector()
            
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œç™»å½•
            def login_worker():
                try:
                    self.collector_login_btn.config(state='disabled', text="ç™»å½•ä¸­...")
                    self.collector_login_status_var.set("æ­£åœ¨ç™»å½•...")
                    self.collector_login_status_label.config(foreground="orange")
                    
                    # è°ƒç”¨ç®€åŒ–ç‰ˆç™»å½•æ–¹æ³•
                    login_success = self.link_collector.start_login_flow()
                    
                    # æ£€æŸ¥ç™»å½•çŠ¶æ€
                    if login_success and self.link_collector.token:
                        self.collector_login_status_var.set("âœ… å·²ç™»å½•")
                        self.collector_login_status_label.config(foreground="green")
                        self.collector_login_btn.config(state='normal', text="âœ… å·²ç™»å½•")
                        self.log_message("âœ… é“¾æ¥æ”¶é›†å™¨ç™»å½•æˆåŠŸ", "SUCCESS")
                    else:
                        self.collector_login_status_var.set("âŒ ç™»å½•å¤±è´¥")
                        self.collector_login_status_label.config(foreground="red")
                        self.collector_login_btn.config(state='normal', text="ğŸš€ å¼€å§‹ç™»å½•")
                    
                except Exception as e:
                    self.log_message(f"âŒ é“¾æ¥æ”¶é›†å™¨ç™»å½•å¤±è´¥: {e}", "ERROR")
                    self.collector_login_status_var.set("âŒ ç™»å½•å¤±è´¥")
                    self.collector_login_status_label.config(foreground="red")
                    self.collector_login_btn.config(state='normal', text="ğŸš€ å¼€å§‹ç™»å½•")
            
            threading.Thread(target=login_worker, daemon=True).start()
            
        except Exception as e:
            self.log_message(f"âŒ å¯åŠ¨é“¾æ¥æ”¶é›†å™¨ç™»å½•å¤±è´¥: {e}", "ERROR")
    
    def retry_collector_login(self):
        """é‡æ–°ç™»å½•é“¾æ¥æ”¶é›†å™¨"""
        self.log_message("ğŸ”„ é‡æ–°ç™»å½•é“¾æ¥æ”¶é›†å™¨", "INFO")
        
        # é‡ç½®çŠ¶æ€
        if self.link_collector:
            self.link_collector.token = ""
            self.link_collector.cookies = {}
        
        self.collector_login_status_var.set("æœªç™»å½•")
        self.collector_login_status_label.config(foreground="red")
        
        # é‡æ–°å¼€å§‹ç™»å½•
        self.start_collector_login()
    
    def search_collector_accounts(self):
        """æœç´¢å…¬ä¼—å·"""
        if not self.link_collector or not self.link_collector.token:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç™»å½•å¾®ä¿¡å…¬ä¼—å·")
            return
        
        keyword = self.collector_search_var.get().strip()
        if not keyword:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœç´¢å…³é”®è¯")
            return
        
        self.log_message(f"ğŸ” æœç´¢å…¬ä¼—å·: {keyword}", "INFO")
        self.collector_search_btn.config(state='disabled', text="æœç´¢ä¸­...")
        
        def search_worker():
            try:
                # è°ƒç”¨ç®€åŒ–ç‰ˆæœç´¢æ–¹æ³•
                accounts = self.link_collector.search_account(keyword)
                
                # æ˜¾ç¤ºæœç´¢ç»“æœ
                self.collector_results_text.delete('1.0', tk.END)
                if accounts:
                    result_text = f"æœç´¢å…³é”®è¯: {keyword}\næ‰¾åˆ° {len(accounts)} ä¸ªå…¬ä¼—å·:\n\n"
                    for i, account in enumerate(accounts, 1):
                        nickname = account.get('nickname', '')
                        alias = account.get('alias', '')
                        signature = account.get('signature', '')[:50] + '...' if len(account.get('signature', '')) > 50 else account.get('signature', '')
                        
                        result_text += f"{i}. {nickname} ({alias})\n   {signature}\n\n"
                    
                    # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªç»“æœ
                    if self.link_collector.current_account:
                        selected_account = self.link_collector.current_account
                        self.collector_selected_var.set(f"{selected_account.get('nickname', '')} ({selected_account.get('alias', '')})")
                        result_text += f"âœ… å·²è‡ªåŠ¨é€‰æ‹©: {selected_account.get('nickname', '')}"
                else:
                    result_text = f"æœç´¢å…³é”®è¯: {keyword}\nâŒ æœªæ‰¾åˆ°åŒ¹é…çš„å…¬ä¼—å·"
                
                self.collector_results_text.insert(tk.END, result_text)
                self.log_message(f"âœ… æœç´¢å®Œæˆ: {keyword}ï¼Œæ‰¾åˆ° {len(accounts)} ä¸ªç»“æœ", "SUCCESS")
                    
            except Exception as e:
                self.log_message(f"âŒ æœç´¢å¤±è´¥: {e}", "ERROR")
                self.collector_results_text.delete('1.0', tk.END)
                self.collector_results_text.insert(tk.END, f"æœç´¢å¤±è´¥: {e}")
            finally:
                self.collector_search_btn.config(state='normal', text="ğŸ” æœç´¢")
        
        threading.Thread(target=search_worker, daemon=True).start()
    
    def start_collect_links(self):
        """å¼€å§‹æ”¶é›†é“¾æ¥"""
        if not self.link_collector or not self.link_collector.current_account:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç™»å½•å¹¶é€‰æ‹©å…¬ä¼—å·")
            return
        
        try:
            limit = int(self.collector_limit_var.get())
            start_date_str = self.collector_start_date_var.get().strip()
            end_date_str = self.collector_end_date_var.get().strip()
            
            from datetime import datetime
            start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
            end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
            
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—å’Œæ—¥æœŸæ ¼å¼ (YYYY-MM-DD)")
            return
        
        self.log_message(f"ğŸ“¥ å¼€å§‹æ”¶é›†é“¾æ¥ (æœ€å¤š{limit}ç¯‡ï¼Œ{start_date_str} è‡³ {end_date_str})", "INFO")
        self.collector_collect_btn.config(state='disabled', text="æ”¶é›†ä¸­...")
        
        def collect_worker():
            try:
                # æ¸…ç©ºä¹‹å‰çš„æ”¶é›†ç»“æœ
                self.collected_articles.clear()
                
                # è°ƒç”¨ç®€åŒ–ç‰ˆæ”¶é›†æ–¹æ³•
                articles = self.link_collector.collect_articles(limit, start_date, end_date)
                
                # è·å–æ”¶é›†ç»“æœ
                self.collected_articles = articles.copy()
                
                # æ›´æ–°ç»Ÿè®¡
                self.collector_stats_var.set(f"å·²æ”¶é›†: {len(self.collected_articles)} ç¯‡æ–‡ç« ")
                self.log_message(f"âœ… æ”¶é›†å®Œæˆï¼Œå…±è·å– {len(self.collected_articles)} ç¯‡æ–‡ç« é“¾æ¥", "SUCCESS")
                
            except Exception as e:
                self.log_message(f"âŒ æ”¶é›†å¤±è´¥: {e}", "ERROR")
            finally:
                self.collector_collect_btn.config(state='normal', text="ğŸ“¥ æ”¶é›†é“¾æ¥")
                self.collector_progress_var.set("")
        
        threading.Thread(target=collect_worker, daemon=True).start()
    
    def export_to_batch_download(self):
        """å¯¼å‡ºé“¾æ¥åˆ°æ‰¹é‡ä¸‹è½½é¡µé¢"""
        if not self.collected_articles:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„é“¾æ¥")
            return
        
        # æå–é“¾æ¥
        links = [article['link'] for article in self.collected_articles if article.get('link')]
        
        if not links:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰æœ‰æ•ˆçš„é“¾æ¥")
            return
        
        # æ·»åŠ åˆ°æ‰¹é‡ä¸‹è½½æ–‡æœ¬æ¡†
        current_content = self.batch_urls_text.get("1.0", tk.END).strip()
        
        # å¦‚æœæ–‡æœ¬æ¡†ä¸ºç©ºæˆ–åªæœ‰ç¤ºä¾‹å†…å®¹ï¼Œåˆ™æ¸…ç©ºåæ·»åŠ 
        if not current_content or "https://mp.weixin.qq.com/s?__biz=xxx" in current_content:
            self.batch_urls_text.delete("1.0", tk.END)
            self.batch_urls_text.insert(tk.END, '\n'.join(links))
        else:
            # åœ¨æœ«å°¾æ·»åŠ æ–°é“¾æ¥
            self.batch_urls_text.insert(tk.END, '\n' + '\n'.join(links))
        
        # å»é‡
        self.clean_duplicate_urls()
        
        self.log_message(f"ğŸ“‹ å·²å¯¼å‡º {len(links)} ä¸ªé“¾æ¥åˆ°æ‰¹é‡ä¸‹è½½é¡µé¢", "SUCCESS")
        messagebox.showinfo("æˆåŠŸ", f"å·²å¯¼å‡º {len(links)} ä¸ªé“¾æ¥åˆ°æ‰¹é‡ä¸‹è½½é¡µé¢")
    
    def export_collector_csv(self):
        """å¯¼å‡ºæ”¶é›†å™¨æ•°æ®ä¸ºCSV"""
        if not self.collected_articles:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
            return
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.join(self.output_dir, "links")
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"collected_articles_{timestamp}.csv"
            filepath = os.path.join(output_dir, filename)
            
            import csv
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['title', 'link', 'author', 'publish_time', 'account_name', 'account_alias', 'digest']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for article in self.collected_articles:
                    writer.writerow(article)
            
            self.log_message(f"âœ… CSVå¯¼å‡ºæˆåŠŸ: {filepath}", "SUCCESS")
            messagebox.showinfo("æˆåŠŸ", f"CSVæ–‡ä»¶å·²å¯¼å‡ºåˆ°:\n{filepath}")
            
        except Exception as e:
            self.log_message(f"âŒ CSVå¯¼å‡ºå¤±è´¥: {e}", "ERROR")
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
    
    def clear_collector_data(self):
        """æ¸…ç©ºæ”¶é›†å™¨æ•°æ®"""
        if messagebox.askyesno("ç¡®è®¤", "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰æ”¶é›†çš„æ•°æ®å—ï¼Ÿ"):
            self.collected_articles.clear()
            self.collector_stats_var.set("å·²æ”¶é›†: 0 ç¯‡æ–‡ç« ")
            self.collector_results_text.delete('1.0', tk.END)
            self.collector_selected_var.set("æœªé€‰æ‹©")
            self.log_message("ğŸ—‘ï¸ æ”¶é›†å™¨æ•°æ®å·²æ¸…ç©º", "INFO")
    
    # ===== ğŸ†• ROè‡ªåŠ¨æ›´æ–°åŠŸèƒ½æ–¹æ³• =====
    
    def toggle_auto_update(self):
        """åˆ‡æ¢è‡ªåŠ¨æ›´æ–°å¼€å…³"""
        self.auto_update_enabled = self.auto_update_enabled_var.get()
        self.save_auto_update_settings()
        
        if self.auto_update_enabled:
            self.log_message("âœ… ROæ–‡ç« è‡ªåŠ¨æ›´æ–°å·²å¯ç”¨", "SUCCESS")
        else:
            self.log_message("âŒ ROæ–‡ç« è‡ªåŠ¨æ›´æ–°å·²ç¦ç”¨", "INFO")
    
    def toggle_timer_update(self):
        """åˆ‡æ¢å®šæ—¶æ›´æ–°å¼€å…³"""
        self.timer_enabled = self.timer_enabled_var.get()
        
        if self.timer_enabled:
            # å¯åŠ¨å®šæ—¶å™¨
            self.start_timer_update()
            self.log_message("â° å®šæ—¶è‡ªåŠ¨æ›´æ–°å·²å¯ç”¨", "SUCCESS")
        else:
            # åœæ­¢å®šæ—¶å™¨
            self.stop_timer_update()
            self.log_message("â° å®šæ—¶è‡ªåŠ¨æ›´æ–°å·²ç¦ç”¨", "INFO")
        
        self.save_auto_update_settings()
    
    def on_timer_interval_changed(self, event):
        """å®šæ—¶é—´éš”è¾“å…¥å˜åŒ–äº‹ä»¶"""
        try:
            interval_str = self.timer_interval_var.get()
            if interval_str.isdigit():
                new_interval = int(interval_str)
                if new_interval > 0:
                    self.timer_interval = new_interval
                    # å¦‚æœå®šæ—¶å™¨æ­£åœ¨è¿è¡Œï¼Œé‡æ–°å¯åŠ¨ä»¥åº”ç”¨æ–°é—´éš”
                    if self.timer_enabled and self.timer_job_id:
                        self.stop_timer_update()
                        self.start_timer_update()
                    self.save_auto_update_settings()
        except Exception as e:
            pass  # å¿½ç•¥è¾“å…¥é”™è¯¯
    
    def start_timer_update(self):
        """å¯åŠ¨å®šæ—¶æ›´æ–°"""
        try:
            if self.timer_job_id:
                # å–æ¶ˆç°æœ‰çš„å®šæ—¶å™¨
                self.root.after_cancel(self.timer_job_id)
            
            # è®¡ç®—ä¸‹æ¬¡æ›´æ–°æ—¶é—´
            from datetime import datetime, timedelta
            next_time = datetime.now() + timedelta(minutes=self.timer_interval)
            self.next_update_time = next_time
            self.next_update_time_var.set(next_time.strftime("%H:%M:%S"))
            
            # è®¾ç½®å®šæ—¶å™¨ï¼ˆè½¬æ¢ä¸ºæ¯«ç§’ï¼‰
            interval_ms = self.timer_interval * 60 * 1000
            self.timer_job_id = self.root.after(interval_ms, self.on_timer_update)
            
            self.log_auto_update(f"â° å®šæ—¶å™¨å·²å¯åŠ¨ï¼Œé—´éš”: {self.timer_interval} åˆ†é’Ÿ")
            self.log_auto_update(f"   ğŸ“… ä¸‹æ¬¡æ›´æ–°æ—¶é—´: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            self.log_auto_update(f"âŒ å¯åŠ¨å®šæ—¶å™¨å¤±è´¥: {e}")
    
    def stop_timer_update(self):
        """åœæ­¢å®šæ—¶æ›´æ–°"""
        try:
            if self.timer_job_id:
                self.root.after_cancel(self.timer_job_id)
                self.timer_job_id = None
            
            self.next_update_time = None
            self.next_update_time_var.set("å®šæ—¶å™¨æœªå¯åŠ¨")
            
            self.log_auto_update("â° å®šæ—¶å™¨å·²åœæ­¢")
            
        except Exception as e:
            self.log_auto_update(f"âŒ åœæ­¢å®šæ—¶å™¨å¤±è´¥: {e}")
    
    def on_timer_update(self):
        """å®šæ—¶å™¨è§¦å‘çš„æ›´æ–°äº‹ä»¶"""
        try:
            self.log_auto_update("â° å®šæ—¶å™¨è§¦å‘ - å¼€å§‹è‡ªåŠ¨æ›´æ–°")
            
            # æ‰§è¡Œè‡ªåŠ¨æ›´æ–°
            self.start_auto_update_process()
            
            # è®¾ç½®ä¸‹ä¸€æ¬¡å®šæ—¶å™¨
            if self.timer_enabled:
                self.start_timer_update()
            
        except Exception as e:
            self.log_auto_update(f"âŒ å®šæ—¶æ›´æ–°æ‰§è¡Œå¤±è´¥: {e}")
            # å³ä½¿å¤±è´¥ä¹Ÿè¦é‡æ–°è®¾ç½®å®šæ—¶å™¨
            if self.timer_enabled:
                self.start_timer_update()
    
    def check_auto_update_on_startup(self):
        """å¯åŠ¨æ—¶æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ›´æ–°"""
        try:
            # åŠ è½½è‡ªåŠ¨æ›´æ–°è®¾ç½®
            self.load_auto_update_settings()
            
            if self.auto_update_enabled:
                self.log_message("ğŸ¤– æ£€æµ‹åˆ°ROè‡ªåŠ¨æ›´æ–°å·²å¯ç”¨ï¼Œå‡†å¤‡è‡ªåŠ¨æ‰§è¡Œ...", "INFO")
                self.auto_update_status_var.set("å¯åŠ¨æ£€æŸ¥ä¸­...")
                
                # å»¶è¿Ÿ2ç§’åå¼€å§‹è‡ªåŠ¨æ›´æ–°æµç¨‹
                self.root.after(2000, self.start_auto_update_process)
            else:
                self.auto_update_status_var.set("æœªå¯ç”¨")
                
        except Exception as e:
            self.log_message(f"âŒ å¯åŠ¨æ£€æŸ¥å¤±è´¥: {e}", "ERROR")
    
    def start_manual_update(self):
        """æ‰‹åŠ¨å¯åŠ¨æ›´æ–°"""
        self.log_message("ğŸš€ æ‰‹åŠ¨å¯åŠ¨ROæ–‡ç« æ›´æ–°...", "INFO")
        self.start_auto_update_process()
    
    def start_auto_update_process(self):
        """å¯åŠ¨è‡ªåŠ¨æ›´æ–°æµç¨‹"""
        self.auto_update_status_var.set("æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨æ›´æ–°...")
        self.manual_update_btn.config(state='disabled', text="æ›´æ–°ä¸­...")
        
        def auto_update_worker():
            try:
                self.log_auto_update("ğŸ¤– å¼€å§‹ROæ–‡ç« è‡ªåŠ¨æ›´æ–°æµç¨‹")
                
                # æ­¥éª¤1: ç™»å½•å¾®ä¿¡å…¬ä¼—å·
                self.log_auto_update("ğŸ“± æ­¥éª¤1: è‡ªåŠ¨ç™»å½•å¾®ä¿¡å…¬ä¼—å·...")
                if not self.auto_login_wechat():
                    return
                
                # æ­¥éª¤2: æœç´¢ROå…¬ä¼—å·
                self.log_auto_update("ğŸ” æ­¥éª¤2: æœç´¢ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆªå…¬ä¼—å·...")
                if not self.auto_search_ro_account():
                    return
                
                # æ­¥éª¤3: è®¡ç®—éœ€è¦æ›´æ–°çš„æ—¥æœŸèŒƒå›´
                self.log_auto_update("ğŸ“… æ­¥éª¤3: è®¡ç®—æ›´æ–°æ—¥æœŸèŒƒå›´...")
                start_date, end_date = self.calculate_update_date_range()
                
                # æ­¥éª¤4: æ”¶é›†æ–°æ–‡ç« é“¾æ¥
                self.log_auto_update(f"ğŸ“¥ æ­¥éª¤4: æ”¶é›†æ–°æ–‡ç«  ({start_date} è‡³ {end_date})...")
                new_articles = self.auto_collect_new_articles(start_date, end_date)
                
                # æ­¥éª¤5: ä¸‹è½½å¹¶ä¸Šä¼ æ–°æ–‡ç« ï¼ˆåŒ…æ‹¬å¤„ç†ç©ºåˆ—è¡¨çš„æƒ…å†µï¼‰
                self.log_auto_update(f"ğŸ“š æ­¥éª¤5: å¤„ç†æ–‡ç« ä¸‹è½½ä¸Šä¼ ...")
                success_count = self.auto_download_and_upload_articles(new_articles)
                
                # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®å®é™…æƒ…å†µç»™å‡ºå‡†ç¡®çš„å®ŒæˆçŠ¶æ€
                if not new_articles:
                    self.log_auto_update("ğŸ‰ è‡ªåŠ¨æ›´æ–°å®Œæˆï¼çŸ¥è¯†åº“å†…å®¹å·²æ˜¯æœ€æ–°çŠ¶æ€")
                    self.auto_update_status_var.set("å®Œæˆ - æ— æ–°æ–‡ç« ")
                    # å³ä½¿æ²¡æœ‰æ–°æ–‡ç« ï¼Œä¹Ÿæ›´æ–°æ—¥æœŸèŠ‚ç‚¹ï¼Œè¡¨ç¤ºå·²æ£€æŸ¥åˆ°è¯¥æ—¥æœŸ
                    self.log_auto_update("ğŸ“… æ­¥éª¤6: æ›´æ–°æ£€æŸ¥æ—¥æœŸèŠ‚ç‚¹...")
                    self.update_last_update_date(end_date)
                else:
                    # æ­¥éª¤6: æ›´æ–°æ—¥æœŸèŠ‚ç‚¹
                    if success_count > 0:
                        self.log_auto_update("ğŸ“… æ­¥éª¤6: æ›´æ–°æ—¥æœŸèŠ‚ç‚¹...")
                        self.update_last_update_date(end_date)
                    
                    self.log_auto_update(f"ğŸ‰ è‡ªåŠ¨æ›´æ–°å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(new_articles)} ç¯‡æ–‡ç« ")
                    self.auto_update_status_var.set(f"å®Œæˆ - æ›´æ–°äº†{success_count}ç¯‡æ–‡ç« ")
                
            except Exception as e:
                self.log_auto_update(f"âŒ è‡ªåŠ¨æ›´æ–°å¤±è´¥: {e}")
                self.auto_update_status_var.set("æ‰§è¡Œå¤±è´¥")
            finally:
                self.manual_update_btn.config(state='normal', text="ğŸš€ ç«‹å³æ‰§è¡Œæ›´æ–°")
        
        threading.Thread(target=auto_update_worker, daemon=True).start()
    
    def test_ro_account_search(self):
        """æµ‹è¯•ROå…¬ä¼—å·æœç´¢"""
        self.log_message("ğŸ” æµ‹è¯•ROå…¬ä¼—å·æœç´¢...", "INFO")
        
        def test_worker():
            try:
                if not self.link_collector or not self.link_collector.token:
                    self.log_message("âŒ è¯·å…ˆç™»å½•å¾®ä¿¡å…¬ä¼—å·", "ERROR")
                    return
                
                # æœç´¢ROå…¬ä¼—å·
                keyword = "ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª"
                accounts = self.link_collector.search_account(keyword)
                
                if accounts and self.link_collector.current_account:
                    nickname = self.link_collector.current_account.get('nickname', '')
                    alias = self.link_collector.current_account.get('alias', '')
                    self.ro_account_status_var.set(f"{nickname} ({alias}) âœ…")
                    self.log_message(f"âœ… æ‰¾åˆ°ROå…¬ä¼—å·: {nickname}", "SUCCESS")
                else:
                    self.ro_account_status_var.set("ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª âŒæœªæ‰¾åˆ°")
                    self.log_message("âŒ æœªæ‰¾åˆ°ROå…¬ä¼—å·", "ERROR")
                    
            except Exception as e:
                self.log_message(f"âŒ æµ‹è¯•æœç´¢å¤±è´¥: {e}", "ERROR")
        
        threading.Thread(target=test_worker, daemon=True).start()
    
    def reset_update_date(self):
        """é‡ç½®æ›´æ–°æ—¥æœŸ"""
        if messagebox.askyesno("ç¡®è®¤é‡ç½®", "ç¡®å®šè¦é‡ç½®æ›´æ–°æ—¥æœŸåˆ° 2025-06-10 å—ï¼Ÿ"):
            self.last_update_date = "2025-06-10"
            self.last_update_date_var.set(self.last_update_date)
            self.save_auto_update_settings()
            self.log_message("ğŸ“… æ›´æ–°æ—¥æœŸå·²é‡ç½®åˆ° 2025-06-10", "INFO")
    
    def view_update_log(self):
        """æŸ¥çœ‹æ›´æ–°æ—¥å¿—"""
        self.log_message("ğŸ“‹ æ˜¾ç¤ºæ›´æ–°æ—¥å¿—çª—å£", "INFO")
        
        # åˆ›å»ºæ—¥å¿—æŸ¥çœ‹çª—å£
        log_window = tk.Toplevel(self.root)
        log_window.title("ROæ–‡ç« æ›´æ–°æ—¥å¿—")
        log_window.geometry("800x600")
        
        log_text = scrolledtext.ScrolledText(log_window, wrap=tk.WORD)
        log_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # æ˜¾ç¤ºå½“å‰è‡ªåŠ¨æ›´æ–°æ—¥å¿—å†…å®¹
        current_log = self.auto_update_log.get('1.0', tk.END)
        log_text.insert('1.0', current_log)
        
        # æ·»åŠ å…³é—­æŒ‰é’®
        ttk.Button(log_window, text="å…³é—­", command=log_window.destroy).pack(pady=10)
    
    # ===== ğŸ†• è‡ªåŠ¨æ›´æ–°è¾…åŠ©æ–¹æ³• =====
    
    def log_auto_update(self, message):
        """è®°å½•è‡ªåŠ¨æ›´æ–°æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"
        
        self.auto_update_log.insert(tk.END, log_entry)
        self.auto_update_log.see(tk.END)
        self.root.update()
        
        # åŒæ—¶è¾“å‡ºåˆ°ä¸»æ—¥å¿—
        self.log_message(message, "INFO")
    
    def save_auto_update_settings(self):
        """ä¿å­˜è‡ªåŠ¨æ›´æ–°è®¾ç½®"""
        try:
            settings = {
                "auto_update_enabled": self.auto_update_enabled,
                "last_update_date": self.last_update_date,
                "timer_enabled": self.timer_enabled,
                "timer_interval": self.timer_interval
            }
            
            with open("ro_auto_update_settings.json", "w", encoding="utf-8") as f:
                json.dump(settings, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.log_message(f"ä¿å­˜è‡ªåŠ¨æ›´æ–°è®¾ç½®å¤±è´¥: {e}", "WARNING")
    
    def load_auto_update_settings(self):
        """åŠ è½½è‡ªåŠ¨æ›´æ–°è®¾ç½®"""
        try:
            if os.path.exists("ro_auto_update_settings.json"):
                with open("ro_auto_update_settings.json", "r", encoding="utf-8") as f:
                    settings = json.load(f)
                
                self.auto_update_enabled = settings.get("auto_update_enabled", False)
                self.last_update_date = settings.get("last_update_date", "2025-06-10")
                self.timer_enabled = settings.get("timer_enabled", False)
                self.timer_interval = settings.get("timer_interval", 60)
                
                # æ›´æ–°GUI
                self.auto_update_enabled_var.set(self.auto_update_enabled)
                self.last_update_date_var.set(self.last_update_date)
                self.timer_enabled_var.set(self.timer_enabled)
                self.timer_interval_var.set(str(self.timer_interval))
                
                # å¦‚æœå®šæ—¶å™¨æ˜¯å¯ç”¨çŠ¶æ€ï¼Œæ¢å¤å®šæ—¶å™¨
                if self.timer_enabled:
                    self.root.after(1000, self.start_timer_update)  # å»¶è¿Ÿ1ç§’å¯åŠ¨
                
        except Exception as e:
            self.log_message(f"åŠ è½½è‡ªåŠ¨æ›´æ–°è®¾ç½®å¤±è´¥: {e}", "WARNING")
    
    def auto_login_wechat(self):
        """è‡ªåŠ¨ç™»å½•å¾®ä¿¡å…¬ä¼—å·"""
        try:
            if not self.link_collector:
                self.link_collector = SimplifiedLinkCollector()
            
            if self.link_collector.token:
                self.log_auto_update("âœ… å·²æœ‰æœ‰æ•ˆç™»å½•token")
                return True
            
            self.log_auto_update("ğŸ“± å¯åŠ¨å¾®ä¿¡å…¬ä¼—å·ç™»å½•...")
            
            # å¯åŠ¨ç™»å½•æµç¨‹ï¼ˆè¿™ä¼šæ˜¾ç¤ºäºŒç»´ç é¡µé¢ï¼‰
            login_success = self.link_collector.start_login_flow()
            
            if login_success:
                self.log_auto_update("âœ… å¾®ä¿¡å…¬ä¼—å·ç™»å½•æˆåŠŸ")
                return True
            else:
                self.log_auto_update("âŒ ç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•")
                return False
            
        except Exception as e:
            self.log_auto_update(f"âŒ è‡ªåŠ¨ç™»å½•å¤±è´¥: {e}")
            return False
    
    def auto_search_ro_account(self):
        """è‡ªåŠ¨æœç´¢ROå…¬ä¼—å·"""
        try:
            keyword = "ä»™å¢ƒä¼ è¯´ROæ–°å¯èˆª"
            self.log_auto_update(f"ğŸ” æœç´¢å…¬ä¼—å·: {keyword}")
            
            accounts = self.link_collector.search_account(keyword)
            
            if accounts and self.link_collector.current_account:
                nickname = self.link_collector.current_account.get('nickname', '')
                self.log_auto_update(f"âœ… æ‰¾åˆ°å¹¶é€‰æ‹©å…¬ä¼—å·: {nickname}")
                self.ro_account_info = self.link_collector.current_account
                return True
            else:
                self.log_auto_update("âŒ æœªæ‰¾åˆ°ROå…¬ä¼—å·")
                return False
                
        except Exception as e:
            self.log_auto_update(f"âŒ æœç´¢ROå…¬ä¼—å·å¤±è´¥: {e}")
            return False
    
    def calculate_update_date_range(self):
        """è®¡ç®—æ›´æ–°æ—¥æœŸèŒƒå›´ - åŒ…å«é˜²æ¼æ£€æŸ¥"""
        from datetime import datetime, timedelta
        
        # å½“å‰æ—¥æœŸ
        today = datetime.now()
        today_str = today.strftime("%Y-%m-%d")
        
        # ä¸Šæ¬¡æ›´æ–°æ—¥æœŸ
        last_update = datetime.strptime(self.last_update_date, "%Y-%m-%d")
        
        # ğŸ†• é˜²æ¼æ£€æŸ¥ï¼šæ£€æŸ¥å‰3å¤©çš„æ‰€æœ‰æ–‡ç« 
        # ä»ä¸Šæ¬¡æ›´æ–°æ—¥æœŸå‰3å¤©å¼€å§‹ï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•æ–‡ç« 
        start_date = last_update - timedelta(days=3)
        start_date_str = start_date.strftime("%Y-%m-%d")
        
        self.log_auto_update(f"ğŸ“… è®¡ç®—æ›´æ–°èŒƒå›´ï¼ˆé˜²æ¼æ£€æŸ¥ï¼‰:")
        self.log_auto_update(f"   ğŸ• å¼€å§‹æ—¥æœŸ: {start_date_str} (ä¸Šæ¬¡æ›´æ–°å‰3å¤©)")
        self.log_auto_update(f"   ğŸ• ç»“æŸæ—¥æœŸ: {today_str} (ä»Šå¤©)")
        self.log_auto_update(f"   ğŸ“Œ ä¸Šæ¬¡æ›´æ–°: {self.last_update_date}")
        self.log_auto_update(f"   ğŸ›¡ï¸ é˜²æ¼ç­–ç•¥: å‘å‰æ£€æŸ¥3å¤©ç¡®ä¿å®Œæ•´æ€§")
        
        return start_date_str, today_str
    
    def auto_collect_new_articles(self, start_date, end_date):
        """è‡ªåŠ¨æ”¶é›†æ–°æ–‡ç« å¹¶è¿›è¡Œæ™ºèƒ½çŸ¥è¯†åº“é‡å¤æ£€æµ‹"""
        try:
            if not self.link_collector.current_account:
                self.log_auto_update("âŒ æ²¡æœ‰é€‰æ‹©çš„å…¬ä¼—å·")
                return []
            
            from datetime import datetime
            from integrated_auto_download_uploader import IntegratedAutoUploader
            
            start_date_obj = datetime.strptime(start_date, "%Y-%m-%d")
            end_date_obj = datetime.strptime(end_date, "%Y-%m-%d")
            
            # æ”¶é›†æ–‡ç« 
            articles = self.link_collector.collect_articles(100, start_date_obj, end_date_obj)  # æœ€å¤š100ç¯‡
            
            self.log_auto_update(f"ğŸ“¥ æ”¶é›†åˆ° {len(articles)} ç¯‡æ–‡ç« ")
            
            # ğŸ”¥ ä¿®å¤ï¼šè·³è¿‡æ—¶é—´ç­›é€‰ï¼Œç›´æ¥è¿›è¡Œæ™ºèƒ½çŸ¥è¯†åº“é‡å¤æ£€æµ‹
            # ç”±äºæˆ‘ä»¬å·²ç»åšäº†é˜²æ¼æ£€æŸ¥ï¼ˆå‰3å¤©ï¼‰ï¼Œè®©çŸ¥è¯†åº“é‡å¤æ£€æµ‹æ¥å†³å®šå“ªäº›æ–‡ç« éœ€è¦æ›´æ–°
            self.log_auto_update(f"ğŸ“Š è·³è¿‡æ—¶é—´ç­›é€‰ï¼Œå°†å¯¹æ‰€æœ‰ {len(articles)} ç¯‡æ–‡ç« è¿›è¡Œæ™ºèƒ½é‡å¤æ£€æµ‹")
            self.log_auto_update(f"ğŸ’¡ åŸå› ï¼šé˜²æ¼æ£€æŸ¥å·²é™å®šæ—¶é—´èŒƒå›´ï¼Œæ™ºèƒ½é‡å¤æ£€æµ‹æ›´å‡†ç¡®")
            
            # æ˜¾ç¤ºæ”¶é›†åˆ°çš„æ–‡ç« è¯¦æƒ…
            if articles:
                self.log_auto_update(f"ğŸ“ æ”¶é›†åˆ°çš„æ–‡ç« è¯¦æƒ…:")
                for i, article in enumerate(articles, 1):
                    title = article.get('title', 'æ— æ ‡é¢˜')
                    publish_time = article.get('publish_time', 'æ— æ—¶é—´')
                    link = article.get('link', 'æ— é“¾æ¥')
                    self.log_auto_update(f"   ğŸ“„ [{i}] {title}")
                    self.log_auto_update(f"       ğŸ“… å‘å¸ƒæ—¶é—´: {publish_time}")
                    self.log_auto_update(f"       ğŸ”— é“¾æ¥: {link[:60]}...")
                self.log_auto_update("")  # åˆ†éš”çº¿
            else:
                self.log_auto_update(f"ğŸ“ æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ”¶é›†åˆ°æ–‡ç« ")
            
            time_filtered_articles = articles  # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æ”¶é›†åˆ°çš„æ–‡ç« 
            
            # ğŸ†• åˆ›å»ºuploaderç”¨äºé‡å¤æ£€æµ‹
            uploader = IntegratedAutoUploader(self.feishu_app_id, self.feishu_app_secret)
            
            # ğŸ†• è¿›è¡Œæ™ºèƒ½çŸ¥è¯†åº“é‡å¤æ£€æµ‹
            self.log_auto_update(f"ğŸ§  å¼€å§‹æ™ºèƒ½çŸ¥è¯†åº“é‡å¤æ£€æµ‹...")
            self.log_auto_update(f"ğŸ’¡ ç­–ç•¥ï¼šæ ¹æ®æ–‡ç« æ ‡é¢˜å…³é”®è¯ï¼Œåªåœ¨å¯¹åº”åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æµ‹é‡å¤æ–‡ç« ")
            self.log_auto_update(f"ğŸ“‚ çŸ¥è¯†åº“ç»“æ„ï¼šçˆ¶èŠ‚ç‚¹ â†’ åˆ†ç±»å­èŠ‚ç‚¹(13ä¸ª) â†’ æ–‡ç« ")
            final_articles = []
            duplicate_count = 0
            
            for i, article in enumerate(time_filtered_articles, 1):
                title = article.get('title', '')
                publish_time = article.get('publish_time', 'æ— æ—¶é—´')
                link = article.get('link', 'æ— é“¾æ¥')
                
                if not title:
                    self.log_auto_update(f"   âš ï¸ [{i}/{len(time_filtered_articles)}] è·³è¿‡æ— æ ‡é¢˜æ–‡ç« ")
                    continue
                
                self.log_auto_update(f"ğŸ” [{i}/{len(time_filtered_articles)}] æ™ºèƒ½æ£€æµ‹æ–‡ç« :")
                self.log_auto_update(f"   ğŸ“ æ–‡ç« æ ‡é¢˜: {title}")
                self.log_auto_update(f"   ğŸ“… å‘å¸ƒæ—¶é—´: {publish_time}")
                self.log_auto_update(f"   ğŸ”— æ–‡ç« é“¾æ¥: {link[:60]}...")
                
                # ğŸ”¥ ä½¿ç”¨æ™ºèƒ½åˆ†ç±»æ‰¾åˆ°ç›®æ ‡ä½ç½®
                self.log_auto_update(f"   ğŸ§  æ­¥éª¤1: æ‰§è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æ...")
                target_location = self.find_target_wiki_location(title)
                target_url = target_location.get("wiki_url", self.default_wiki_location)
                
                # æå–ç›®æ ‡ä½ç½®çš„wiki_token
                target_wiki_token = None
                if "wiki/" in target_url:
                    if "?" in target_url:
                        clean_url = target_url.split("?")[0]
                    else:
                        clean_url = target_url
                    
                    if "/wiki/space/" in clean_url:
                        target_wiki_token = clean_url.split("/wiki/space/")[-1]
                    elif "/wiki/" in clean_url:
                        target_wiki_token = clean_url.split("/wiki/")[-1]
                
                # æå–åŒ¹é…çš„å…³é”®è¯ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
                matched_keywords = target_location.get("keywords", [])
                if matched_keywords:
                    # æ‰¾åˆ°å®é™…åŒ¹é…çš„å…³é”®è¯
                    matched_keyword = None
                    title_lower = title.lower()
                    for keyword in matched_keywords:
                        if keyword.lower() in title_lower:
                            matched_keyword = keyword
                            break
                    
                    if matched_keyword:
                        self.log_auto_update(f"   ğŸ¯ åˆ†ç±»ç»“æœ: åŒ¹é…å…³é”®è¯ '{matched_keyword}' â†’ {target_url.split('/')[-1]}")
                    else:
                        self.log_auto_update(f"   ğŸ¯ åˆ†ç±»ç»“æœ: é…ç½®å…³é”®è¯ {matched_keywords} â†’ {target_url.split('/')[-1]}")
                else:
                    self.log_auto_update(f"   ğŸ¯ åˆ†ç±»ç»“æœ: æ— åŒ¹é…å…³é”®è¯ â†’ é»˜è®¤ä½ç½® {target_url.split('/')[-1]}")
                
                self.log_auto_update(f"   ğŸ“‹ ç›®æ ‡wiki_token: {target_wiki_token}")
                
                # ğŸ”¥ åœ¨ç›®æ ‡åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æŸ¥é‡å¤æ–‡ç« 
                self.log_auto_update(f"   ğŸ” æ­¥éª¤2: æ£€æŸ¥ç›®æ ‡åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ç« ...")
                if target_wiki_token:
                    self.log_auto_update(f"   ğŸ“‚ æ£€æŸ¥ä½ç½®: {target_wiki_token} (åˆ†ç±»å­èŠ‚ç‚¹)")
                    wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                        uploader.space_id, 
                        title, 
                        target_wiki_token  # åœ¨åˆ†ç±»å­èŠ‚ç‚¹ä¸‹æ£€æŸ¥æ˜¯å¦æœ‰åŒåæ–‡ç« 
                    )
                else:
                    # å¦‚æœæ— æ³•è§£æç›®æ ‡tokenï¼Œä½¿ç”¨é»˜è®¤ä½ç½®æ£€æŸ¥
                    self.log_auto_update(f"   âš ï¸ æ— æ³•è§£æç›®æ ‡tokenï¼Œä½¿ç”¨é»˜è®¤ä½ç½®æ£€æŸ¥...")
                    default_wiki_token = self.default_wiki_location.split("/wiki/")[-1] if "/wiki/" in self.default_wiki_location else None
                    if default_wiki_token:
                        self.log_auto_update(f"   ğŸ“‚ æ£€æŸ¥ä½ç½®: {default_wiki_token} (é»˜è®¤ä½ç½®)")
                        wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                            uploader.space_id, 
                            title, 
                            default_wiki_token
                        )
                    else:
                        # æœ€åå›é€€åˆ°çˆ¶èŠ‚ç‚¹æ£€æŸ¥
                        self.log_auto_update(f"   âš ï¸ é»˜è®¤ä½ç½®ä¹Ÿæ— æ³•è§£æï¼Œå›é€€åˆ°çˆ¶èŠ‚ç‚¹æ£€æŸ¥...")
                        self.log_auto_update(f"   ğŸ“‚ æ£€æŸ¥ä½ç½®: {uploader.parent_wiki_token} (çˆ¶èŠ‚ç‚¹)")
                        wiki_exists = uploader.feishu_client.check_file_exists_in_wiki(
                            uploader.space_id, 
                            title, 
                            uploader.parent_wiki_token
                        )
                
                if wiki_exists:
                    self.log_auto_update(f"   ğŸ“‹ æ£€æµ‹ç»“æœ: ç›®æ ‡ä½ç½®å·²å­˜åœ¨åŒåæ–‡æ¡£ '{title}'ï¼Œè·³è¿‡")
                    duplicate_count += 1
                else:
                    self.log_auto_update(f"   âœ… æ£€æµ‹ç»“æœ: ç›®æ ‡ä½ç½®ä¸å­˜åœ¨åŒåæ–‡æ¡£ï¼ŒåŠ å…¥ä¸‹è½½é˜Ÿåˆ—")
                    final_articles.append(article)
                
                self.log_auto_update("")  # ç©ºè¡Œåˆ†éš”
            
            # æ¸…ç†uploader
            uploader.cleanup()
            
            self.log_auto_update(f"ğŸ“Š æ™ºèƒ½é‡å¤æ£€æµ‹æ±‡æ€»:")
            self.log_auto_update(f"   ğŸ“¥ æ”¶é›†æ–‡ç« : {len(time_filtered_articles)} ç¯‡")
            self.log_auto_update(f"   ğŸ“‹ å·²å­˜åœ¨: {duplicate_count} ç¯‡ (ç›®æ ‡ä½ç½®å·²æœ‰åŒåæ–‡æ¡£)")
            self.log_auto_update(f"   ğŸ†• å¾…å¤„ç†: {len(final_articles)} ç¯‡ (æ–°æ–‡ç« éœ€è¦ä¸‹è½½ä¸Šä¼ )")
            self.log_auto_update("")
            
            return final_articles
            
        except Exception as e:
            self.log_auto_update(f"âŒ æ”¶é›†æ–°æ–‡ç« å¤±è´¥: {e}")
            return []
    
    def auto_download_and_upload_articles(self, articles):
        """è‡ªåŠ¨ä¸‹è½½å¹¶ä¸Šä¼ æ–‡ç«  - æ”¯æŒæ™ºèƒ½åˆ†ç±»"""
        success_count = 0
        
        # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰æ–‡ç« éœ€è¦å¤„ç†ï¼Œç›´æ¥è¿”å›
        if not articles:
            self.log_auto_update(f"ğŸ“‹ æ²¡æœ‰æ–°æ–‡ç« éœ€è¦ä¸‹è½½ï¼Œæ‰€æœ‰æ–‡ç« éƒ½å·²å­˜åœ¨äºçŸ¥è¯†åº“ä¸­")
            self.log_auto_update(f"   âœ… æ™ºèƒ½é‡å¤æ£€æµ‹å·²è¿‡æ»¤æ‰æ‰€æœ‰é‡å¤æ–‡ç« ")
            self.log_auto_update(f"   ğŸ’¡ è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œè¡¨æ˜çŸ¥è¯†åº“å†…å®¹æ˜¯æœ€æ–°çš„")
            return 0  # è¿”å›0è¡¨ç¤ºæˆåŠŸå®Œæˆï¼ˆæ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ç« ï¼‰
        
        try:
            from integrated_auto_download_uploader import IntegratedAutoUploader
            
            # åˆ›å»ºæ•´åˆç‰ˆä¸Šä¼ å™¨
            uploader = IntegratedAutoUploader(self.feishu_app_id, self.feishu_app_secret)
            
            self.log_auto_update(f"ğŸ“¥ å¼€å§‹å¤„ç† {len(articles)} ç¯‡éœ€è¦ä¸‹è½½çš„æ–°æ–‡ç« :")
            
            for i, article in enumerate(articles, 1):
                try:
                    title = article.get('title', f'article_{i}')
                    link = article.get('link', '')
                    
                    if not link:
                        self.log_auto_update(f"âš ï¸ [{i}/{len(articles)}] è·³è¿‡æ— é“¾æ¥æ–‡ç« : {title}")
                        continue
                    
                    self.log_auto_update(f"ğŸ“¥ [{i}/{len(articles)}] å¼€å§‹å¤„ç†æ–‡ç« : {title}")
                    self.log_auto_update(f"   ğŸ”— æ–‡ç« é“¾æ¥: {link[:60]}...")
                    
                    # ğŸ†• ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å¤„ç†æµç¨‹
                    result = self._process_article_with_smart_classification(uploader, link, title, i, len(articles))
                    
                    if result:
                        success_count += 1
                        self.log_auto_update(f"âœ… [{i}/{len(articles)}] æ–‡ç« å¤„ç†æˆåŠŸ: {title}")
                        self.log_auto_update(f"   ğŸ‰ å·²æˆåŠŸä¸‹è½½å¹¶ä¸Šä¼ åˆ°é£ä¹¦çŸ¥è¯†åº“")
                    else:
                        self.log_auto_update(f"âŒ [{i}/{len(articles)}] æ–‡ç« å¤„ç†å¤±è´¥: {title}")
                        self.log_auto_update(f"   ğŸ’” ä¸‹è½½æˆ–ä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
                    import time
                    time.sleep(3)
                    
                except Exception as e:
                    self.log_auto_update(f"âŒ [{i}/{len(articles)}] å¤„ç†å¼‚å¸¸: {e}")
            
            uploader.cleanup()
            
            # ğŸ”¥ ä¿®å¤ï¼šæ›´å‡†ç¡®çš„å¤„ç†ç»“æœæ±‡æ€»
            self.log_auto_update(f"ğŸ“Š æ–‡ç« å¤„ç†æ±‡æ€»:")
            self.log_auto_update(f"   ğŸ“¥ é¢„è®¡å¤„ç†: {len(articles)} ç¯‡ (æ™ºèƒ½é‡å¤æ£€æµ‹åçš„æ–°æ–‡ç« )")
            self.log_auto_update(f"   âœ… æˆåŠŸå¤„ç†: {success_count} ç¯‡")
            if len(articles) - success_count > 0:
                self.log_auto_update(f"   âŒ å¤„ç†å¤±è´¥: {len(articles) - success_count} ç¯‡")
            
        except Exception as e:
            self.log_auto_update(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        
        return success_count
    
    def _process_article_with_smart_classification(self, uploader, url: str, title: str, current: int, total: int) -> bool:
        """å¤„ç†å•ç¯‡æ–‡ç« çš„æ™ºèƒ½åˆ†ç±»æµç¨‹ï¼ˆå·²é€šè¿‡å‰ç½®é‡å¤æ£€æµ‹ï¼‰"""
        try:
            # æ­¥éª¤1: ä¸‹è½½æ–‡ä»¶
            self.log_auto_update(f"   ğŸ“¥ æ­¥éª¤1: å¼€å§‹ä¸‹è½½å¾®ä¿¡æ–‡ç« ...")
            temp_file_path = uploader.download_article(url, 'pdf')
            
            # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†è·³è¿‡ä¸‹è½½çš„æƒ…å†µ
            if temp_file_path == "DUPLICATE_SKIPPED":
                self.log_auto_update(f"   ğŸ“‹ æ­¥éª¤1ç»“æœ: æ£€æµ‹åˆ°äº‘æ–‡æ¡£é‡å¤æ–‡ä»¶ï¼Œè·³è¿‡ä¸‹è½½")
                self.log_auto_update(f"   âœ… è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œè¯´æ˜æ–‡æ¡£å·²å­˜åœ¨äºäº‘æ–‡æ¡£ä¸­")
                return True  # è·³è¿‡æ˜¯æˆåŠŸçš„çŠ¶æ€
            
            if not temp_file_path:
                self.log_auto_update(f"   âŒ æ­¥éª¤1å¤±è´¥: æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œæ— æ³•è·å–æ–‡ç« å†…å®¹")
                return False
            
            filename = temp_file_path.name
            actual_title = temp_file_path.stem  # ä½¿ç”¨å®é™…çš„æ–‡ä»¶åä½œä¸ºæ ‡é¢˜
            
            self.log_auto_update(f"   âœ… æ­¥éª¤1æˆåŠŸ: æ–‡ä»¶ä¸‹è½½å®Œæˆ")
            self.log_auto_update(f"      ğŸ“„ æ–‡ä»¶å: {filename}")
            self.log_auto_update(f"      ğŸ“ æå–æ ‡é¢˜: {actual_title}")
            
            # æ­¥éª¤2: æ™ºèƒ½åˆ†ç±»åˆ†æï¼ˆåŸºäºå®é™…ä¸‹è½½çš„æ–‡ä»¶æ ‡é¢˜ï¼‰
            self.log_auto_update(f"   ğŸ§  æ­¥éª¤2: æ‰§è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æ...")
            target_location = self.find_target_wiki_location(actual_title)
            target_url = target_location.get("wiki_url", self.default_wiki_location)
            as_subpage = target_location.get("as_subpage", True)
            
            # æå–åŒ¹é…çš„å…³é”®è¯ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
            matched_keywords = target_location.get("keywords", [])
            if matched_keywords:
                # æ‰¾åˆ°å®é™…åŒ¹é…çš„å…³é”®è¯
                matched_keyword = None
                title_lower = actual_title.lower()
                for keyword in matched_keywords:
                    if keyword.lower() in title_lower:
                        matched_keyword = keyword
                        break
                
                if matched_keyword:
                    self.log_auto_update(f"   âœ… æ­¥éª¤2æˆåŠŸ: åŒ¹é…å…³é”®è¯ '{matched_keyword}'")
                else:
                    self.log_auto_update(f"   âœ… æ­¥éª¤2æˆåŠŸ: é…ç½®å…³é”®è¯ {matched_keywords}")
            else:
                self.log_auto_update(f"   âœ… æ­¥éª¤2æˆåŠŸ: æ— åŒ¹é…å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®")
            
            self.log_auto_update(f"      ğŸ¯ ç›®æ ‡ä½ç½®: {target_url.split('/')[-1]}")
            self.log_auto_update(f"      ğŸ“„ ä½œä¸ºå­é¡µé¢: {'æ˜¯' if as_subpage else 'å¦'}")
            
            # ğŸ†• è·³è¿‡é‡å¤æ£€æµ‹ï¼ˆå·²åœ¨å‰ç½®é˜¶æ®µå®Œæˆï¼‰
            self.log_auto_update(f"   â­ï¸ è·³è¿‡é‡å¤æ£€æµ‹ï¼ˆå·²åœ¨æ”¶é›†é˜¶æ®µå®Œæˆæ™ºèƒ½é‡å¤æ£€æµ‹ï¼‰")
            
            # æ­¥éª¤3: ä¸Šä¼ åˆ°äº‘æ–‡æ¡£
            self.log_auto_update(f"   â˜ï¸ æ­¥éª¤3: ä¸Šä¼ æ–‡ä»¶åˆ°é£ä¹¦äº‘æ–‡æ¡£...")
            file_token = uploader.upload_to_drive(temp_file_path)
            
            if file_token == "DUPLICATE":
                self.log_auto_update(f"   ğŸ“‹ æ­¥éª¤3ç»“æœ: äº‘æ–‡æ¡£ä¸­å·²å­˜åœ¨ç›¸åŒæ–‡ä»¶ï¼Œè·³è¿‡ä¸Šä¼ ")
                return True
            
            if not file_token:
                self.log_auto_update(f"   âŒ æ­¥éª¤3å¤±è´¥: äº‘æ–‡æ¡£ä¸Šä¼ å¤±è´¥ï¼Œæ— æ³•è·å–æ–‡ä»¶token")
                return False
            
            self.log_auto_update(f"   âœ… æ­¥éª¤3æˆåŠŸ: æ–‡ä»¶å·²ä¸Šä¼ åˆ°äº‘æ–‡æ¡£")
            self.log_auto_update(f"      ğŸ·ï¸ æ–‡ä»¶token: {file_token}")
            
            # æ­¥éª¤4: æ™ºèƒ½è½¬ç§»åˆ°ç›®æ ‡çŸ¥è¯†åº“ä½ç½®
            self.log_auto_update(f"   ğŸ“š æ­¥éª¤4: è½¬ç§»æ–‡æ¡£åˆ°ç›®æ ‡çŸ¥è¯†åº“ä½ç½®...")
            wiki_result = self._smart_move_to_wiki(uploader, file_token, filename, target_location)
            
            if wiki_result:
                if wiki_result.startswith("75"):  # task_idæ ¼å¼
                    self.log_auto_update(f"   âœ… æ­¥éª¤4æˆåŠŸ: è½¬ç§»ä»»åŠ¡å·²æäº¤åˆ°é£ä¹¦åå°")
                    self.log_auto_update(f"      â³ ä»»åŠ¡ID: {wiki_result}")
                    self.log_auto_update(f"      ğŸ’¡ é£ä¹¦æ­£åœ¨åå°å¤„ç†è½¬ç§»ï¼Œè¯·ç¨ååœ¨çŸ¥è¯†åº“ä¸­æŸ¥çœ‹")
                else:  # wiki_tokenæ ¼å¼
                    wiki_url = f"https://thedream.feishu.cn/wiki/{wiki_result}"
                    self.log_auto_update(f"   âœ… æ­¥éª¤4æˆåŠŸ: æ–‡æ¡£å·²è½¬ç§»åˆ°çŸ¥è¯†åº“")
                    self.log_auto_update(f"      ğŸ“– æ–‡æ¡£é“¾æ¥: {wiki_url}")
                
                self.log_auto_update(f"      ğŸ¯ ç›®æ ‡ä½ç½®: {target_url.split('/')[-1]}")
                return True
            else:
                self.log_auto_update(f"   âŒ æ­¥éª¤4å¤±è´¥: è½¬ç§»åˆ°çŸ¥è¯†åº“å¤±è´¥")
                return False
                
        except Exception as e:
            self.log_auto_update(f"   âŒ [{current}/{total}] æ™ºèƒ½åˆ†ç±»å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def update_last_update_date(self, new_date):
        """æ›´æ–°æœ€åæ›´æ–°æ—¥æœŸ"""
        self.last_update_date = new_date
        self.last_update_date_var.set(new_date)
        self.save_auto_update_settings()
        self.log_auto_update(f"ğŸ“… æ›´æ–°æ—¥æœŸèŠ‚ç‚¹: {new_date}")


def main():
    """å¯åŠ¨GUIåº”ç”¨"""
    try:
        print("ğŸš€ å¯åŠ¨å¾®ä¿¡æ–‡ç« ä¸‹è½½å·¥å…·GUI...")
        
        root = tk.Tk()
        print("âœ… tkinteræ ¹çª—å£åˆ›å»ºæˆåŠŸ")
        
        app = WechatDownloaderGUI(root)
        print("âœ… GUIåº”ç”¨åˆå§‹åŒ–æˆåŠŸ")
        
        # è®¾ç½®å…³é—­äº‹ä»¶
        root.protocol("WM_DELETE_WINDOW", app.on_closing)
        
        print("ğŸ¯ å¯åŠ¨GUIä¸»å¾ªç¯...")
        # å¯åŠ¨ä¸»å¾ªç¯
        root.mainloop()
        
        print("ğŸ‘‹ GUIåº”ç”¨å·²å…³é—­")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å®‰è£…äº†æ‰€æœ‰ä¾èµ–åŒ…:")
        print("   pip install selenium beautifulsoup4 requests loguru")
        input("æŒ‰å›è½¦é”®é€€å‡º...")
    except Exception as e:
        print(f"âŒ GUIå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        print("ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        input("æŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main() 